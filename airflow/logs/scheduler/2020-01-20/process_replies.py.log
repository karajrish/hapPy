[2020-01-20 12:12:54,014] {scheduler_job.py:153} INFO - Started process (PID=739) to work on /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 12:12:54,020] {scheduler_job.py:1539} INFO - Processing file /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py for tasks to queue
[2020-01-20 12:12:54,021] {logging_mixin.py:112} INFO - [2020-01-20 12:12:54,020] {dagbag.py:403} INFO - Filling up the DagBag from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 12:12:54,251] {scheduler_job.py:1551} INFO - DAG(s) dict_keys(['process_replies']) retrieved from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 12:12:54,260] {logging_mixin.py:112} INFO - [2020-01-20 12:12:54,260] {dag.py:1376} INFO - Creating ORM DAG for process_replies
[2020-01-20 12:12:54,270] {scheduler_job.py:161} INFO - Processing /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py took 0.256 seconds
[2020-01-20 12:13:38,161] {scheduler_job.py:153} INFO - Started process (PID=778) to work on /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 12:13:38,168] {scheduler_job.py:1539} INFO - Processing file /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py for tasks to queue
[2020-01-20 12:13:38,169] {logging_mixin.py:112} INFO - [2020-01-20 12:13:38,169] {dagbag.py:403} INFO - Filling up the DagBag from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 12:13:38,255] {scheduler_job.py:1551} INFO - DAG(s) dict_keys(['process_replies']) retrieved from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 12:13:38,273] {scheduler_job.py:161} INFO - Processing /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py took 0.113 seconds
[2020-01-20 12:14:22,276] {scheduler_job.py:153} INFO - Started process (PID=805) to work on /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 12:14:22,282] {scheduler_job.py:1539} INFO - Processing file /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py for tasks to queue
[2020-01-20 12:14:22,283] {logging_mixin.py:112} INFO - [2020-01-20 12:14:22,283] {dagbag.py:403} INFO - Filling up the DagBag from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 12:14:22,441] {scheduler_job.py:1551} INFO - DAG(s) dict_keys(['process_replies']) retrieved from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 12:14:22,459] {scheduler_job.py:161} INFO - Processing /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py took 0.183 seconds
[2020-01-20 12:15:06,035] {scheduler_job.py:153} INFO - Started process (PID=832) to work on /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 12:15:06,043] {scheduler_job.py:1539} INFO - Processing file /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py for tasks to queue
[2020-01-20 12:15:06,044] {logging_mixin.py:112} INFO - [2020-01-20 12:15:06,044] {dagbag.py:403} INFO - Filling up the DagBag from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 12:15:06,099] {scheduler_job.py:1551} INFO - DAG(s) dict_keys(['process_replies']) retrieved from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 12:15:06,115] {scheduler_job.py:161} INFO - Processing /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py took 0.081 seconds
[2020-01-20 12:15:50,148] {scheduler_job.py:153} INFO - Started process (PID=861) to work on /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 12:15:50,155] {scheduler_job.py:1539} INFO - Processing file /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py for tasks to queue
[2020-01-20 12:15:50,156] {logging_mixin.py:112} INFO - [2020-01-20 12:15:50,156] {dagbag.py:403} INFO - Filling up the DagBag from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 12:15:50,210] {scheduler_job.py:1551} INFO - DAG(s) dict_keys(['process_replies']) retrieved from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 12:15:50,228] {scheduler_job.py:161} INFO - Processing /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py took 0.080 seconds
[2020-01-20 12:16:34,263] {scheduler_job.py:153} INFO - Started process (PID=889) to work on /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 12:16:34,269] {scheduler_job.py:1539} INFO - Processing file /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py for tasks to queue
[2020-01-20 12:16:34,270] {logging_mixin.py:112} INFO - [2020-01-20 12:16:34,269] {dagbag.py:403} INFO - Filling up the DagBag from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 12:16:34,412] {scheduler_job.py:1551} INFO - DAG(s) dict_keys(['process_replies']) retrieved from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 12:16:34,431] {scheduler_job.py:161} INFO - Processing /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py took 0.168 seconds
[2020-01-20 12:17:18,361] {scheduler_job.py:153} INFO - Started process (PID=920) to work on /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 12:17:18,368] {scheduler_job.py:1539} INFO - Processing file /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py for tasks to queue
[2020-01-20 12:17:18,369] {logging_mixin.py:112} INFO - [2020-01-20 12:17:18,369] {dagbag.py:403} INFO - Filling up the DagBag from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 12:17:18,446] {scheduler_job.py:1551} INFO - DAG(s) dict_keys(['process_replies']) retrieved from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 12:17:18,463] {scheduler_job.py:161} INFO - Processing /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py took 0.102 seconds
[2020-01-20 12:18:02,471] {scheduler_job.py:153} INFO - Started process (PID=945) to work on /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 12:18:02,478] {scheduler_job.py:1539} INFO - Processing file /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py for tasks to queue
[2020-01-20 12:18:02,479] {logging_mixin.py:112} INFO - [2020-01-20 12:18:02,478] {dagbag.py:403} INFO - Filling up the DagBag from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 12:18:02,555] {scheduler_job.py:1551} INFO - DAG(s) dict_keys(['process_replies']) retrieved from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 12:18:02,573] {scheduler_job.py:161} INFO - Processing /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py took 0.102 seconds
[2020-01-20 12:18:46,568] {scheduler_job.py:153} INFO - Started process (PID=970) to work on /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 12:18:46,575] {scheduler_job.py:1539} INFO - Processing file /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py for tasks to queue
[2020-01-20 12:18:46,576] {logging_mixin.py:112} INFO - [2020-01-20 12:18:46,576] {dagbag.py:403} INFO - Filling up the DagBag from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 12:18:46,631] {scheduler_job.py:1551} INFO - DAG(s) dict_keys(['process_replies']) retrieved from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 12:18:46,646] {scheduler_job.py:161} INFO - Processing /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py took 0.079 seconds
[2020-01-20 12:19:30,703] {scheduler_job.py:153} INFO - Started process (PID=1003) to work on /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 12:19:30,713] {scheduler_job.py:1539} INFO - Processing file /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py for tasks to queue
[2020-01-20 12:19:30,715] {logging_mixin.py:112} INFO - [2020-01-20 12:19:30,715] {dagbag.py:403} INFO - Filling up the DagBag from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 12:19:30,798] {scheduler_job.py:1551} INFO - DAG(s) dict_keys(['process_replies']) retrieved from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 12:19:30,822] {scheduler_job.py:161} INFO - Processing /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py took 0.119 seconds
[2020-01-20 12:20:14,818] {scheduler_job.py:153} INFO - Started process (PID=1031) to work on /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 12:20:14,824] {scheduler_job.py:1539} INFO - Processing file /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py for tasks to queue
[2020-01-20 12:20:14,825] {logging_mixin.py:112} INFO - [2020-01-20 12:20:14,825] {dagbag.py:403} INFO - Filling up the DagBag from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 12:20:14,882] {scheduler_job.py:1551} INFO - DAG(s) dict_keys(['process_replies']) retrieved from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 12:20:14,901] {scheduler_job.py:161} INFO - Processing /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py took 0.083 seconds
[2020-01-20 12:20:58,931] {scheduler_job.py:153} INFO - Started process (PID=1059) to work on /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 12:20:58,941] {scheduler_job.py:1539} INFO - Processing file /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py for tasks to queue
[2020-01-20 12:20:58,942] {logging_mixin.py:112} INFO - [2020-01-20 12:20:58,942] {dagbag.py:403} INFO - Filling up the DagBag from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 12:20:59,005] {scheduler_job.py:1551} INFO - DAG(s) dict_keys(['process_replies']) retrieved from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 12:20:59,023] {scheduler_job.py:161} INFO - Processing /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py took 0.092 seconds
[2020-01-20 12:21:43,054] {scheduler_job.py:153} INFO - Started process (PID=1086) to work on /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 12:21:43,061] {scheduler_job.py:1539} INFO - Processing file /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py for tasks to queue
[2020-01-20 12:21:43,062] {logging_mixin.py:112} INFO - [2020-01-20 12:21:43,062] {dagbag.py:403} INFO - Filling up the DagBag from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 12:21:43,115] {scheduler_job.py:1551} INFO - DAG(s) dict_keys(['process_replies']) retrieved from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 12:21:43,132] {scheduler_job.py:161} INFO - Processing /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py took 0.079 seconds
[2020-01-20 12:22:27,178] {scheduler_job.py:153} INFO - Started process (PID=1130) to work on /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 12:22:27,184] {scheduler_job.py:1539} INFO - Processing file /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py for tasks to queue
[2020-01-20 12:22:27,185] {logging_mixin.py:112} INFO - [2020-01-20 12:22:27,185] {dagbag.py:403} INFO - Filling up the DagBag from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 12:22:27,268] {scheduler_job.py:1551} INFO - DAG(s) dict_keys(['process_replies']) retrieved from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 12:22:27,285] {scheduler_job.py:161} INFO - Processing /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py took 0.106 seconds
[2020-01-20 12:23:11,293] {scheduler_job.py:153} INFO - Started process (PID=1164) to work on /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 12:23:11,304] {scheduler_job.py:1539} INFO - Processing file /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py for tasks to queue
[2020-01-20 12:23:11,305] {logging_mixin.py:112} INFO - [2020-01-20 12:23:11,305] {dagbag.py:403} INFO - Filling up the DagBag from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 12:23:11,381] {scheduler_job.py:1551} INFO - DAG(s) dict_keys(['process_replies']) retrieved from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 12:23:11,397] {scheduler_job.py:161} INFO - Processing /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py took 0.104 seconds
[2020-01-20 12:23:55,427] {scheduler_job.py:153} INFO - Started process (PID=1195) to work on /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 12:23:55,432] {scheduler_job.py:1539} INFO - Processing file /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py for tasks to queue
[2020-01-20 12:23:55,433] {logging_mixin.py:112} INFO - [2020-01-20 12:23:55,433] {dagbag.py:403} INFO - Filling up the DagBag from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 12:23:55,500] {scheduler_job.py:1551} INFO - DAG(s) dict_keys(['process_replies']) retrieved from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 12:23:55,516] {scheduler_job.py:161} INFO - Processing /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py took 0.090 seconds
[2020-01-20 12:24:39,578] {scheduler_job.py:153} INFO - Started process (PID=1231) to work on /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 12:24:39,590] {scheduler_job.py:1539} INFO - Processing file /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py for tasks to queue
[2020-01-20 12:24:39,591] {logging_mixin.py:112} INFO - [2020-01-20 12:24:39,591] {dagbag.py:403} INFO - Filling up the DagBag from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 12:24:39,907] {scheduler_job.py:1551} INFO - DAG(s) dict_keys(['process_replies']) retrieved from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 12:24:39,928] {scheduler_job.py:161} INFO - Processing /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py took 0.351 seconds
[2020-01-20 12:25:23,642] {scheduler_job.py:153} INFO - Started process (PID=1260) to work on /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 12:25:23,657] {scheduler_job.py:1539} INFO - Processing file /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py for tasks to queue
[2020-01-20 12:25:23,658] {logging_mixin.py:112} INFO - [2020-01-20 12:25:23,657] {dagbag.py:403} INFO - Filling up the DagBag from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 12:25:23,730] {scheduler_job.py:1551} INFO - DAG(s) dict_keys(['process_replies']) retrieved from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 12:25:23,757] {scheduler_job.py:1262} INFO - Processing process_replies
[2020-01-20 12:25:23,813] {scheduler_job.py:1272} INFO - Created <DagRun process_replies @ 2019-10-09T00:00:00+00:00: scheduled__2019-10-09T00:00:00+00:00, externally triggered: False>
[2020-01-20 12:25:23,822] {scheduler_job.py:740} INFO - Examining DAG run <DagRun process_replies @ 2019-10-09 00:00:00+00:00: scheduled__2019-10-09T00:00:00+00:00, externally triggered: False>
[2020-01-20 12:25:23,839] {scheduler_job.py:740} INFO - Examining DAG run <DagRun process_replies @ 2020-01-20 06:46:08.010086+00:00: manual__2020-01-20T06:46:08.010086+00:00, externally triggered: True>
[2020-01-20 12:25:23,904] {scheduler_job.py:440} INFO - Skipping SLA check for <DAG: process_replies> because no tasks in DAG have SLAs
[2020-01-20 12:25:23,915] {scheduler_job.py:1613} INFO - Creating / updating <TaskInstance: process_replies.send_replies 2019-10-09 00:00:00+00:00 [scheduled]> in ORM
[2020-01-20 12:25:23,926] {scheduler_job.py:1613} INFO - Creating / updating <TaskInstance: process_replies.send_replies 2020-01-20 06:46:08.010086+00:00 [scheduled]> in ORM
[2020-01-20 12:25:23,938] {scheduler_job.py:161} INFO - Processing /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py took 0.296 seconds
[2020-01-20 12:26:12,771] {scheduler_job.py:153} INFO - Started process (PID=1297) to work on /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 12:26:12,783] {scheduler_job.py:1539} INFO - Processing file /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py for tasks to queue
[2020-01-20 12:26:12,784] {logging_mixin.py:112} INFO - [2020-01-20 12:26:12,783] {dagbag.py:403} INFO - Filling up the DagBag from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 12:26:13,031] {scheduler_job.py:1551} INFO - DAG(s) dict_keys(['process_replies']) retrieved from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 12:26:13,055] {scheduler_job.py:1262} INFO - Processing process_replies
[2020-01-20 12:26:13,066] {scheduler_job.py:740} INFO - Examining DAG run <DagRun process_replies @ 2019-10-09 00:00:00+00:00: scheduled__2019-10-09T00:00:00+00:00, externally triggered: False>
[2020-01-20 12:26:13,081] {logging_mixin.py:112} INFO - [2020-01-20 12:26:13,081] {dagrun.py:309} INFO - Marking run <DagRun process_replies @ 2019-10-09 00:00:00+00:00: scheduled__2019-10-09T00:00:00+00:00, externally triggered: False> failed
[2020-01-20 12:26:13,084] {scheduler_job.py:740} INFO - Examining DAG run <DagRun process_replies @ 2020-01-20 06:46:08.010086+00:00: manual__2020-01-20T06:46:08.010086+00:00, externally triggered: True>
[2020-01-20 12:26:13,092] {logging_mixin.py:112} INFO - [2020-01-20 12:26:13,091] {dagrun.py:309} INFO - Marking run <DagRun process_replies @ 2020-01-20 06:46:08.010086+00:00: manual__2020-01-20T06:46:08.010086+00:00, externally triggered: True> failed
[2020-01-20 12:26:13,094] {scheduler_job.py:440} INFO - Skipping SLA check for <DAG: process_replies> because no tasks in DAG have SLAs
[2020-01-20 12:26:13,097] {scheduler_job.py:161} INFO - Processing /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py took 0.326 seconds
[2020-01-20 12:29:40,888] {scheduler_job.py:153} INFO - Started process (PID=1365) to work on /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 12:29:40,906] {scheduler_job.py:1539} INFO - Processing file /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py for tasks to queue
[2020-01-20 12:29:40,907] {logging_mixin.py:112} INFO - [2020-01-20 12:29:40,907] {dagbag.py:403} INFO - Filling up the DagBag from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 12:29:41,132] {scheduler_job.py:1551} INFO - DAG(s) dict_keys(['process_replies']) retrieved from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 12:29:41,158] {scheduler_job.py:1262} INFO - Processing process_replies
[2020-01-20 12:29:41,167] {scheduler_job.py:440} INFO - Skipping SLA check for <DAG: process_replies> because no tasks in DAG have SLAs
[2020-01-20 12:29:41,170] {scheduler_job.py:161} INFO - Processing /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py took 0.282 seconds
[2020-01-20 12:30:24,987] {scheduler_job.py:153} INFO - Started process (PID=1396) to work on /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 12:30:24,997] {scheduler_job.py:1539} INFO - Processing file /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py for tasks to queue
[2020-01-20 12:30:24,998] {logging_mixin.py:112} INFO - [2020-01-20 12:30:24,998] {dagbag.py:403} INFO - Filling up the DagBag from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 12:30:25,109] {scheduler_job.py:1551} INFO - DAG(s) dict_keys(['process_replies']) retrieved from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 12:30:25,148] {scheduler_job.py:1262} INFO - Processing process_replies
[2020-01-20 12:30:25,160] {scheduler_job.py:740} INFO - Examining DAG run <DagRun process_replies @ 2020-01-20 07:00:12.428513+00:00: manual__2020-01-20T07:00:12.428513+00:00, externally triggered: True>
[2020-01-20 12:30:25,185] {scheduler_job.py:440} INFO - Skipping SLA check for <DAG: process_replies> because no tasks in DAG have SLAs
[2020-01-20 12:30:25,193] {scheduler_job.py:1613} INFO - Creating / updating <TaskInstance: process_replies.send_replies 2020-01-20 07:00:12.428513+00:00 [scheduled]> in ORM
[2020-01-20 12:30:25,209] {scheduler_job.py:161} INFO - Processing /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py took 0.222 seconds
[2020-01-20 12:31:46,791] {scheduler_job.py:153} INFO - Started process (PID=1429) to work on /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 12:31:46,801] {scheduler_job.py:1539} INFO - Processing file /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py for tasks to queue
[2020-01-20 12:31:46,802] {logging_mixin.py:112} INFO - [2020-01-20 12:31:46,802] {dagbag.py:403} INFO - Filling up the DagBag from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 12:31:46,995] {scheduler_job.py:1551} INFO - DAG(s) dict_keys(['process_replies']) retrieved from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 12:31:47,020] {scheduler_job.py:1262} INFO - Processing process_replies
[2020-01-20 12:31:47,027] {scheduler_job.py:740} INFO - Examining DAG run <DagRun process_replies @ 2020-01-20 07:00:12.428513+00:00: manual__2020-01-20T07:00:12.428513+00:00, externally triggered: True>
[2020-01-20 12:31:47,034] {logging_mixin.py:112} INFO - [2020-01-20 12:31:47,034] {dagrun.py:309} INFO - Marking run <DagRun process_replies @ 2020-01-20 07:00:12.428513+00:00: manual__2020-01-20T07:00:12.428513+00:00, externally triggered: True> failed
[2020-01-20 12:31:47,038] {scheduler_job.py:440} INFO - Skipping SLA check for <DAG: process_replies> because no tasks in DAG have SLAs
[2020-01-20 12:31:47,041] {scheduler_job.py:161} INFO - Processing /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py took 0.250 seconds
[2020-01-20 12:32:30,917] {scheduler_job.py:153} INFO - Started process (PID=1457) to work on /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 12:32:30,928] {scheduler_job.py:1539} INFO - Processing file /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py for tasks to queue
[2020-01-20 12:32:30,929] {logging_mixin.py:112} INFO - [2020-01-20 12:32:30,928] {dagbag.py:403} INFO - Filling up the DagBag from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 12:32:32,453] {scheduler_job.py:1551} INFO - DAG(s) dict_keys(['process_replies']) retrieved from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 12:32:32,493] {scheduler_job.py:1262} INFO - Processing process_replies
[2020-01-20 12:32:32,510] {scheduler_job.py:440} INFO - Skipping SLA check for <DAG: process_replies> because no tasks in DAG have SLAs
[2020-01-20 12:32:32,515] {scheduler_job.py:161} INFO - Processing /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py took 1.598 seconds
[2020-01-20 12:34:00,171] {scheduler_job.py:153} INFO - Started process (PID=1495) to work on /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 12:34:00,182] {scheduler_job.py:1539} INFO - Processing file /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py for tasks to queue
[2020-01-20 12:34:00,183] {logging_mixin.py:112} INFO - [2020-01-20 12:34:00,183] {dagbag.py:403} INFO - Filling up the DagBag from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 12:34:00,312] {scheduler_job.py:1551} INFO - DAG(s) dict_keys(['process_replies']) retrieved from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 12:34:00,333] {scheduler_job.py:1262} INFO - Processing process_replies
[2020-01-20 12:34:00,341] {scheduler_job.py:440} INFO - Skipping SLA check for <DAG: process_replies> because no tasks in DAG have SLAs
[2020-01-20 12:34:00,344] {scheduler_job.py:161} INFO - Processing /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py took 0.173 seconds
[2020-01-20 12:34:44,300] {scheduler_job.py:153} INFO - Started process (PID=1519) to work on /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 12:34:44,308] {scheduler_job.py:1539} INFO - Processing file /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py for tasks to queue
[2020-01-20 12:34:44,309] {logging_mixin.py:112} INFO - [2020-01-20 12:34:44,308] {dagbag.py:403} INFO - Filling up the DagBag from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 12:34:44,408] {scheduler_job.py:1551} INFO - DAG(s) dict_keys(['process_replies']) retrieved from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 12:34:44,429] {scheduler_job.py:1262} INFO - Processing process_replies
[2020-01-20 12:34:44,436] {scheduler_job.py:440} INFO - Skipping SLA check for <DAG: process_replies> because no tasks in DAG have SLAs
[2020-01-20 12:34:44,439] {scheduler_job.py:161} INFO - Processing /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py took 0.139 seconds
[2020-01-20 12:35:28,443] {scheduler_job.py:153} INFO - Started process (PID=1545) to work on /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 12:35:28,453] {scheduler_job.py:1539} INFO - Processing file /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py for tasks to queue
[2020-01-20 12:35:28,454] {logging_mixin.py:112} INFO - [2020-01-20 12:35:28,453] {dagbag.py:403} INFO - Filling up the DagBag from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 12:35:28,516] {scheduler_job.py:1551} INFO - DAG(s) dict_keys(['process_replies']) retrieved from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 12:35:28,542] {scheduler_job.py:1262} INFO - Processing process_replies
[2020-01-20 12:35:28,550] {scheduler_job.py:440} INFO - Skipping SLA check for <DAG: process_replies> because no tasks in DAG have SLAs
[2020-01-20 12:35:28,554] {scheduler_job.py:161} INFO - Processing /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py took 0.111 seconds
[2020-01-20 12:36:12,561] {scheduler_job.py:153} INFO - Started process (PID=1570) to work on /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 12:36:12,570] {scheduler_job.py:1539} INFO - Processing file /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py for tasks to queue
[2020-01-20 12:36:12,572] {logging_mixin.py:112} INFO - [2020-01-20 12:36:12,571] {dagbag.py:403} INFO - Filling up the DagBag from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 12:36:12,777] {scheduler_job.py:1551} INFO - DAG(s) dict_keys(['process_replies']) retrieved from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 12:36:12,800] {scheduler_job.py:1262} INFO - Processing process_replies
[2020-01-20 12:36:12,808] {scheduler_job.py:440} INFO - Skipping SLA check for <DAG: process_replies> because no tasks in DAG have SLAs
[2020-01-20 12:36:12,810] {scheduler_job.py:161} INFO - Processing /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py took 0.249 seconds
[2020-01-20 12:36:56,672] {scheduler_job.py:153} INFO - Started process (PID=1606) to work on /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 12:36:56,682] {scheduler_job.py:1539} INFO - Processing file /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py for tasks to queue
[2020-01-20 12:36:56,683] {logging_mixin.py:112} INFO - [2020-01-20 12:36:56,683] {dagbag.py:403} INFO - Filling up the DagBag from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 12:36:56,742] {scheduler_job.py:1551} INFO - DAG(s) dict_keys(['process_replies']) retrieved from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 12:36:56,761] {scheduler_job.py:1262} INFO - Processing process_replies
[2020-01-20 12:36:56,768] {scheduler_job.py:440} INFO - Skipping SLA check for <DAG: process_replies> because no tasks in DAG have SLAs
[2020-01-20 12:36:56,770] {scheduler_job.py:161} INFO - Processing /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py took 0.099 seconds
[2020-01-20 12:37:40,819] {scheduler_job.py:153} INFO - Started process (PID=1636) to work on /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 12:37:40,827] {scheduler_job.py:1539} INFO - Processing file /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py for tasks to queue
[2020-01-20 12:37:40,828] {logging_mixin.py:112} INFO - [2020-01-20 12:37:40,828] {dagbag.py:403} INFO - Filling up the DagBag from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 12:37:40,890] {scheduler_job.py:1551} INFO - DAG(s) dict_keys(['process_replies']) retrieved from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 12:37:40,913] {scheduler_job.py:1262} INFO - Processing process_replies
[2020-01-20 12:37:40,920] {scheduler_job.py:440} INFO - Skipping SLA check for <DAG: process_replies> because no tasks in DAG have SLAs
[2020-01-20 12:37:40,923] {scheduler_job.py:161} INFO - Processing /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py took 0.104 seconds
[2020-01-20 12:38:24,927] {scheduler_job.py:153} INFO - Started process (PID=1666) to work on /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 12:38:24,935] {scheduler_job.py:1539} INFO - Processing file /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py for tasks to queue
[2020-01-20 12:38:24,936] {logging_mixin.py:112} INFO - [2020-01-20 12:38:24,935] {dagbag.py:403} INFO - Filling up the DagBag from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 12:38:25,002] {scheduler_job.py:1551} INFO - DAG(s) dict_keys(['process_replies']) retrieved from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 12:38:25,035] {scheduler_job.py:1262} INFO - Processing process_replies
[2020-01-20 12:38:25,050] {scheduler_job.py:740} INFO - Examining DAG run <DagRun process_replies @ 2020-01-20 07:08:17.355254+00:00: manual__2020-01-20T07:08:17.355254+00:00, externally triggered: True>
[2020-01-20 12:38:25,066] {scheduler_job.py:440} INFO - Skipping SLA check for <DAG: process_replies> because no tasks in DAG have SLAs
[2020-01-20 12:38:25,070] {scheduler_job.py:1613} INFO - Creating / updating <TaskInstance: process_replies.send_replies 2020-01-20 07:08:17.355254+00:00 [scheduled]> in ORM
[2020-01-20 12:38:25,123] {scheduler_job.py:161} INFO - Processing /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py took 0.196 seconds
[2020-01-20 12:39:46,541] {scheduler_job.py:153} INFO - Started process (PID=1705) to work on /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 12:39:46,552] {scheduler_job.py:1539} INFO - Processing file /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py for tasks to queue
[2020-01-20 12:39:46,553] {logging_mixin.py:112} INFO - [2020-01-20 12:39:46,553] {dagbag.py:403} INFO - Filling up the DagBag from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 12:39:46,619] {scheduler_job.py:1551} INFO - DAG(s) dict_keys(['process_replies']) retrieved from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 12:39:46,641] {scheduler_job.py:1262} INFO - Processing process_replies
[2020-01-20 12:39:46,650] {scheduler_job.py:740} INFO - Examining DAG run <DagRun process_replies @ 2020-01-20 07:08:17.355254+00:00: manual__2020-01-20T07:08:17.355254+00:00, externally triggered: True>
[2020-01-20 12:39:46,658] {logging_mixin.py:112} INFO - [2020-01-20 12:39:46,658] {dagrun.py:309} INFO - Marking run <DagRun process_replies @ 2020-01-20 07:08:17.355254+00:00: manual__2020-01-20T07:08:17.355254+00:00, externally triggered: True> failed
[2020-01-20 12:39:46,661] {scheduler_job.py:440} INFO - Skipping SLA check for <DAG: process_replies> because no tasks in DAG have SLAs
[2020-01-20 12:39:46,663] {scheduler_job.py:161} INFO - Processing /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py took 0.122 seconds
[2020-01-20 12:40:30,661] {scheduler_job.py:153} INFO - Started process (PID=1739) to work on /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 12:40:30,669] {scheduler_job.py:1539} INFO - Processing file /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py for tasks to queue
[2020-01-20 12:40:30,670] {logging_mixin.py:112} INFO - [2020-01-20 12:40:30,669] {dagbag.py:403} INFO - Filling up the DagBag from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 12:40:30,737] {scheduler_job.py:1551} INFO - DAG(s) dict_keys(['process_replies']) retrieved from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 12:40:30,757] {scheduler_job.py:1262} INFO - Processing process_replies
[2020-01-20 12:40:30,764] {scheduler_job.py:440} INFO - Skipping SLA check for <DAG: process_replies> because no tasks in DAG have SLAs
[2020-01-20 12:40:30,767] {scheduler_job.py:161} INFO - Processing /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py took 0.106 seconds
[2020-01-20 12:41:14,830] {scheduler_job.py:153} INFO - Started process (PID=1779) to work on /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 12:41:14,850] {scheduler_job.py:1539} INFO - Processing file /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py for tasks to queue
[2020-01-20 12:41:14,852] {logging_mixin.py:112} INFO - [2020-01-20 12:41:14,851] {dagbag.py:403} INFO - Filling up the DagBag from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 12:41:15,318] {scheduler_job.py:1551} INFO - DAG(s) dict_keys(['process_replies']) retrieved from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 12:41:15,352] {scheduler_job.py:1262} INFO - Processing process_replies
[2020-01-20 12:41:15,367] {scheduler_job.py:440} INFO - Skipping SLA check for <DAG: process_replies> because no tasks in DAG have SLAs
[2020-01-20 12:41:15,370] {scheduler_job.py:161} INFO - Processing /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py took 0.541 seconds
[2020-01-20 12:41:58,885] {scheduler_job.py:153} INFO - Started process (PID=1811) to work on /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 12:41:58,894] {scheduler_job.py:1539} INFO - Processing file /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py for tasks to queue
[2020-01-20 12:41:58,895] {logging_mixin.py:112} INFO - [2020-01-20 12:41:58,895] {dagbag.py:403} INFO - Filling up the DagBag from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 12:41:58,968] {scheduler_job.py:1551} INFO - DAG(s) dict_keys(['process_replies']) retrieved from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 12:41:58,990] {scheduler_job.py:1262} INFO - Processing process_replies
[2020-01-20 12:41:59,000] {scheduler_job.py:440} INFO - Skipping SLA check for <DAG: process_replies> because no tasks in DAG have SLAs
[2020-01-20 12:41:59,005] {scheduler_job.py:161} INFO - Processing /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py took 0.119 seconds
[2020-01-20 12:42:43,277] {scheduler_job.py:153} INFO - Started process (PID=2243) to work on /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 12:42:43,289] {scheduler_job.py:1539} INFO - Processing file /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py for tasks to queue
[2020-01-20 12:42:43,290] {logging_mixin.py:112} INFO - [2020-01-20 12:42:43,289] {dagbag.py:403} INFO - Filling up the DagBag from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 12:42:43,578] {scheduler_job.py:1551} INFO - DAG(s) dict_keys(['process_replies']) retrieved from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 12:42:43,609] {scheduler_job.py:1262} INFO - Processing process_replies
[2020-01-20 12:42:43,618] {scheduler_job.py:440} INFO - Skipping SLA check for <DAG: process_replies> because no tasks in DAG have SLAs
[2020-01-20 12:42:43,620] {scheduler_job.py:161} INFO - Processing /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py took 0.343 seconds
[2020-01-20 12:43:27,394] {scheduler_job.py:153} INFO - Started process (PID=2270) to work on /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 12:43:27,401] {scheduler_job.py:1539} INFO - Processing file /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py for tasks to queue
[2020-01-20 12:43:27,402] {logging_mixin.py:112} INFO - [2020-01-20 12:43:27,401] {dagbag.py:403} INFO - Filling up the DagBag from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 12:43:27,470] {scheduler_job.py:1551} INFO - DAG(s) dict_keys(['process_replies']) retrieved from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 12:43:27,495] {scheduler_job.py:1262} INFO - Processing process_replies
[2020-01-20 12:43:27,505] {scheduler_job.py:440} INFO - Skipping SLA check for <DAG: process_replies> because no tasks in DAG have SLAs
[2020-01-20 12:43:27,508] {scheduler_job.py:161} INFO - Processing /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py took 0.114 seconds
[2020-01-20 12:44:11,516] {scheduler_job.py:153} INFO - Started process (PID=2296) to work on /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 12:44:11,524] {scheduler_job.py:1539} INFO - Processing file /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py for tasks to queue
[2020-01-20 12:44:11,525] {logging_mixin.py:112} INFO - [2020-01-20 12:44:11,524] {dagbag.py:403} INFO - Filling up the DagBag from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 12:44:11,603] {scheduler_job.py:1551} INFO - DAG(s) dict_keys(['process_replies']) retrieved from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 12:44:11,624] {scheduler_job.py:1262} INFO - Processing process_replies
[2020-01-20 12:44:11,631] {scheduler_job.py:440} INFO - Skipping SLA check for <DAG: process_replies> because no tasks in DAG have SLAs
[2020-01-20 12:44:11,634] {scheduler_job.py:161} INFO - Processing /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py took 0.118 seconds
[2020-01-20 12:44:55,651] {scheduler_job.py:153} INFO - Started process (PID=2324) to work on /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 12:44:55,662] {scheduler_job.py:1539} INFO - Processing file /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py for tasks to queue
[2020-01-20 12:44:55,663] {logging_mixin.py:112} INFO - [2020-01-20 12:44:55,663] {dagbag.py:403} INFO - Filling up the DagBag from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 12:44:55,724] {scheduler_job.py:1551} INFO - DAG(s) dict_keys(['process_replies']) retrieved from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 12:44:55,746] {scheduler_job.py:1262} INFO - Processing process_replies
[2020-01-20 12:44:55,753] {scheduler_job.py:440} INFO - Skipping SLA check for <DAG: process_replies> because no tasks in DAG have SLAs
[2020-01-20 12:44:55,755] {scheduler_job.py:161} INFO - Processing /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py took 0.105 seconds
[2020-01-20 12:45:39,764] {scheduler_job.py:153} INFO - Started process (PID=2352) to work on /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 12:45:39,774] {scheduler_job.py:1539} INFO - Processing file /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py for tasks to queue
[2020-01-20 12:45:39,776] {logging_mixin.py:112} INFO - [2020-01-20 12:45:39,775] {dagbag.py:403} INFO - Filling up the DagBag from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 12:45:39,845] {scheduler_job.py:1551} INFO - DAG(s) dict_keys(['process_replies']) retrieved from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 12:45:39,868] {scheduler_job.py:1262} INFO - Processing process_replies
[2020-01-20 12:45:39,878] {scheduler_job.py:440} INFO - Skipping SLA check for <DAG: process_replies> because no tasks in DAG have SLAs
[2020-01-20 12:45:39,882] {scheduler_job.py:161} INFO - Processing /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py took 0.118 seconds
[2020-01-20 12:46:23,886] {scheduler_job.py:153} INFO - Started process (PID=2379) to work on /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 12:46:23,897] {scheduler_job.py:1539} INFO - Processing file /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py for tasks to queue
[2020-01-20 12:46:23,898] {logging_mixin.py:112} INFO - [2020-01-20 12:46:23,898] {dagbag.py:403} INFO - Filling up the DagBag from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 12:46:24,153] {scheduler_job.py:1551} INFO - DAG(s) dict_keys(['process_replies']) retrieved from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 12:46:24,185] {scheduler_job.py:1262} INFO - Processing process_replies
[2020-01-20 12:46:24,198] {scheduler_job.py:740} INFO - Examining DAG run <DagRun process_replies @ 2020-01-20 07:16:14.766315+00:00: manual__2020-01-20T07:16:14.766315+00:00, externally triggered: True>
[2020-01-20 12:46:24,220] {scheduler_job.py:440} INFO - Skipping SLA check for <DAG: process_replies> because no tasks in DAG have SLAs
[2020-01-20 12:46:24,228] {scheduler_job.py:1613} INFO - Creating / updating <TaskInstance: process_replies.send_replies 2020-01-20 07:16:14.766315+00:00 [scheduled]> in ORM
[2020-01-20 12:46:24,239] {scheduler_job.py:161} INFO - Processing /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py took 0.353 seconds
[2020-01-20 12:47:21,148] {scheduler_job.py:153} INFO - Started process (PID=2420) to work on /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 12:47:21,158] {scheduler_job.py:1539} INFO - Processing file /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py for tasks to queue
[2020-01-20 12:47:21,159] {logging_mixin.py:112} INFO - [2020-01-20 12:47:21,159] {dagbag.py:403} INFO - Filling up the DagBag from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 12:47:21,233] {scheduler_job.py:1551} INFO - DAG(s) dict_keys(['process_replies']) retrieved from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 12:47:21,256] {scheduler_job.py:1262} INFO - Processing process_replies
[2020-01-20 12:47:21,266] {scheduler_job.py:740} INFO - Examining DAG run <DagRun process_replies @ 2020-01-20 07:16:14.766315+00:00: manual__2020-01-20T07:16:14.766315+00:00, externally triggered: True>
[2020-01-20 12:47:21,280] {logging_mixin.py:112} INFO - [2020-01-20 12:47:21,279] {dagrun.py:318} INFO - Marking run <DagRun process_replies @ 2020-01-20 07:16:14.766315+00:00: manual__2020-01-20T07:16:14.766315+00:00, externally triggered: True> successful
[2020-01-20 12:47:21,286] {scheduler_job.py:440} INFO - Skipping SLA check for <DAG: process_replies> because no tasks in DAG have SLAs
[2020-01-20 12:47:21,289] {scheduler_job.py:161} INFO - Processing /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py took 0.141 seconds
[2020-01-20 12:48:05,292] {scheduler_job.py:153} INFO - Started process (PID=2449) to work on /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 12:48:05,310] {scheduler_job.py:1539} INFO - Processing file /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py for tasks to queue
[2020-01-20 12:48:05,311] {logging_mixin.py:112} INFO - [2020-01-20 12:48:05,311] {dagbag.py:403} INFO - Filling up the DagBag from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 12:48:06,138] {scheduler_job.py:1551} INFO - DAG(s) dict_keys(['process_replies']) retrieved from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 12:48:06,164] {scheduler_job.py:1262} INFO - Processing process_replies
[2020-01-20 12:48:06,175] {scheduler_job.py:440} INFO - Skipping SLA check for <DAG: process_replies> because no tasks in DAG have SLAs
[2020-01-20 12:48:06,178] {scheduler_job.py:161} INFO - Processing /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py took 0.886 seconds
[2020-01-20 12:48:49,401] {scheduler_job.py:153} INFO - Started process (PID=2476) to work on /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 12:48:49,413] {scheduler_job.py:1539} INFO - Processing file /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py for tasks to queue
[2020-01-20 12:48:49,414] {logging_mixin.py:112} INFO - [2020-01-20 12:48:49,414] {dagbag.py:403} INFO - Filling up the DagBag from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 12:48:49,466] {scheduler_job.py:1551} INFO - DAG(s) dict_keys(['process_replies']) retrieved from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 12:48:49,487] {scheduler_job.py:1262} INFO - Processing process_replies
[2020-01-20 12:48:49,495] {scheduler_job.py:740} INFO - Examining DAG run <DagRun process_replies @ 2020-01-20 07:18:10.800003+00:00: manual__2020-01-20T07:18:10.800003+00:00, externally triggered: True>
[2020-01-20 12:48:49,509] {scheduler_job.py:440} INFO - Skipping SLA check for <DAG: process_replies> because no tasks in DAG have SLAs
[2020-01-20 12:48:49,515] {scheduler_job.py:1613} INFO - Creating / updating <TaskInstance: process_replies.send_replies 2020-01-20 07:18:10.800003+00:00 [scheduled]> in ORM
[2020-01-20 12:48:49,525] {scheduler_job.py:161} INFO - Processing /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py took 0.125 seconds
[2020-01-20 12:49:46,402] {scheduler_job.py:153} INFO - Started process (PID=2509) to work on /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 12:49:46,410] {scheduler_job.py:1539} INFO - Processing file /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py for tasks to queue
[2020-01-20 12:49:46,412] {logging_mixin.py:112} INFO - [2020-01-20 12:49:46,411] {dagbag.py:403} INFO - Filling up the DagBag from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 12:49:46,474] {scheduler_job.py:1551} INFO - DAG(s) dict_keys(['process_replies']) retrieved from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 12:49:46,498] {scheduler_job.py:1262} INFO - Processing process_replies
[2020-01-20 12:49:46,512] {scheduler_job.py:740} INFO - Examining DAG run <DagRun process_replies @ 2020-01-20 07:18:10.800003+00:00: manual__2020-01-20T07:18:10.800003+00:00, externally triggered: True>
[2020-01-20 12:49:46,527] {logging_mixin.py:112} INFO - [2020-01-20 12:49:46,526] {dagrun.py:309} INFO - Marking run <DagRun process_replies @ 2020-01-20 07:18:10.800003+00:00: manual__2020-01-20T07:18:10.800003+00:00, externally triggered: True> failed
[2020-01-20 12:49:46,530] {scheduler_job.py:440} INFO - Skipping SLA check for <DAG: process_replies> because no tasks in DAG have SLAs
[2020-01-20 12:49:46,533] {scheduler_job.py:161} INFO - Processing /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py took 0.131 seconds
[2020-01-20 12:50:30,527] {scheduler_job.py:153} INFO - Started process (PID=2539) to work on /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 12:50:30,539] {scheduler_job.py:1539} INFO - Processing file /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py for tasks to queue
[2020-01-20 12:50:30,541] {logging_mixin.py:112} INFO - [2020-01-20 12:50:30,540] {dagbag.py:403} INFO - Filling up the DagBag from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 12:50:30,715] {scheduler_job.py:1551} INFO - DAG(s) dict_keys(['process_replies']) retrieved from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 12:50:30,737] {scheduler_job.py:1262} INFO - Processing process_replies
[2020-01-20 12:50:30,745] {scheduler_job.py:440} INFO - Skipping SLA check for <DAG: process_replies> because no tasks in DAG have SLAs
[2020-01-20 12:50:30,747] {scheduler_job.py:161} INFO - Processing /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py took 0.220 seconds
[2020-01-20 12:51:14,696] {scheduler_job.py:153} INFO - Started process (PID=2562) to work on /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 12:51:14,727] {scheduler_job.py:1539} INFO - Processing file /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py for tasks to queue
[2020-01-20 12:51:14,730] {logging_mixin.py:112} INFO - [2020-01-20 12:51:14,729] {dagbag.py:403} INFO - Filling up the DagBag from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 12:51:14,926] {scheduler_job.py:1551} INFO - DAG(s) dict_keys(['process_replies']) retrieved from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 12:51:14,965] {scheduler_job.py:1262} INFO - Processing process_replies
[2020-01-20 12:51:14,985] {scheduler_job.py:440} INFO - Skipping SLA check for <DAG: process_replies> because no tasks in DAG have SLAs
[2020-01-20 12:51:14,989] {scheduler_job.py:161} INFO - Processing /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py took 0.292 seconds
[2020-01-20 12:51:58,810] {scheduler_job.py:153} INFO - Started process (PID=2596) to work on /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 12:51:58,818] {scheduler_job.py:1539} INFO - Processing file /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py for tasks to queue
[2020-01-20 12:51:58,819] {logging_mixin.py:112} INFO - [2020-01-20 12:51:58,818] {dagbag.py:403} INFO - Filling up the DagBag from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 12:51:58,883] {scheduler_job.py:1551} INFO - DAG(s) dict_keys(['process_replies']) retrieved from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 12:51:58,902] {scheduler_job.py:1262} INFO - Processing process_replies
[2020-01-20 12:51:58,909] {scheduler_job.py:440} INFO - Skipping SLA check for <DAG: process_replies> because no tasks in DAG have SLAs
[2020-01-20 12:51:58,911] {scheduler_job.py:161} INFO - Processing /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py took 0.102 seconds
[2020-01-20 12:52:42,922] {scheduler_job.py:153} INFO - Started process (PID=2635) to work on /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 12:52:42,931] {scheduler_job.py:1539} INFO - Processing file /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py for tasks to queue
[2020-01-20 12:52:42,932] {logging_mixin.py:112} INFO - [2020-01-20 12:52:42,932] {dagbag.py:403} INFO - Filling up the DagBag from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 12:52:42,996] {scheduler_job.py:1551} INFO - DAG(s) dict_keys(['process_replies']) retrieved from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 12:52:43,016] {scheduler_job.py:1262} INFO - Processing process_replies
[2020-01-20 12:52:43,028] {scheduler_job.py:440} INFO - Skipping SLA check for <DAG: process_replies> because no tasks in DAG have SLAs
[2020-01-20 12:52:43,032] {scheduler_job.py:161} INFO - Processing /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py took 0.110 seconds
[2020-01-20 12:53:27,042] {scheduler_job.py:153} INFO - Started process (PID=2664) to work on /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 12:53:27,053] {scheduler_job.py:1539} INFO - Processing file /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py for tasks to queue
[2020-01-20 12:53:27,055] {logging_mixin.py:112} INFO - [2020-01-20 12:53:27,054] {dagbag.py:403} INFO - Filling up the DagBag from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 12:53:27,265] {scheduler_job.py:1551} INFO - DAG(s) dict_keys(['process_replies']) retrieved from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 12:53:27,286] {scheduler_job.py:1262} INFO - Processing process_replies
[2020-01-20 12:53:27,298] {scheduler_job.py:440} INFO - Skipping SLA check for <DAG: process_replies> because no tasks in DAG have SLAs
[2020-01-20 12:53:27,303] {scheduler_job.py:161} INFO - Processing /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py took 0.261 seconds
[2020-01-20 12:54:11,152] {scheduler_job.py:153} INFO - Started process (PID=2688) to work on /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 12:54:11,161] {scheduler_job.py:1539} INFO - Processing file /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py for tasks to queue
[2020-01-20 12:54:11,162] {logging_mixin.py:112} INFO - [2020-01-20 12:54:11,161] {dagbag.py:403} INFO - Filling up the DagBag from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 12:54:11,230] {scheduler_job.py:1551} INFO - DAG(s) dict_keys(['process_replies']) retrieved from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 12:54:11,251] {scheduler_job.py:1262} INFO - Processing process_replies
[2020-01-20 12:54:11,259] {scheduler_job.py:440} INFO - Skipping SLA check for <DAG: process_replies> because no tasks in DAG have SLAs
[2020-01-20 12:54:11,262] {scheduler_job.py:161} INFO - Processing /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py took 0.110 seconds
[2020-01-20 12:54:55,276] {scheduler_job.py:153} INFO - Started process (PID=2711) to work on /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 12:54:55,286] {scheduler_job.py:1539} INFO - Processing file /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py for tasks to queue
[2020-01-20 12:54:55,287] {logging_mixin.py:112} INFO - [2020-01-20 12:54:55,287] {dagbag.py:403} INFO - Filling up the DagBag from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 12:54:55,453] {scheduler_job.py:1551} INFO - DAG(s) dict_keys(['process_replies']) retrieved from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 12:54:55,476] {scheduler_job.py:1262} INFO - Processing process_replies
[2020-01-20 12:54:55,483] {scheduler_job.py:440} INFO - Skipping SLA check for <DAG: process_replies> because no tasks in DAG have SLAs
[2020-01-20 12:54:55,486] {scheduler_job.py:161} INFO - Processing /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py took 0.210 seconds
[2020-01-20 12:55:39,388] {scheduler_job.py:153} INFO - Started process (PID=2738) to work on /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 12:55:39,398] {scheduler_job.py:1539} INFO - Processing file /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py for tasks to queue
[2020-01-20 12:55:39,400] {logging_mixin.py:112} INFO - [2020-01-20 12:55:39,399] {dagbag.py:403} INFO - Filling up the DagBag from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 12:55:39,526] {scheduler_job.py:1551} INFO - DAG(s) dict_keys(['process_replies']) retrieved from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 12:55:39,547] {scheduler_job.py:1262} INFO - Processing process_replies
[2020-01-20 12:55:39,554] {scheduler_job.py:440} INFO - Skipping SLA check for <DAG: process_replies> because no tasks in DAG have SLAs
[2020-01-20 12:55:39,557] {scheduler_job.py:161} INFO - Processing /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py took 0.169 seconds
[2020-01-20 12:56:23,522] {scheduler_job.py:153} INFO - Started process (PID=2766) to work on /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 12:56:23,534] {scheduler_job.py:1539} INFO - Processing file /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py for tasks to queue
[2020-01-20 12:56:23,535] {logging_mixin.py:112} INFO - [2020-01-20 12:56:23,535] {dagbag.py:403} INFO - Filling up the DagBag from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 12:56:23,602] {scheduler_job.py:1551} INFO - DAG(s) dict_keys(['process_replies']) retrieved from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 12:56:23,626] {scheduler_job.py:1262} INFO - Processing process_replies
[2020-01-20 12:56:23,636] {scheduler_job.py:440} INFO - Skipping SLA check for <DAG: process_replies> because no tasks in DAG have SLAs
[2020-01-20 12:56:23,639] {scheduler_job.py:161} INFO - Processing /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py took 0.117 seconds
[2020-01-20 12:57:07,623] {scheduler_job.py:153} INFO - Started process (PID=2794) to work on /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 12:57:07,630] {scheduler_job.py:1539} INFO - Processing file /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py for tasks to queue
[2020-01-20 12:57:07,631] {logging_mixin.py:112} INFO - [2020-01-20 12:57:07,631] {dagbag.py:403} INFO - Filling up the DagBag from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 12:57:07,716] {scheduler_job.py:1551} INFO - DAG(s) dict_keys(['process_replies']) retrieved from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 12:57:07,740] {scheduler_job.py:1262} INFO - Processing process_replies
[2020-01-20 12:57:07,748] {scheduler_job.py:440} INFO - Skipping SLA check for <DAG: process_replies> because no tasks in DAG have SLAs
[2020-01-20 12:57:07,751] {scheduler_job.py:161} INFO - Processing /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py took 0.129 seconds
[2020-01-20 12:57:51,726] {scheduler_job.py:153} INFO - Started process (PID=2822) to work on /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 12:57:51,732] {scheduler_job.py:1539} INFO - Processing file /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py for tasks to queue
[2020-01-20 12:57:51,734] {logging_mixin.py:112} INFO - [2020-01-20 12:57:51,733] {dagbag.py:403} INFO - Filling up the DagBag from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 12:57:51,748] {logging_mixin.py:112} INFO - [2020-01-20 12:57:51,738] {dagbag.py:246} ERROR - Failed to import: /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
Traceback (most recent call last):
  File "/Users/aneeshmakala/Documents/ComputerScience/datascience/venv_datascience/lib/python3.7/site-packages/airflow/models/dagbag.py", line 243, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/aneeshmakala/Documents/ComputerScience/datascience/venv_datascience/lib/python3.7/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 696, in _load
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py", line 1, in <module>
    from bot.tweet_reply import send_replies
  File "/Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/bot/tweet_reply.py", line 25
    filter_doc={'_id': {"$in": [doc_ids} })
                                       ^
SyntaxError: invalid syntax
[2020-01-20 12:57:51,748] {scheduler_job.py:1553} WARNING - No viable dags retrieved from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 12:57:51,772] {scheduler_job.py:161} INFO - Processing /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py took 0.046 seconds
[2020-01-20 12:58:35,839] {scheduler_job.py:153} INFO - Started process (PID=2845) to work on /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 12:58:35,850] {scheduler_job.py:1539} INFO - Processing file /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py for tasks to queue
[2020-01-20 12:58:35,852] {logging_mixin.py:112} INFO - [2020-01-20 12:58:35,852] {dagbag.py:403} INFO - Filling up the DagBag from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 12:58:35,858] {logging_mixin.py:112} INFO - [2020-01-20 12:58:35,856] {dagbag.py:246} ERROR - Failed to import: /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
Traceback (most recent call last):
  File "/Users/aneeshmakala/Documents/ComputerScience/datascience/venv_datascience/lib/python3.7/site-packages/airflow/models/dagbag.py", line 243, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/aneeshmakala/Documents/ComputerScience/datascience/venv_datascience/lib/python3.7/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 696, in _load
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py", line 1, in <module>
    from bot.tweet_reply import send_replies
  File "/Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/bot/tweet_reply.py", line 25
    filter_doc={'_id': {"$in": [doc_ids} })
                                       ^
SyntaxError: invalid syntax
[2020-01-20 12:58:35,858] {scheduler_job.py:1553} WARNING - No viable dags retrieved from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 12:58:35,869] {scheduler_job.py:161} INFO - Processing /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py took 0.030 seconds
[2020-01-20 12:59:19,986] {scheduler_job.py:153} INFO - Started process (PID=2875) to work on /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 12:59:19,999] {scheduler_job.py:1539} INFO - Processing file /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py for tasks to queue
[2020-01-20 12:59:20,002] {logging_mixin.py:112} INFO - [2020-01-20 12:59:20,001] {dagbag.py:403} INFO - Filling up the DagBag from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 12:59:20,235] {scheduler_job.py:1551} INFO - DAG(s) dict_keys(['process_replies']) retrieved from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 12:59:20,258] {scheduler_job.py:1262} INFO - Processing process_replies
[2020-01-20 12:59:20,271] {scheduler_job.py:440} INFO - Skipping SLA check for <DAG: process_replies> because no tasks in DAG have SLAs
[2020-01-20 12:59:20,277] {scheduler_job.py:161} INFO - Processing /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py took 0.290 seconds
[2020-01-20 13:00:04,136] {scheduler_job.py:153} INFO - Started process (PID=2901) to work on /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 13:00:04,146] {scheduler_job.py:1539} INFO - Processing file /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py for tasks to queue
[2020-01-20 13:00:04,148] {logging_mixin.py:112} INFO - [2020-01-20 13:00:04,147] {dagbag.py:403} INFO - Filling up the DagBag from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 13:00:04,219] {scheduler_job.py:1551} INFO - DAG(s) dict_keys(['process_replies']) retrieved from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 13:00:04,245] {scheduler_job.py:1262} INFO - Processing process_replies
[2020-01-20 13:00:04,253] {scheduler_job.py:440} INFO - Skipping SLA check for <DAG: process_replies> because no tasks in DAG have SLAs
[2020-01-20 13:00:04,256] {scheduler_job.py:161} INFO - Processing /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py took 0.120 seconds
[2020-01-20 13:00:48,246] {scheduler_job.py:153} INFO - Started process (PID=2929) to work on /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 13:00:48,257] {scheduler_job.py:1539} INFO - Processing file /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py for tasks to queue
[2020-01-20 13:00:48,258] {logging_mixin.py:112} INFO - [2020-01-20 13:00:48,258] {dagbag.py:403} INFO - Filling up the DagBag from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 13:00:48,363] {scheduler_job.py:1551} INFO - DAG(s) dict_keys(['process_replies']) retrieved from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 13:00:48,384] {scheduler_job.py:1262} INFO - Processing process_replies
[2020-01-20 13:00:48,392] {scheduler_job.py:440} INFO - Skipping SLA check for <DAG: process_replies> because no tasks in DAG have SLAs
[2020-01-20 13:00:48,394] {scheduler_job.py:161} INFO - Processing /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py took 0.149 seconds
[2020-01-20 13:01:32,382] {scheduler_job.py:153} INFO - Started process (PID=2959) to work on /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 13:01:32,391] {scheduler_job.py:1539} INFO - Processing file /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py for tasks to queue
[2020-01-20 13:01:32,391] {logging_mixin.py:112} INFO - [2020-01-20 13:01:32,391] {dagbag.py:403} INFO - Filling up the DagBag from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 13:01:32,889] {scheduler_job.py:1551} INFO - DAG(s) dict_keys(['process_replies']) retrieved from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 13:01:32,911] {scheduler_job.py:1262} INFO - Processing process_replies
[2020-01-20 13:01:32,924] {scheduler_job.py:740} INFO - Examining DAG run <DagRun process_replies @ 2020-01-20 07:31:10.916072+00:00: manual__2020-01-20T07:31:10.916072+00:00, externally triggered: True>
[2020-01-20 13:01:32,949] {scheduler_job.py:440} INFO - Skipping SLA check for <DAG: process_replies> because no tasks in DAG have SLAs
[2020-01-20 13:01:32,957] {scheduler_job.py:1613} INFO - Creating / updating <TaskInstance: process_replies.send_replies 2020-01-20 07:31:10.916072+00:00 [scheduled]> in ORM
[2020-01-20 13:01:32,966] {scheduler_job.py:161} INFO - Processing /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py took 0.585 seconds
[2020-01-20 13:02:29,320] {scheduler_job.py:153} INFO - Started process (PID=2993) to work on /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 13:02:29,329] {scheduler_job.py:1539} INFO - Processing file /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py for tasks to queue
[2020-01-20 13:02:29,330] {logging_mixin.py:112} INFO - [2020-01-20 13:02:29,330] {dagbag.py:403} INFO - Filling up the DagBag from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 13:02:29,522] {scheduler_job.py:1551} INFO - DAG(s) dict_keys(['process_replies']) retrieved from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 13:02:29,547] {scheduler_job.py:1262} INFO - Processing process_replies
[2020-01-20 13:02:29,554] {scheduler_job.py:740} INFO - Examining DAG run <DagRun process_replies @ 2020-01-20 07:31:10.916072+00:00: manual__2020-01-20T07:31:10.916072+00:00, externally triggered: True>
[2020-01-20 13:02:29,562] {logging_mixin.py:112} INFO - [2020-01-20 13:02:29,561] {dagrun.py:318} INFO - Marking run <DagRun process_replies @ 2020-01-20 07:31:10.916072+00:00: manual__2020-01-20T07:31:10.916072+00:00, externally triggered: True> successful
[2020-01-20 13:02:29,567] {scheduler_job.py:440} INFO - Skipping SLA check for <DAG: process_replies> because no tasks in DAG have SLAs
[2020-01-20 13:02:29,570] {scheduler_job.py:161} INFO - Processing /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py took 0.250 seconds
[2020-01-20 13:04:02,515] {scheduler_job.py:153} INFO - Started process (PID=3049) to work on /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 13:04:02,525] {scheduler_job.py:1539} INFO - Processing file /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py for tasks to queue
[2020-01-20 13:04:02,526] {logging_mixin.py:112} INFO - [2020-01-20 13:04:02,526] {dagbag.py:403} INFO - Filling up the DagBag from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 13:04:02,583] {scheduler_job.py:1551} INFO - DAG(s) dict_keys(['process_replies']) retrieved from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 13:04:02,606] {scheduler_job.py:1262} INFO - Processing process_replies
[2020-01-20 13:04:02,615] {scheduler_job.py:740} INFO - Examining DAG run <DagRun process_replies @ 2020-01-20 07:33:34.276367+00:00: manual__2020-01-20T07:33:34.276367+00:00, externally triggered: True>
[2020-01-20 13:04:02,626] {scheduler_job.py:440} INFO - Skipping SLA check for <DAG: process_replies> because no tasks in DAG have SLAs
[2020-01-20 13:04:02,629] {scheduler_job.py:1613} INFO - Creating / updating <TaskInstance: process_replies.send_replies 2020-01-20 07:33:34.276367+00:00 [scheduled]> in ORM
[2020-01-20 13:04:02,636] {scheduler_job.py:161} INFO - Processing /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py took 0.121 seconds
[2020-01-20 13:04:57,529] {scheduler_job.py:153} INFO - Started process (PID=3080) to work on /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 13:04:57,536] {scheduler_job.py:1539} INFO - Processing file /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py for tasks to queue
[2020-01-20 13:04:57,537] {logging_mixin.py:112} INFO - [2020-01-20 13:04:57,537] {dagbag.py:403} INFO - Filling up the DagBag from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 13:04:57,750] {scheduler_job.py:1551} INFO - DAG(s) dict_keys(['process_replies']) retrieved from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 13:04:57,781] {scheduler_job.py:1262} INFO - Processing process_replies
[2020-01-20 13:04:57,789] {scheduler_job.py:740} INFO - Examining DAG run <DagRun process_replies @ 2020-01-20 07:33:34.276367+00:00: manual__2020-01-20T07:33:34.276367+00:00, externally triggered: True>
[2020-01-20 13:04:57,799] {logging_mixin.py:112} INFO - [2020-01-20 13:04:57,799] {dagrun.py:318} INFO - Marking run <DagRun process_replies @ 2020-01-20 07:33:34.276367+00:00: manual__2020-01-20T07:33:34.276367+00:00, externally triggered: True> successful
[2020-01-20 13:04:57,803] {scheduler_job.py:440} INFO - Skipping SLA check for <DAG: process_replies> because no tasks in DAG have SLAs
[2020-01-20 13:04:57,805] {scheduler_job.py:161} INFO - Processing /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py took 0.276 seconds
[2020-01-20 13:05:41,678] {scheduler_job.py:153} INFO - Started process (PID=3108) to work on /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 13:05:41,691] {scheduler_job.py:1539} INFO - Processing file /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py for tasks to queue
[2020-01-20 13:05:41,693] {logging_mixin.py:112} INFO - [2020-01-20 13:05:41,692] {dagbag.py:403} INFO - Filling up the DagBag from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 13:05:42,135] {scheduler_job.py:1551} INFO - DAG(s) dict_keys(['process_replies']) retrieved from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 13:05:42,162] {scheduler_job.py:1262} INFO - Processing process_replies
[2020-01-20 13:05:42,172] {scheduler_job.py:440} INFO - Skipping SLA check for <DAG: process_replies> because no tasks in DAG have SLAs
[2020-01-20 13:05:42,175] {scheduler_job.py:161} INFO - Processing /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py took 0.496 seconds
[2020-01-20 13:06:25,779] {scheduler_job.py:153} INFO - Started process (PID=3139) to work on /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 13:06:25,785] {scheduler_job.py:1539} INFO - Processing file /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py for tasks to queue
[2020-01-20 13:06:25,786] {logging_mixin.py:112} INFO - [2020-01-20 13:06:25,785] {dagbag.py:403} INFO - Filling up the DagBag from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 13:06:25,855] {scheduler_job.py:1551} INFO - DAG(s) dict_keys(['process_replies']) retrieved from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 13:06:25,874] {scheduler_job.py:1262} INFO - Processing process_replies
[2020-01-20 13:06:25,881] {scheduler_job.py:440} INFO - Skipping SLA check for <DAG: process_replies> because no tasks in DAG have SLAs
[2020-01-20 13:06:25,884] {scheduler_job.py:161} INFO - Processing /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py took 0.105 seconds
[2020-01-20 13:07:09,919] {scheduler_job.py:153} INFO - Started process (PID=3175) to work on /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 13:07:09,935] {scheduler_job.py:1539} INFO - Processing file /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py for tasks to queue
[2020-01-20 13:07:09,936] {logging_mixin.py:112} INFO - [2020-01-20 13:07:09,935] {dagbag.py:403} INFO - Filling up the DagBag from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 13:07:10,253] {scheduler_job.py:1551} INFO - DAG(s) dict_keys(['process_replies']) retrieved from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 13:07:10,348] {scheduler_job.py:1262} INFO - Processing process_replies
[2020-01-20 13:07:10,367] {scheduler_job.py:440} INFO - Skipping SLA check for <DAG: process_replies> because no tasks in DAG have SLAs
[2020-01-20 13:07:10,381] {scheduler_job.py:161} INFO - Processing /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py took 0.462 seconds
[2020-01-20 13:07:54,930] {scheduler_job.py:153} INFO - Started process (PID=3224) to work on /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 13:07:54,940] {scheduler_job.py:1539} INFO - Processing file /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py for tasks to queue
[2020-01-20 13:07:54,941] {logging_mixin.py:112} INFO - [2020-01-20 13:07:54,941] {dagbag.py:403} INFO - Filling up the DagBag from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 13:07:55,103] {scheduler_job.py:1551} INFO - DAG(s) dict_keys(['process_replies']) retrieved from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 13:07:55,129] {scheduler_job.py:1262} INFO - Processing process_replies
[2020-01-20 13:07:55,137] {scheduler_job.py:740} INFO - Examining DAG run <DagRun process_replies @ 2020-01-20 07:37:51.501024+00:00: manual__2020-01-20T07:37:51.501024+00:00, externally triggered: True>
[2020-01-20 13:07:55,151] {scheduler_job.py:440} INFO - Skipping SLA check for <DAG: process_replies> because no tasks in DAG have SLAs
[2020-01-20 13:07:55,154] {scheduler_job.py:1613} INFO - Creating / updating <TaskInstance: process_replies.send_replies 2020-01-20 07:37:51.501024+00:00 [scheduled]> in ORM
[2020-01-20 13:07:55,165] {scheduler_job.py:161} INFO - Processing /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py took 0.234 seconds
[2020-01-20 13:08:52,864] {scheduler_job.py:153} INFO - Started process (PID=3261) to work on /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 13:08:52,876] {scheduler_job.py:1539} INFO - Processing file /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py for tasks to queue
[2020-01-20 13:08:52,877] {logging_mixin.py:112} INFO - [2020-01-20 13:08:52,877] {dagbag.py:403} INFO - Filling up the DagBag from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 13:08:52,949] {scheduler_job.py:1551} INFO - DAG(s) dict_keys(['process_replies']) retrieved from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 13:08:52,981] {scheduler_job.py:1262} INFO - Processing process_replies
[2020-01-20 13:08:52,992] {scheduler_job.py:740} INFO - Examining DAG run <DagRun process_replies @ 2020-01-20 07:37:51.501024+00:00: manual__2020-01-20T07:37:51.501024+00:00, externally triggered: True>
[2020-01-20 13:08:53,004] {logging_mixin.py:112} INFO - [2020-01-20 13:08:53,003] {dagrun.py:318} INFO - Marking run <DagRun process_replies @ 2020-01-20 07:37:51.501024+00:00: manual__2020-01-20T07:37:51.501024+00:00, externally triggered: True> successful
[2020-01-20 13:08:53,007] {scheduler_job.py:440} INFO - Skipping SLA check for <DAG: process_replies> because no tasks in DAG have SLAs
[2020-01-20 13:08:53,011] {scheduler_job.py:161} INFO - Processing /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py took 0.147 seconds
[2020-01-20 13:09:37,006] {scheduler_job.py:153} INFO - Started process (PID=3284) to work on /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 13:09:37,016] {scheduler_job.py:1539} INFO - Processing file /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py for tasks to queue
[2020-01-20 13:09:37,016] {logging_mixin.py:112} INFO - [2020-01-20 13:09:37,016] {dagbag.py:403} INFO - Filling up the DagBag from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 13:09:37,075] {scheduler_job.py:1551} INFO - DAG(s) dict_keys(['process_replies']) retrieved from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 13:09:37,097] {scheduler_job.py:1262} INFO - Processing process_replies
[2020-01-20 13:09:37,104] {scheduler_job.py:440} INFO - Skipping SLA check for <DAG: process_replies> because no tasks in DAG have SLAs
[2020-01-20 13:09:37,107] {scheduler_job.py:161} INFO - Processing /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py took 0.101 seconds
[2020-01-20 13:10:21,124] {scheduler_job.py:153} INFO - Started process (PID=3312) to work on /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 13:10:21,144] {scheduler_job.py:1539} INFO - Processing file /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py for tasks to queue
[2020-01-20 13:10:21,147] {logging_mixin.py:112} INFO - [2020-01-20 13:10:21,147] {dagbag.py:403} INFO - Filling up the DagBag from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 13:10:21,232] {scheduler_job.py:1551} INFO - DAG(s) dict_keys(['process_replies']) retrieved from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 13:10:21,257] {scheduler_job.py:1262} INFO - Processing process_replies
[2020-01-20 13:10:21,267] {scheduler_job.py:440} INFO - Skipping SLA check for <DAG: process_replies> because no tasks in DAG have SLAs
[2020-01-20 13:10:21,271] {scheduler_job.py:161} INFO - Processing /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py took 0.148 seconds
[2020-01-20 13:11:05,246] {scheduler_job.py:153} INFO - Started process (PID=3339) to work on /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 13:11:05,256] {scheduler_job.py:1539} INFO - Processing file /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py for tasks to queue
[2020-01-20 13:11:05,257] {logging_mixin.py:112} INFO - [2020-01-20 13:11:05,257] {dagbag.py:403} INFO - Filling up the DagBag from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 13:11:05,327] {scheduler_job.py:1551} INFO - DAG(s) dict_keys(['process_replies']) retrieved from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 13:11:05,347] {scheduler_job.py:1262} INFO - Processing process_replies
[2020-01-20 13:11:05,354] {scheduler_job.py:440} INFO - Skipping SLA check for <DAG: process_replies> because no tasks in DAG have SLAs
[2020-01-20 13:11:05,357] {scheduler_job.py:161} INFO - Processing /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py took 0.111 seconds
[2020-01-20 13:11:49,378] {scheduler_job.py:153} INFO - Started process (PID=3363) to work on /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 13:11:49,394] {scheduler_job.py:1539} INFO - Processing file /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py for tasks to queue
[2020-01-20 13:11:49,395] {logging_mixin.py:112} INFO - [2020-01-20 13:11:49,395] {dagbag.py:403} INFO - Filling up the DagBag from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 13:11:49,467] {scheduler_job.py:1551} INFO - DAG(s) dict_keys(['process_replies']) retrieved from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 13:11:49,489] {scheduler_job.py:1262} INFO - Processing process_replies
[2020-01-20 13:11:49,498] {scheduler_job.py:440} INFO - Skipping SLA check for <DAG: process_replies> because no tasks in DAG have SLAs
[2020-01-20 13:11:49,502] {scheduler_job.py:161} INFO - Processing /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py took 0.124 seconds
[2020-01-20 13:12:33,523] {scheduler_job.py:153} INFO - Started process (PID=3393) to work on /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 13:12:33,535] {scheduler_job.py:1539} INFO - Processing file /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py for tasks to queue
[2020-01-20 13:12:33,536] {logging_mixin.py:112} INFO - [2020-01-20 13:12:33,535] {dagbag.py:403} INFO - Filling up the DagBag from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 13:12:33,614] {scheduler_job.py:1551} INFO - DAG(s) dict_keys(['process_replies']) retrieved from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 13:12:33,638] {scheduler_job.py:1262} INFO - Processing process_replies
[2020-01-20 13:12:33,650] {scheduler_job.py:440} INFO - Skipping SLA check for <DAG: process_replies> because no tasks in DAG have SLAs
[2020-01-20 13:12:33,652] {scheduler_job.py:161} INFO - Processing /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py took 0.129 seconds
[2020-01-20 13:13:17,591] {scheduler_job.py:153} INFO - Started process (PID=3425) to work on /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 13:13:17,601] {scheduler_job.py:1539} INFO - Processing file /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py for tasks to queue
[2020-01-20 13:13:17,602] {logging_mixin.py:112} INFO - [2020-01-20 13:13:17,602] {dagbag.py:403} INFO - Filling up the DagBag from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 13:13:17,754] {scheduler_job.py:1551} INFO - DAG(s) dict_keys(['process_replies']) retrieved from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 13:13:17,777] {scheduler_job.py:1262} INFO - Processing process_replies
[2020-01-20 13:13:17,784] {scheduler_job.py:740} INFO - Examining DAG run <DagRun process_replies @ 2020-01-20 07:43:09.537707+00:00: manual__2020-01-20T07:43:09.537707+00:00, externally triggered: True>
[2020-01-20 13:13:17,799] {scheduler_job.py:440} INFO - Skipping SLA check for <DAG: process_replies> because no tasks in DAG have SLAs
[2020-01-20 13:13:17,805] {scheduler_job.py:1613} INFO - Creating / updating <TaskInstance: process_replies.send_replies 2020-01-20 07:43:09.537707+00:00 [scheduled]> in ORM
[2020-01-20 13:13:17,813] {scheduler_job.py:161} INFO - Processing /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py took 0.222 seconds
[2020-01-20 13:14:16,493] {scheduler_job.py:153} INFO - Started process (PID=3460) to work on /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 13:14:16,500] {scheduler_job.py:1539} INFO - Processing file /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py for tasks to queue
[2020-01-20 13:14:16,502] {logging_mixin.py:112} INFO - [2020-01-20 13:14:16,501] {dagbag.py:403} INFO - Filling up the DagBag from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 13:14:16,635] {scheduler_job.py:1551} INFO - DAG(s) dict_keys(['process_replies']) retrieved from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 13:14:16,656] {scheduler_job.py:1262} INFO - Processing process_replies
[2020-01-20 13:14:16,670] {scheduler_job.py:740} INFO - Examining DAG run <DagRun process_replies @ 2020-01-20 07:43:09.537707+00:00: manual__2020-01-20T07:43:09.537707+00:00, externally triggered: True>
[2020-01-20 13:14:16,683] {logging_mixin.py:112} INFO - [2020-01-20 13:14:16,682] {dagrun.py:318} INFO - Marking run <DagRun process_replies @ 2020-01-20 07:43:09.537707+00:00: manual__2020-01-20T07:43:09.537707+00:00, externally triggered: True> successful
[2020-01-20 13:14:16,688] {scheduler_job.py:440} INFO - Skipping SLA check for <DAG: process_replies> because no tasks in DAG have SLAs
[2020-01-20 13:14:16,693] {scheduler_job.py:161} INFO - Processing /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py took 0.200 seconds
[2020-01-20 13:15:00,616] {scheduler_job.py:153} INFO - Started process (PID=3486) to work on /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 13:15:00,624] {scheduler_job.py:1539} INFO - Processing file /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py for tasks to queue
[2020-01-20 13:15:00,626] {logging_mixin.py:112} INFO - [2020-01-20 13:15:00,625] {dagbag.py:403} INFO - Filling up the DagBag from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 13:15:00,675] {scheduler_job.py:1551} INFO - DAG(s) dict_keys(['process_replies']) retrieved from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 13:15:00,699] {scheduler_job.py:1262} INFO - Processing process_replies
[2020-01-20 13:15:00,706] {scheduler_job.py:440} INFO - Skipping SLA check for <DAG: process_replies> because no tasks in DAG have SLAs
[2020-01-20 13:15:00,708] {scheduler_job.py:161} INFO - Processing /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py took 0.093 seconds
[2020-01-20 13:15:44,728] {scheduler_job.py:153} INFO - Started process (PID=3522) to work on /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 13:15:44,735] {scheduler_job.py:1539} INFO - Processing file /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py for tasks to queue
[2020-01-20 13:15:44,736] {logging_mixin.py:112} INFO - [2020-01-20 13:15:44,736] {dagbag.py:403} INFO - Filling up the DagBag from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 13:15:44,804] {scheduler_job.py:1551} INFO - DAG(s) dict_keys(['process_replies']) retrieved from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 13:15:44,824] {scheduler_job.py:1262} INFO - Processing process_replies
[2020-01-20 13:15:44,832] {scheduler_job.py:440} INFO - Skipping SLA check for <DAG: process_replies> because no tasks in DAG have SLAs
[2020-01-20 13:15:44,837] {scheduler_job.py:161} INFO - Processing /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py took 0.108 seconds
[2020-01-20 13:16:28,870] {scheduler_job.py:153} INFO - Started process (PID=3548) to work on /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 13:16:28,880] {scheduler_job.py:1539} INFO - Processing file /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py for tasks to queue
[2020-01-20 13:16:28,881] {logging_mixin.py:112} INFO - [2020-01-20 13:16:28,880] {dagbag.py:403} INFO - Filling up the DagBag from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 13:16:28,949] {scheduler_job.py:1551} INFO - DAG(s) dict_keys(['process_replies']) retrieved from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 13:16:28,970] {scheduler_job.py:1262} INFO - Processing process_replies
[2020-01-20 13:16:28,980] {scheduler_job.py:740} INFO - Examining DAG run <DagRun process_replies @ 2020-01-20 07:46:10.732932+00:00: manual__2020-01-20T07:46:10.732932+00:00, externally triggered: True>
[2020-01-20 13:16:28,994] {scheduler_job.py:440} INFO - Skipping SLA check for <DAG: process_replies> because no tasks in DAG have SLAs
[2020-01-20 13:16:29,000] {scheduler_job.py:1613} INFO - Creating / updating <TaskInstance: process_replies.send_replies 2020-01-20 07:46:10.732932+00:00 [scheduled]> in ORM
[2020-01-20 13:16:29,010] {scheduler_job.py:161} INFO - Processing /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py took 0.141 seconds
[2020-01-20 13:17:25,396] {scheduler_job.py:153} INFO - Started process (PID=3582) to work on /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 13:17:25,405] {scheduler_job.py:1539} INFO - Processing file /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py for tasks to queue
[2020-01-20 13:17:25,407] {logging_mixin.py:112} INFO - [2020-01-20 13:17:25,406] {dagbag.py:403} INFO - Filling up the DagBag from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 13:17:25,615] {scheduler_job.py:1551} INFO - DAG(s) dict_keys(['process_replies']) retrieved from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 13:17:25,637] {scheduler_job.py:1262} INFO - Processing process_replies
[2020-01-20 13:17:25,645] {scheduler_job.py:740} INFO - Examining DAG run <DagRun process_replies @ 2020-01-20 07:46:10.732932+00:00: manual__2020-01-20T07:46:10.732932+00:00, externally triggered: True>
[2020-01-20 13:17:25,654] {logging_mixin.py:112} INFO - [2020-01-20 13:17:25,654] {dagrun.py:309} INFO - Marking run <DagRun process_replies @ 2020-01-20 07:46:10.732932+00:00: manual__2020-01-20T07:46:10.732932+00:00, externally triggered: True> failed
[2020-01-20 13:17:25,657] {scheduler_job.py:440} INFO - Skipping SLA check for <DAG: process_replies> because no tasks in DAG have SLAs
[2020-01-20 13:17:25,659] {scheduler_job.py:161} INFO - Processing /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py took 0.263 seconds
[2020-01-20 13:18:09,515] {scheduler_job.py:153} INFO - Started process (PID=3611) to work on /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 13:18:09,522] {scheduler_job.py:1539} INFO - Processing file /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py for tasks to queue
[2020-01-20 13:18:09,523] {logging_mixin.py:112} INFO - [2020-01-20 13:18:09,523] {dagbag.py:403} INFO - Filling up the DagBag from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 13:18:09,687] {scheduler_job.py:1551} INFO - DAG(s) dict_keys(['process_replies']) retrieved from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 13:18:09,707] {scheduler_job.py:1262} INFO - Processing process_replies
[2020-01-20 13:18:09,714] {scheduler_job.py:440} INFO - Skipping SLA check for <DAG: process_replies> because no tasks in DAG have SLAs
[2020-01-20 13:18:09,717] {scheduler_job.py:161} INFO - Processing /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py took 0.202 seconds
[2020-01-20 13:18:53,642] {scheduler_job.py:153} INFO - Started process (PID=3639) to work on /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 13:18:53,653] {scheduler_job.py:1539} INFO - Processing file /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py for tasks to queue
[2020-01-20 13:18:53,654] {logging_mixin.py:112} INFO - [2020-01-20 13:18:53,654] {dagbag.py:403} INFO - Filling up the DagBag from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 13:18:53,708] {scheduler_job.py:1551} INFO - DAG(s) dict_keys(['process_replies']) retrieved from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 13:18:53,731] {scheduler_job.py:1262} INFO - Processing process_replies
[2020-01-20 13:18:53,739] {scheduler_job.py:440} INFO - Skipping SLA check for <DAG: process_replies> because no tasks in DAG have SLAs
[2020-01-20 13:18:53,741] {scheduler_job.py:161} INFO - Processing /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py took 0.099 seconds
[2020-01-20 13:19:37,816] {scheduler_job.py:153} INFO - Started process (PID=3665) to work on /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 13:19:37,824] {scheduler_job.py:1539} INFO - Processing file /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py for tasks to queue
[2020-01-20 13:19:37,825] {logging_mixin.py:112} INFO - [2020-01-20 13:19:37,825] {dagbag.py:403} INFO - Filling up the DagBag from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 13:19:37,955] {scheduler_job.py:1551} INFO - DAG(s) dict_keys(['process_replies']) retrieved from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 13:19:37,976] {scheduler_job.py:1262} INFO - Processing process_replies
[2020-01-20 13:19:37,983] {scheduler_job.py:440} INFO - Skipping SLA check for <DAG: process_replies> because no tasks in DAG have SLAs
[2020-01-20 13:19:37,986] {scheduler_job.py:161} INFO - Processing /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py took 0.169 seconds
[2020-01-20 13:20:21,937] {scheduler_job.py:153} INFO - Started process (PID=3696) to work on /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 13:20:21,944] {scheduler_job.py:1539} INFO - Processing file /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py for tasks to queue
[2020-01-20 13:20:21,945] {logging_mixin.py:112} INFO - [2020-01-20 13:20:21,944] {dagbag.py:403} INFO - Filling up the DagBag from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 13:20:22,072] {scheduler_job.py:1551} INFO - DAG(s) dict_keys(['process_replies']) retrieved from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 13:20:22,092] {scheduler_job.py:1262} INFO - Processing process_replies
[2020-01-20 13:20:22,099] {scheduler_job.py:440} INFO - Skipping SLA check for <DAG: process_replies> because no tasks in DAG have SLAs
[2020-01-20 13:20:22,102] {scheduler_job.py:161} INFO - Processing /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py took 0.165 seconds
[2020-01-20 13:21:06,050] {scheduler_job.py:153} INFO - Started process (PID=3725) to work on /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 13:21:06,059] {scheduler_job.py:1539} INFO - Processing file /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py for tasks to queue
[2020-01-20 13:21:06,061] {logging_mixin.py:112} INFO - [2020-01-20 13:21:06,060] {dagbag.py:403} INFO - Filling up the DagBag from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 13:21:06,159] {scheduler_job.py:1551} INFO - DAG(s) dict_keys(['process_replies']) retrieved from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 13:21:06,184] {scheduler_job.py:1262} INFO - Processing process_replies
[2020-01-20 13:21:06,195] {scheduler_job.py:440} INFO - Skipping SLA check for <DAG: process_replies> because no tasks in DAG have SLAs
[2020-01-20 13:21:06,197] {scheduler_job.py:161} INFO - Processing /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py took 0.147 seconds
[2020-01-20 13:21:50,167] {scheduler_job.py:153} INFO - Started process (PID=3749) to work on /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 13:21:50,175] {scheduler_job.py:1539} INFO - Processing file /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py for tasks to queue
[2020-01-20 13:21:50,176] {logging_mixin.py:112} INFO - [2020-01-20 13:21:50,176] {dagbag.py:403} INFO - Filling up the DagBag from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 13:21:50,228] {scheduler_job.py:1551} INFO - DAG(s) dict_keys(['process_replies']) retrieved from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 13:21:50,250] {scheduler_job.py:1262} INFO - Processing process_replies
[2020-01-20 13:21:50,257] {scheduler_job.py:440} INFO - Skipping SLA check for <DAG: process_replies> because no tasks in DAG have SLAs
[2020-01-20 13:21:50,259] {scheduler_job.py:161} INFO - Processing /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py took 0.093 seconds
[2020-01-20 13:22:34,274] {scheduler_job.py:153} INFO - Started process (PID=3781) to work on /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 13:22:34,283] {scheduler_job.py:1539} INFO - Processing file /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py for tasks to queue
[2020-01-20 13:22:34,284] {logging_mixin.py:112} INFO - [2020-01-20 13:22:34,284] {dagbag.py:403} INFO - Filling up the DagBag from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 13:22:34,343] {scheduler_job.py:1551} INFO - DAG(s) dict_keys(['process_replies']) retrieved from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 13:22:34,366] {scheduler_job.py:1262} INFO - Processing process_replies
[2020-01-20 13:22:34,374] {scheduler_job.py:440} INFO - Skipping SLA check for <DAG: process_replies> because no tasks in DAG have SLAs
[2020-01-20 13:22:34,377] {scheduler_job.py:161} INFO - Processing /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py took 0.103 seconds
[2020-01-20 13:23:18,380] {scheduler_job.py:153} INFO - Started process (PID=3809) to work on /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 13:23:18,390] {scheduler_job.py:1539} INFO - Processing file /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py for tasks to queue
[2020-01-20 13:23:18,391] {logging_mixin.py:112} INFO - [2020-01-20 13:23:18,390] {dagbag.py:403} INFO - Filling up the DagBag from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 13:23:18,474] {scheduler_job.py:1551} INFO - DAG(s) dict_keys(['process_replies']) retrieved from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 13:23:18,500] {scheduler_job.py:1262} INFO - Processing process_replies
[2020-01-20 13:23:18,508] {scheduler_job.py:440} INFO - Skipping SLA check for <DAG: process_replies> because no tasks in DAG have SLAs
[2020-01-20 13:23:18,510] {scheduler_job.py:161} INFO - Processing /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py took 0.131 seconds
[2020-01-20 13:24:02,494] {scheduler_job.py:153} INFO - Started process (PID=3832) to work on /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 13:24:02,503] {scheduler_job.py:1539} INFO - Processing file /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py for tasks to queue
[2020-01-20 13:24:02,504] {logging_mixin.py:112} INFO - [2020-01-20 13:24:02,504] {dagbag.py:403} INFO - Filling up the DagBag from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 13:24:02,577] {scheduler_job.py:1551} INFO - DAG(s) dict_keys(['process_replies']) retrieved from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 13:24:02,603] {scheduler_job.py:1262} INFO - Processing process_replies
[2020-01-20 13:24:02,616] {scheduler_job.py:440} INFO - Skipping SLA check for <DAG: process_replies> because no tasks in DAG have SLAs
[2020-01-20 13:24:02,619] {scheduler_job.py:161} INFO - Processing /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py took 0.125 seconds
[2020-01-20 13:24:46,616] {scheduler_job.py:153} INFO - Started process (PID=3865) to work on /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 13:24:46,624] {scheduler_job.py:1539} INFO - Processing file /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py for tasks to queue
[2020-01-20 13:24:46,625] {logging_mixin.py:112} INFO - [2020-01-20 13:24:46,625] {dagbag.py:403} INFO - Filling up the DagBag from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 13:24:46,756] {scheduler_job.py:1551} INFO - DAG(s) dict_keys(['process_replies']) retrieved from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 13:24:46,789] {scheduler_job.py:1262} INFO - Processing process_replies
[2020-01-20 13:24:46,811] {scheduler_job.py:440} INFO - Skipping SLA check for <DAG: process_replies> because no tasks in DAG have SLAs
[2020-01-20 13:24:46,821] {scheduler_job.py:161} INFO - Processing /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py took 0.205 seconds
[2020-01-20 13:25:30,712] {scheduler_job.py:153} INFO - Started process (PID=3893) to work on /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 13:25:30,722] {scheduler_job.py:1539} INFO - Processing file /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py for tasks to queue
[2020-01-20 13:25:30,724] {logging_mixin.py:112} INFO - [2020-01-20 13:25:30,723] {dagbag.py:403} INFO - Filling up the DagBag from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 13:25:30,794] {scheduler_job.py:1551} INFO - DAG(s) dict_keys(['process_replies']) retrieved from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 13:25:30,817] {scheduler_job.py:1262} INFO - Processing process_replies
[2020-01-20 13:25:30,826] {scheduler_job.py:440} INFO - Skipping SLA check for <DAG: process_replies> because no tasks in DAG have SLAs
[2020-01-20 13:25:30,829] {scheduler_job.py:161} INFO - Processing /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py took 0.117 seconds
[2020-01-20 13:26:14,840] {scheduler_job.py:153} INFO - Started process (PID=3923) to work on /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 13:26:14,845] {scheduler_job.py:1539} INFO - Processing file /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py for tasks to queue
[2020-01-20 13:26:14,846] {logging_mixin.py:112} INFO - [2020-01-20 13:26:14,846] {dagbag.py:403} INFO - Filling up the DagBag from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 13:26:15,438] {scheduler_job.py:1551} INFO - DAG(s) dict_keys(['process_replies']) retrieved from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 13:26:15,460] {scheduler_job.py:1262} INFO - Processing process_replies
[2020-01-20 13:26:15,471] {scheduler_job.py:440} INFO - Skipping SLA check for <DAG: process_replies> because no tasks in DAG have SLAs
[2020-01-20 13:26:15,474] {scheduler_job.py:161} INFO - Processing /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py took 0.634 seconds
[2020-01-20 13:26:58,961] {scheduler_job.py:153} INFO - Started process (PID=3957) to work on /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 13:26:58,975] {scheduler_job.py:1539} INFO - Processing file /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py for tasks to queue
[2020-01-20 13:26:58,976] {logging_mixin.py:112} INFO - [2020-01-20 13:26:58,976] {dagbag.py:403} INFO - Filling up the DagBag from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 13:26:59,060] {scheduler_job.py:1551} INFO - DAG(s) dict_keys(['process_replies']) retrieved from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 13:26:59,101] {scheduler_job.py:1262} INFO - Processing process_replies
[2020-01-20 13:26:59,110] {scheduler_job.py:440} INFO - Skipping SLA check for <DAG: process_replies> because no tasks in DAG have SLAs
[2020-01-20 13:26:59,113] {scheduler_job.py:161} INFO - Processing /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py took 0.152 seconds
[2020-01-20 13:27:43,067] {scheduler_job.py:153} INFO - Started process (PID=3997) to work on /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 13:27:43,075] {scheduler_job.py:1539} INFO - Processing file /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py for tasks to queue
[2020-01-20 13:27:43,076] {logging_mixin.py:112} INFO - [2020-01-20 13:27:43,075] {dagbag.py:403} INFO - Filling up the DagBag from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 13:27:43,237] {scheduler_job.py:1551} INFO - DAG(s) dict_keys(['process_replies']) retrieved from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 13:27:43,257] {scheduler_job.py:1262} INFO - Processing process_replies
[2020-01-20 13:27:43,264] {scheduler_job.py:440} INFO - Skipping SLA check for <DAG: process_replies> because no tasks in DAG have SLAs
[2020-01-20 13:27:43,266] {scheduler_job.py:161} INFO - Processing /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py took 0.199 seconds
[2020-01-20 13:28:27,177] {scheduler_job.py:153} INFO - Started process (PID=4030) to work on /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 13:28:27,191] {scheduler_job.py:1539} INFO - Processing file /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py for tasks to queue
[2020-01-20 13:28:27,192] {logging_mixin.py:112} INFO - [2020-01-20 13:28:27,192] {dagbag.py:403} INFO - Filling up the DagBag from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 13:28:27,270] {scheduler_job.py:1551} INFO - DAG(s) dict_keys(['process_replies']) retrieved from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 13:28:27,319] {scheduler_job.py:1262} INFO - Processing process_replies
[2020-01-20 13:28:27,338] {scheduler_job.py:440} INFO - Skipping SLA check for <DAG: process_replies> because no tasks in DAG have SLAs
[2020-01-20 13:28:27,342] {scheduler_job.py:161} INFO - Processing /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py took 0.165 seconds
[2020-01-20 13:29:11,297] {scheduler_job.py:153} INFO - Started process (PID=4057) to work on /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 13:29:11,303] {scheduler_job.py:1539} INFO - Processing file /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py for tasks to queue
[2020-01-20 13:29:11,304] {logging_mixin.py:112} INFO - [2020-01-20 13:29:11,304] {dagbag.py:403} INFO - Filling up the DagBag from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 13:29:11,360] {scheduler_job.py:1551} INFO - DAG(s) dict_keys(['process_replies']) retrieved from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 13:29:11,379] {scheduler_job.py:1262} INFO - Processing process_replies
[2020-01-20 13:29:11,388] {scheduler_job.py:440} INFO - Skipping SLA check for <DAG: process_replies> because no tasks in DAG have SLAs
[2020-01-20 13:29:11,391] {scheduler_job.py:161} INFO - Processing /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py took 0.093 seconds
[2020-01-20 13:29:55,421] {scheduler_job.py:153} INFO - Started process (PID=4081) to work on /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 13:29:55,428] {scheduler_job.py:1539} INFO - Processing file /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py for tasks to queue
[2020-01-20 13:29:55,429] {logging_mixin.py:112} INFO - [2020-01-20 13:29:55,429] {dagbag.py:403} INFO - Filling up the DagBag from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 13:29:55,480] {scheduler_job.py:1551} INFO - DAG(s) dict_keys(['process_replies']) retrieved from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 13:29:55,502] {scheduler_job.py:1262} INFO - Processing process_replies
[2020-01-20 13:29:55,509] {scheduler_job.py:440} INFO - Skipping SLA check for <DAG: process_replies> because no tasks in DAG have SLAs
[2020-01-20 13:29:55,511] {scheduler_job.py:161} INFO - Processing /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py took 0.090 seconds
[2020-01-20 13:30:39,560] {scheduler_job.py:153} INFO - Started process (PID=4108) to work on /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 13:30:39,567] {scheduler_job.py:1539} INFO - Processing file /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py for tasks to queue
[2020-01-20 13:30:39,568] {logging_mixin.py:112} INFO - [2020-01-20 13:30:39,567] {dagbag.py:403} INFO - Filling up the DagBag from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 13:30:39,621] {scheduler_job.py:1551} INFO - DAG(s) dict_keys(['process_replies']) retrieved from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 13:30:39,641] {scheduler_job.py:1262} INFO - Processing process_replies
[2020-01-20 13:30:39,648] {scheduler_job.py:440} INFO - Skipping SLA check for <DAG: process_replies> because no tasks in DAG have SLAs
[2020-01-20 13:30:39,650] {scheduler_job.py:161} INFO - Processing /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py took 0.090 seconds
[2020-01-20 13:31:23,707] {scheduler_job.py:153} INFO - Started process (PID=4132) to work on /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 13:31:23,715] {scheduler_job.py:1539} INFO - Processing file /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py for tasks to queue
[2020-01-20 13:31:23,716] {logging_mixin.py:112} INFO - [2020-01-20 13:31:23,716] {dagbag.py:403} INFO - Filling up the DagBag from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 13:31:23,782] {scheduler_job.py:1551} INFO - DAG(s) dict_keys(['process_replies']) retrieved from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 13:31:23,801] {scheduler_job.py:1262} INFO - Processing process_replies
[2020-01-20 13:31:23,808] {scheduler_job.py:440} INFO - Skipping SLA check for <DAG: process_replies> because no tasks in DAG have SLAs
[2020-01-20 13:31:23,811] {scheduler_job.py:161} INFO - Processing /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py took 0.104 seconds
[2020-01-20 13:32:07,834] {scheduler_job.py:153} INFO - Started process (PID=4160) to work on /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 13:32:07,840] {scheduler_job.py:1539} INFO - Processing file /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py for tasks to queue
[2020-01-20 13:32:07,841] {logging_mixin.py:112} INFO - [2020-01-20 13:32:07,841] {dagbag.py:403} INFO - Filling up the DagBag from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 13:32:07,910] {scheduler_job.py:1551} INFO - DAG(s) dict_keys(['process_replies']) retrieved from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 13:32:07,930] {scheduler_job.py:1262} INFO - Processing process_replies
[2020-01-20 13:32:07,941] {scheduler_job.py:440} INFO - Skipping SLA check for <DAG: process_replies> because no tasks in DAG have SLAs
[2020-01-20 13:32:07,944] {scheduler_job.py:161} INFO - Processing /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py took 0.111 seconds
[2020-01-20 13:32:51,957] {scheduler_job.py:153} INFO - Started process (PID=4199) to work on /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 13:32:51,963] {scheduler_job.py:1539} INFO - Processing file /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py for tasks to queue
[2020-01-20 13:32:51,964] {logging_mixin.py:112} INFO - [2020-01-20 13:32:51,964] {dagbag.py:403} INFO - Filling up the DagBag from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 13:32:52,022] {scheduler_job.py:1551} INFO - DAG(s) dict_keys(['process_replies']) retrieved from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 13:32:52,045] {scheduler_job.py:1262} INFO - Processing process_replies
[2020-01-20 13:32:52,055] {scheduler_job.py:440} INFO - Skipping SLA check for <DAG: process_replies> because no tasks in DAG have SLAs
[2020-01-20 13:32:52,057] {scheduler_job.py:161} INFO - Processing /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py took 0.100 seconds
[2020-01-20 13:33:36,074] {scheduler_job.py:153} INFO - Started process (PID=4226) to work on /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 13:33:36,081] {scheduler_job.py:1539} INFO - Processing file /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py for tasks to queue
[2020-01-20 13:33:36,082] {logging_mixin.py:112} INFO - [2020-01-20 13:33:36,082] {dagbag.py:403} INFO - Filling up the DagBag from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 13:33:36,270] {scheduler_job.py:1551} INFO - DAG(s) dict_keys(['process_replies']) retrieved from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 13:33:36,291] {scheduler_job.py:1262} INFO - Processing process_replies
[2020-01-20 13:33:36,299] {scheduler_job.py:440} INFO - Skipping SLA check for <DAG: process_replies> because no tasks in DAG have SLAs
[2020-01-20 13:33:36,301] {scheduler_job.py:161} INFO - Processing /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py took 0.227 seconds
[2020-01-20 13:34:20,188] {scheduler_job.py:153} INFO - Started process (PID=4262) to work on /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 13:34:20,200] {scheduler_job.py:1539} INFO - Processing file /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py for tasks to queue
[2020-01-20 13:34:20,201] {logging_mixin.py:112} INFO - [2020-01-20 13:34:20,201] {dagbag.py:403} INFO - Filling up the DagBag from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 13:34:20,441] {scheduler_job.py:1551} INFO - DAG(s) dict_keys(['process_replies']) retrieved from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 13:34:20,471] {scheduler_job.py:1262} INFO - Processing process_replies
[2020-01-20 13:34:20,481] {scheduler_job.py:440} INFO - Skipping SLA check for <DAG: process_replies> because no tasks in DAG have SLAs
[2020-01-20 13:34:20,484] {scheduler_job.py:161} INFO - Processing /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py took 0.296 seconds
[2020-01-20 13:35:04,289] {scheduler_job.py:153} INFO - Started process (PID=4291) to work on /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 13:35:04,295] {scheduler_job.py:1539} INFO - Processing file /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py for tasks to queue
[2020-01-20 13:35:04,296] {logging_mixin.py:112} INFO - [2020-01-20 13:35:04,296] {dagbag.py:403} INFO - Filling up the DagBag from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 13:35:04,365] {scheduler_job.py:1551} INFO - DAG(s) dict_keys(['process_replies']) retrieved from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 13:35:04,395] {scheduler_job.py:1262} INFO - Processing process_replies
[2020-01-20 13:35:04,408] {scheduler_job.py:440} INFO - Skipping SLA check for <DAG: process_replies> because no tasks in DAG have SLAs
[2020-01-20 13:35:04,411] {scheduler_job.py:161} INFO - Processing /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py took 0.123 seconds
[2020-01-20 13:35:48,401] {scheduler_job.py:153} INFO - Started process (PID=4319) to work on /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 13:35:48,409] {scheduler_job.py:1539} INFO - Processing file /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py for tasks to queue
[2020-01-20 13:35:48,410] {logging_mixin.py:112} INFO - [2020-01-20 13:35:48,410] {dagbag.py:403} INFO - Filling up the DagBag from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 13:35:48,590] {scheduler_job.py:1551} INFO - DAG(s) dict_keys(['process_replies']) retrieved from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 13:35:48,615] {scheduler_job.py:1262} INFO - Processing process_replies
[2020-01-20 13:35:48,623] {scheduler_job.py:440} INFO - Skipping SLA check for <DAG: process_replies> because no tasks in DAG have SLAs
[2020-01-20 13:35:48,625] {scheduler_job.py:161} INFO - Processing /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py took 0.225 seconds
[2020-01-20 13:36:32,506] {scheduler_job.py:153} INFO - Started process (PID=4349) to work on /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 13:36:32,513] {scheduler_job.py:1539} INFO - Processing file /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py for tasks to queue
[2020-01-20 13:36:32,514] {logging_mixin.py:112} INFO - [2020-01-20 13:36:32,514] {dagbag.py:403} INFO - Filling up the DagBag from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 13:36:32,584] {scheduler_job.py:1551} INFO - DAG(s) dict_keys(['process_replies']) retrieved from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 13:36:32,614] {scheduler_job.py:1262} INFO - Processing process_replies
[2020-01-20 13:36:32,621] {scheduler_job.py:440} INFO - Skipping SLA check for <DAG: process_replies> because no tasks in DAG have SLAs
[2020-01-20 13:36:32,624] {scheduler_job.py:161} INFO - Processing /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py took 0.119 seconds
[2020-01-20 13:37:16,620] {scheduler_job.py:153} INFO - Started process (PID=4378) to work on /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 13:37:16,625] {scheduler_job.py:1539} INFO - Processing file /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py for tasks to queue
[2020-01-20 13:37:16,626] {logging_mixin.py:112} INFO - [2020-01-20 13:37:16,626] {dagbag.py:403} INFO - Filling up the DagBag from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 13:37:16,697] {scheduler_job.py:1551} INFO - DAG(s) dict_keys(['process_replies']) retrieved from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 13:37:16,720] {scheduler_job.py:1262} INFO - Processing process_replies
[2020-01-20 13:37:16,732] {scheduler_job.py:440} INFO - Skipping SLA check for <DAG: process_replies> because no tasks in DAG have SLAs
[2020-01-20 13:37:16,738] {scheduler_job.py:161} INFO - Processing /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py took 0.118 seconds
[2020-01-20 13:38:00,717] {scheduler_job.py:153} INFO - Started process (PID=4408) to work on /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 13:38:00,726] {scheduler_job.py:1539} INFO - Processing file /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py for tasks to queue
[2020-01-20 13:38:00,727] {logging_mixin.py:112} INFO - [2020-01-20 13:38:00,726] {dagbag.py:403} INFO - Filling up the DagBag from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 13:38:00,796] {scheduler_job.py:1551} INFO - DAG(s) dict_keys(['process_replies']) retrieved from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 13:38:00,817] {scheduler_job.py:1262} INFO - Processing process_replies
[2020-01-20 13:38:00,829] {scheduler_job.py:440} INFO - Skipping SLA check for <DAG: process_replies> because no tasks in DAG have SLAs
[2020-01-20 13:38:00,833] {scheduler_job.py:161} INFO - Processing /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py took 0.116 seconds
[2020-01-20 13:38:46,838] {scheduler_job.py:153} INFO - Started process (PID=4439) to work on /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 13:38:46,847] {scheduler_job.py:1539} INFO - Processing file /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py for tasks to queue
[2020-01-20 13:38:46,848] {logging_mixin.py:112} INFO - [2020-01-20 13:38:46,847] {dagbag.py:403} INFO - Filling up the DagBag from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 13:38:46,923] {scheduler_job.py:1551} INFO - DAG(s) dict_keys(['process_replies']) retrieved from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 13:38:46,942] {scheduler_job.py:1262} INFO - Processing process_replies
[2020-01-20 13:38:46,950] {scheduler_job.py:440} INFO - Skipping SLA check for <DAG: process_replies> because no tasks in DAG have SLAs
[2020-01-20 13:38:46,952] {scheduler_job.py:161} INFO - Processing /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py took 0.115 seconds
[2020-01-20 13:39:32,978] {scheduler_job.py:153} INFO - Started process (PID=4483) to work on /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 13:39:32,986] {scheduler_job.py:1539} INFO - Processing file /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py for tasks to queue
[2020-01-20 13:39:32,987] {logging_mixin.py:112} INFO - [2020-01-20 13:39:32,986] {dagbag.py:403} INFO - Filling up the DagBag from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 13:39:33,066] {scheduler_job.py:1551} INFO - DAG(s) dict_keys(['process_replies']) retrieved from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 13:39:33,088] {scheduler_job.py:1262} INFO - Processing process_replies
[2020-01-20 13:39:33,098] {scheduler_job.py:440} INFO - Skipping SLA check for <DAG: process_replies> because no tasks in DAG have SLAs
[2020-01-20 13:39:33,101] {scheduler_job.py:161} INFO - Processing /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py took 0.124 seconds
[2020-01-20 13:40:19,099] {scheduler_job.py:153} INFO - Started process (PID=4526) to work on /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 13:40:19,106] {scheduler_job.py:1539} INFO - Processing file /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py for tasks to queue
[2020-01-20 13:40:19,109] {logging_mixin.py:112} INFO - [2020-01-20 13:40:19,109] {dagbag.py:403} INFO - Filling up the DagBag from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 13:40:19,216] {scheduler_job.py:1551} INFO - DAG(s) dict_keys(['process_replies']) retrieved from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 13:40:19,246] {scheduler_job.py:1262} INFO - Processing process_replies
[2020-01-20 13:40:19,257] {scheduler_job.py:440} INFO - Skipping SLA check for <DAG: process_replies> because no tasks in DAG have SLAs
[2020-01-20 13:40:19,262] {scheduler_job.py:161} INFO - Processing /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py took 0.163 seconds
[2020-01-20 13:41:05,204] {scheduler_job.py:153} INFO - Started process (PID=4559) to work on /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 13:41:05,213] {scheduler_job.py:1539} INFO - Processing file /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py for tasks to queue
[2020-01-20 13:41:05,214] {logging_mixin.py:112} INFO - [2020-01-20 13:41:05,214] {dagbag.py:403} INFO - Filling up the DagBag from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 13:41:05,293] {scheduler_job.py:1551} INFO - DAG(s) dict_keys(['process_replies']) retrieved from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 13:41:05,318] {scheduler_job.py:1262} INFO - Processing process_replies
[2020-01-20 13:41:05,327] {scheduler_job.py:440} INFO - Skipping SLA check for <DAG: process_replies> because no tasks in DAG have SLAs
[2020-01-20 13:41:05,329] {scheduler_job.py:161} INFO - Processing /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py took 0.126 seconds
[2020-01-20 13:41:51,353] {scheduler_job.py:153} INFO - Started process (PID=4591) to work on /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 13:41:51,360] {scheduler_job.py:1539} INFO - Processing file /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py for tasks to queue
[2020-01-20 13:41:51,362] {logging_mixin.py:112} INFO - [2020-01-20 13:41:51,361] {dagbag.py:403} INFO - Filling up the DagBag from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 13:41:51,419] {scheduler_job.py:1551} INFO - DAG(s) dict_keys(['process_replies']) retrieved from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 13:41:51,442] {scheduler_job.py:1262} INFO - Processing process_replies
[2020-01-20 13:41:51,456] {scheduler_job.py:440} INFO - Skipping SLA check for <DAG: process_replies> because no tasks in DAG have SLAs
[2020-01-20 13:41:51,459] {scheduler_job.py:161} INFO - Processing /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py took 0.107 seconds
[2020-01-20 13:42:37,458] {scheduler_job.py:153} INFO - Started process (PID=4642) to work on /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 13:42:37,468] {scheduler_job.py:1539} INFO - Processing file /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py for tasks to queue
[2020-01-20 13:42:37,469] {logging_mixin.py:112} INFO - [2020-01-20 13:42:37,469] {dagbag.py:403} INFO - Filling up the DagBag from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 13:42:37,713] {scheduler_job.py:1551} INFO - DAG(s) dict_keys(['process_replies']) retrieved from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 13:42:37,739] {scheduler_job.py:1262} INFO - Processing process_replies
[2020-01-20 13:42:37,751] {scheduler_job.py:440} INFO - Skipping SLA check for <DAG: process_replies> because no tasks in DAG have SLAs
[2020-01-20 13:42:37,754] {scheduler_job.py:161} INFO - Processing /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py took 0.296 seconds
[2020-01-20 13:43:23,578] {scheduler_job.py:153} INFO - Started process (PID=4682) to work on /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 13:43:23,584] {scheduler_job.py:1539} INFO - Processing file /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py for tasks to queue
[2020-01-20 13:43:23,585] {logging_mixin.py:112} INFO - [2020-01-20 13:43:23,585] {dagbag.py:403} INFO - Filling up the DagBag from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 13:43:23,655] {scheduler_job.py:1551} INFO - DAG(s) dict_keys(['process_replies']) retrieved from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 13:43:23,675] {scheduler_job.py:1262} INFO - Processing process_replies
[2020-01-20 13:43:23,685] {scheduler_job.py:440} INFO - Skipping SLA check for <DAG: process_replies> because no tasks in DAG have SLAs
[2020-01-20 13:43:23,687] {scheduler_job.py:161} INFO - Processing /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py took 0.109 seconds
[2020-01-20 13:44:09,707] {scheduler_job.py:153} INFO - Started process (PID=4718) to work on /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 13:44:09,715] {scheduler_job.py:1539} INFO - Processing file /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py for tasks to queue
[2020-01-20 13:44:09,715] {logging_mixin.py:112} INFO - [2020-01-20 13:44:09,715] {dagbag.py:403} INFO - Filling up the DagBag from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 13:44:09,921] {scheduler_job.py:1551} INFO - DAG(s) dict_keys(['process_replies']) retrieved from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 13:44:09,953] {scheduler_job.py:1262} INFO - Processing process_replies
[2020-01-20 13:44:09,965] {scheduler_job.py:440} INFO - Skipping SLA check for <DAG: process_replies> because no tasks in DAG have SLAs
[2020-01-20 13:44:09,970] {scheduler_job.py:161} INFO - Processing /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py took 0.263 seconds
[2020-01-20 13:44:55,833] {scheduler_job.py:153} INFO - Started process (PID=4760) to work on /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 13:44:55,841] {scheduler_job.py:1539} INFO - Processing file /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py for tasks to queue
[2020-01-20 13:44:55,843] {logging_mixin.py:112} INFO - [2020-01-20 13:44:55,842] {dagbag.py:403} INFO - Filling up the DagBag from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 13:44:55,915] {scheduler_job.py:1551} INFO - DAG(s) dict_keys(['process_replies']) retrieved from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 13:44:55,942] {scheduler_job.py:1262} INFO - Processing process_replies
[2020-01-20 13:44:55,954] {scheduler_job.py:440} INFO - Skipping SLA check for <DAG: process_replies> because no tasks in DAG have SLAs
[2020-01-20 13:44:55,958] {scheduler_job.py:161} INFO - Processing /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py took 0.125 seconds
[2020-01-20 13:45:41,976] {scheduler_job.py:153} INFO - Started process (PID=4799) to work on /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 13:45:41,982] {scheduler_job.py:1539} INFO - Processing file /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py for tasks to queue
[2020-01-20 13:45:41,984] {logging_mixin.py:112} INFO - [2020-01-20 13:45:41,983] {dagbag.py:403} INFO - Filling up the DagBag from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 13:45:42,110] {scheduler_job.py:1551} INFO - DAG(s) dict_keys(['process_replies']) retrieved from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 13:45:42,131] {scheduler_job.py:1262} INFO - Processing process_replies
[2020-01-20 13:45:42,144] {scheduler_job.py:440} INFO - Skipping SLA check for <DAG: process_replies> because no tasks in DAG have SLAs
[2020-01-20 13:45:42,148] {scheduler_job.py:161} INFO - Processing /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py took 0.172 seconds
[2020-01-20 13:46:28,142] {scheduler_job.py:153} INFO - Started process (PID=4846) to work on /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 13:46:28,148] {scheduler_job.py:1539} INFO - Processing file /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py for tasks to queue
[2020-01-20 13:46:28,149] {logging_mixin.py:112} INFO - [2020-01-20 13:46:28,149] {dagbag.py:403} INFO - Filling up the DagBag from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 13:46:28,330] {scheduler_job.py:1551} INFO - DAG(s) dict_keys(['process_replies']) retrieved from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 13:46:28,351] {scheduler_job.py:1262} INFO - Processing process_replies
[2020-01-20 13:46:28,360] {scheduler_job.py:440} INFO - Skipping SLA check for <DAG: process_replies> because no tasks in DAG have SLAs
[2020-01-20 13:46:28,362] {scheduler_job.py:161} INFO - Processing /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py took 0.220 seconds
[2020-01-20 13:47:14,260] {scheduler_job.py:153} INFO - Started process (PID=4899) to work on /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 13:47:14,269] {scheduler_job.py:1539} INFO - Processing file /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py for tasks to queue
[2020-01-20 13:47:14,270] {logging_mixin.py:112} INFO - [2020-01-20 13:47:14,270] {dagbag.py:403} INFO - Filling up the DagBag from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 13:47:14,330] {scheduler_job.py:1551} INFO - DAG(s) dict_keys(['process_replies']) retrieved from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 13:47:14,351] {scheduler_job.py:1262} INFO - Processing process_replies
[2020-01-20 13:47:14,359] {scheduler_job.py:440} INFO - Skipping SLA check for <DAG: process_replies> because no tasks in DAG have SLAs
[2020-01-20 13:47:14,361] {scheduler_job.py:161} INFO - Processing /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py took 0.101 seconds
[2020-01-20 13:48:00,389] {scheduler_job.py:153} INFO - Started process (PID=4980) to work on /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 13:48:00,395] {scheduler_job.py:1539} INFO - Processing file /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py for tasks to queue
[2020-01-20 13:48:00,396] {logging_mixin.py:112} INFO - [2020-01-20 13:48:00,396] {dagbag.py:403} INFO - Filling up the DagBag from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 13:48:00,535] {scheduler_job.py:1551} INFO - DAG(s) dict_keys(['process_replies']) retrieved from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 13:48:00,555] {scheduler_job.py:1262} INFO - Processing process_replies
[2020-01-20 13:48:00,563] {scheduler_job.py:440} INFO - Skipping SLA check for <DAG: process_replies> because no tasks in DAG have SLAs
[2020-01-20 13:48:00,565] {scheduler_job.py:161} INFO - Processing /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py took 0.177 seconds
[2020-01-20 13:48:46,524] {scheduler_job.py:153} INFO - Started process (PID=5010) to work on /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 13:48:46,537] {scheduler_job.py:1539} INFO - Processing file /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py for tasks to queue
[2020-01-20 13:48:46,538] {logging_mixin.py:112} INFO - [2020-01-20 13:48:46,538] {dagbag.py:403} INFO - Filling up the DagBag from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 13:48:46,787] {scheduler_job.py:1551} INFO - DAG(s) dict_keys(['process_replies']) retrieved from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 13:48:46,819] {scheduler_job.py:1262} INFO - Processing process_replies
[2020-01-20 13:48:46,835] {scheduler_job.py:440} INFO - Skipping SLA check for <DAG: process_replies> because no tasks in DAG have SLAs
[2020-01-20 13:48:46,838] {scheduler_job.py:161} INFO - Processing /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py took 0.314 seconds
[2020-01-20 13:49:32,647] {scheduler_job.py:153} INFO - Started process (PID=5048) to work on /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 13:49:32,656] {scheduler_job.py:1539} INFO - Processing file /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py for tasks to queue
[2020-01-20 13:49:32,657] {logging_mixin.py:112} INFO - [2020-01-20 13:49:32,656] {dagbag.py:403} INFO - Filling up the DagBag from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 13:49:32,721] {scheduler_job.py:1551} INFO - DAG(s) dict_keys(['process_replies']) retrieved from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 13:49:32,743] {scheduler_job.py:1262} INFO - Processing process_replies
[2020-01-20 13:49:32,752] {scheduler_job.py:440} INFO - Skipping SLA check for <DAG: process_replies> because no tasks in DAG have SLAs
[2020-01-20 13:49:32,754] {scheduler_job.py:161} INFO - Processing /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py took 0.107 seconds
[2020-01-20 13:50:18,799] {scheduler_job.py:153} INFO - Started process (PID=5076) to work on /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 13:50:18,806] {scheduler_job.py:1539} INFO - Processing file /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py for tasks to queue
[2020-01-20 13:50:18,806] {logging_mixin.py:112} INFO - [2020-01-20 13:50:18,806] {dagbag.py:403} INFO - Filling up the DagBag from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 13:50:18,980] {scheduler_job.py:1551} INFO - DAG(s) dict_keys(['process_replies']) retrieved from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 13:50:19,002] {scheduler_job.py:1262} INFO - Processing process_replies
[2020-01-20 13:50:19,010] {scheduler_job.py:440} INFO - Skipping SLA check for <DAG: process_replies> because no tasks in DAG have SLAs
[2020-01-20 13:50:19,012] {scheduler_job.py:161} INFO - Processing /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py took 0.214 seconds
[2020-01-20 13:51:04,931] {scheduler_job.py:153} INFO - Started process (PID=5109) to work on /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 13:51:04,938] {scheduler_job.py:1539} INFO - Processing file /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py for tasks to queue
[2020-01-20 13:51:04,939] {logging_mixin.py:112} INFO - [2020-01-20 13:51:04,938] {dagbag.py:403} INFO - Filling up the DagBag from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 13:51:05,008] {scheduler_job.py:1551} INFO - DAG(s) dict_keys(['process_replies']) retrieved from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 13:51:05,045] {scheduler_job.py:1262} INFO - Processing process_replies
[2020-01-20 13:51:05,056] {scheduler_job.py:440} INFO - Skipping SLA check for <DAG: process_replies> because no tasks in DAG have SLAs
[2020-01-20 13:51:05,060] {scheduler_job.py:161} INFO - Processing /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py took 0.129 seconds
[2020-01-20 13:51:51,058] {scheduler_job.py:153} INFO - Started process (PID=5139) to work on /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 13:51:51,065] {scheduler_job.py:1539} INFO - Processing file /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py for tasks to queue
[2020-01-20 13:51:51,066] {logging_mixin.py:112} INFO - [2020-01-20 13:51:51,066] {dagbag.py:403} INFO - Filling up the DagBag from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 13:51:51,258] {scheduler_job.py:1551} INFO - DAG(s) dict_keys(['process_replies']) retrieved from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 13:51:51,285] {scheduler_job.py:1262} INFO - Processing process_replies
[2020-01-20 13:51:51,294] {scheduler_job.py:440} INFO - Skipping SLA check for <DAG: process_replies> because no tasks in DAG have SLAs
[2020-01-20 13:51:51,298] {scheduler_job.py:161} INFO - Processing /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py took 0.240 seconds
[2020-01-20 13:52:37,171] {scheduler_job.py:153} INFO - Started process (PID=5174) to work on /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 13:52:37,181] {scheduler_job.py:1539} INFO - Processing file /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py for tasks to queue
[2020-01-20 13:52:37,181] {logging_mixin.py:112} INFO - [2020-01-20 13:52:37,181] {dagbag.py:403} INFO - Filling up the DagBag from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 13:52:37,254] {scheduler_job.py:1551} INFO - DAG(s) dict_keys(['process_replies']) retrieved from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 13:52:37,276] {scheduler_job.py:1262} INFO - Processing process_replies
[2020-01-20 13:52:37,287] {scheduler_job.py:440} INFO - Skipping SLA check for <DAG: process_replies> because no tasks in DAG have SLAs
[2020-01-20 13:52:37,291] {scheduler_job.py:161} INFO - Processing /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py took 0.119 seconds
[2020-01-20 13:53:23,299] {scheduler_job.py:153} INFO - Started process (PID=5207) to work on /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 13:53:23,308] {scheduler_job.py:1539} INFO - Processing file /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py for tasks to queue
[2020-01-20 13:53:23,309] {logging_mixin.py:112} INFO - [2020-01-20 13:53:23,309] {dagbag.py:403} INFO - Filling up the DagBag from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 13:53:23,390] {scheduler_job.py:1551} INFO - DAG(s) dict_keys(['process_replies']) retrieved from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 13:53:23,410] {scheduler_job.py:1262} INFO - Processing process_replies
[2020-01-20 13:53:23,420] {scheduler_job.py:440} INFO - Skipping SLA check for <DAG: process_replies> because no tasks in DAG have SLAs
[2020-01-20 13:53:23,423] {scheduler_job.py:161} INFO - Processing /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py took 0.125 seconds
[2020-01-20 13:54:09,441] {scheduler_job.py:153} INFO - Started process (PID=5239) to work on /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 13:54:09,457] {scheduler_job.py:1539} INFO - Processing file /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py for tasks to queue
[2020-01-20 13:54:09,458] {logging_mixin.py:112} INFO - [2020-01-20 13:54:09,458] {dagbag.py:403} INFO - Filling up the DagBag from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 13:54:09,698] {scheduler_job.py:1551} INFO - DAG(s) dict_keys(['process_replies']) retrieved from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 13:54:09,734] {scheduler_job.py:1262} INFO - Processing process_replies
[2020-01-20 13:54:09,747] {scheduler_job.py:440} INFO - Skipping SLA check for <DAG: process_replies> because no tasks in DAG have SLAs
[2020-01-20 13:54:09,749] {scheduler_job.py:161} INFO - Processing /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py took 0.309 seconds
[2020-01-20 13:58:05,692] {scheduler_job.py:153} INFO - Started process (PID=5311) to work on /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 13:58:05,699] {scheduler_job.py:1539} INFO - Processing file /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py for tasks to queue
[2020-01-20 13:58:05,700] {logging_mixin.py:112} INFO - [2020-01-20 13:58:05,700] {dagbag.py:403} INFO - Filling up the DagBag from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 13:58:05,758] {scheduler_job.py:1551} INFO - DAG(s) dict_keys(['process_replies']) retrieved from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 13:58:05,778] {scheduler_job.py:1262} INFO - Processing process_replies
[2020-01-20 13:58:05,801] {scheduler_job.py:1272} INFO - Created <DagRun process_replies @ 2019-10-09T00:10:00+00:00: scheduled__2019-10-09T00:10:00+00:00, externally triggered: False>
[2020-01-20 13:58:05,804] {scheduler_job.py:740} INFO - Examining DAG run <DagRun process_replies @ 2019-10-09 00:10:00+00:00: scheduled__2019-10-09T00:10:00+00:00, externally triggered: False>
[2020-01-20 13:58:05,813] {scheduler_job.py:440} INFO - Skipping SLA check for <DAG: process_replies> because no tasks in DAG have SLAs
[2020-01-20 13:58:05,816] {scheduler_job.py:1613} INFO - Creating / updating <TaskInstance: process_replies.send_replies 2019-10-09 00:10:00+00:00 [scheduled]> in ORM
[2020-01-20 13:58:05,822] {scheduler_job.py:161} INFO - Processing /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py took 0.130 seconds
[2020-01-20 13:59:16,741] {scheduler_job.py:153} INFO - Started process (PID=5354) to work on /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 13:59:16,748] {scheduler_job.py:1539} INFO - Processing file /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py for tasks to queue
[2020-01-20 13:59:16,749] {logging_mixin.py:112} INFO - [2020-01-20 13:59:16,749] {dagbag.py:403} INFO - Filling up the DagBag from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 13:59:16,934] {scheduler_job.py:1551} INFO - DAG(s) dict_keys(['process_replies']) retrieved from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 13:59:16,956] {scheduler_job.py:1262} INFO - Processing process_replies
[2020-01-20 13:59:16,979] {scheduler_job.py:1272} INFO - Created <DagRun process_replies @ 2019-10-09T00:20:00+00:00: scheduled__2019-10-09T00:20:00+00:00, externally triggered: False>
[2020-01-20 13:59:16,981] {scheduler_job.py:740} INFO - Examining DAG run <DagRun process_replies @ 2019-10-09 00:10:00+00:00: scheduled__2019-10-09T00:10:00+00:00, externally triggered: False>
[2020-01-20 13:59:16,987] {logging_mixin.py:112} INFO - [2020-01-20 13:59:16,987] {dagrun.py:318} INFO - Marking run <DagRun process_replies @ 2019-10-09 00:10:00+00:00: scheduled__2019-10-09T00:10:00+00:00, externally triggered: False> successful
[2020-01-20 13:59:16,990] {scheduler_job.py:740} INFO - Examining DAG run <DagRun process_replies @ 2019-10-09 00:20:00+00:00: scheduled__2019-10-09T00:20:00+00:00, externally triggered: False>
[2020-01-20 13:59:17,003] {scheduler_job.py:440} INFO - Skipping SLA check for <DAG: process_replies> because no tasks in DAG have SLAs
[2020-01-20 13:59:17,006] {scheduler_job.py:1613} INFO - Creating / updating <TaskInstance: process_replies.send_replies 2019-10-09 00:20:00+00:00 [scheduled]> in ORM
[2020-01-20 13:59:17,014] {scheduler_job.py:161} INFO - Processing /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py took 0.273 seconds
[2020-01-20 14:00:28,148] {scheduler_job.py:153} INFO - Started process (PID=5401) to work on /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 14:00:28,158] {scheduler_job.py:1539} INFO - Processing file /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py for tasks to queue
[2020-01-20 14:00:28,159] {logging_mixin.py:112} INFO - [2020-01-20 14:00:28,159] {dagbag.py:403} INFO - Filling up the DagBag from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 14:00:28,275] {scheduler_job.py:1551} INFO - DAG(s) dict_keys(['process_replies']) retrieved from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 14:00:28,316] {scheduler_job.py:1262} INFO - Processing process_replies
[2020-01-20 14:00:28,395] {scheduler_job.py:1272} INFO - Created <DagRun process_replies @ 2019-10-09T00:30:00+00:00: scheduled__2019-10-09T00:30:00+00:00, externally triggered: False>
[2020-01-20 14:00:28,399] {scheduler_job.py:740} INFO - Examining DAG run <DagRun process_replies @ 2019-10-09 00:20:00+00:00: scheduled__2019-10-09T00:20:00+00:00, externally triggered: False>
[2020-01-20 14:00:28,417] {logging_mixin.py:112} INFO - [2020-01-20 14:00:28,416] {dagrun.py:318} INFO - Marking run <DagRun process_replies @ 2019-10-09 00:20:00+00:00: scheduled__2019-10-09T00:20:00+00:00, externally triggered: False> successful
[2020-01-20 14:00:28,427] {scheduler_job.py:740} INFO - Examining DAG run <DagRun process_replies @ 2019-10-09 00:30:00+00:00: scheduled__2019-10-09T00:30:00+00:00, externally triggered: False>
[2020-01-20 14:00:28,452] {scheduler_job.py:440} INFO - Skipping SLA check for <DAG: process_replies> because no tasks in DAG have SLAs
[2020-01-20 14:00:28,462] {scheduler_job.py:1613} INFO - Creating / updating <TaskInstance: process_replies.send_replies 2019-10-09 00:30:00+00:00 [scheduled]> in ORM
[2020-01-20 14:00:28,480] {scheduler_job.py:161} INFO - Processing /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py took 0.332 seconds
[2020-01-20 14:01:38,680] {scheduler_job.py:153} INFO - Started process (PID=5448) to work on /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 14:01:38,685] {scheduler_job.py:1539} INFO - Processing file /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py for tasks to queue
[2020-01-20 14:01:38,686] {logging_mixin.py:112} INFO - [2020-01-20 14:01:38,685] {dagbag.py:403} INFO - Filling up the DagBag from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 14:01:38,861] {scheduler_job.py:1551} INFO - DAG(s) dict_keys(['process_replies']) retrieved from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 14:01:38,881] {scheduler_job.py:1262} INFO - Processing process_replies
[2020-01-20 14:01:38,902] {scheduler_job.py:1272} INFO - Created <DagRun process_replies @ 2019-10-09T00:40:00+00:00: scheduled__2019-10-09T00:40:00+00:00, externally triggered: False>
[2020-01-20 14:01:38,905] {scheduler_job.py:740} INFO - Examining DAG run <DagRun process_replies @ 2019-10-09 00:30:00+00:00: scheduled__2019-10-09T00:30:00+00:00, externally triggered: False>
[2020-01-20 14:01:38,912] {logging_mixin.py:112} INFO - [2020-01-20 14:01:38,912] {dagrun.py:318} INFO - Marking run <DagRun process_replies @ 2019-10-09 00:30:00+00:00: scheduled__2019-10-09T00:30:00+00:00, externally triggered: False> successful
[2020-01-20 14:01:38,915] {scheduler_job.py:740} INFO - Examining DAG run <DagRun process_replies @ 2019-10-09 00:40:00+00:00: scheduled__2019-10-09T00:40:00+00:00, externally triggered: False>
[2020-01-20 14:01:38,925] {scheduler_job.py:440} INFO - Skipping SLA check for <DAG: process_replies> because no tasks in DAG have SLAs
[2020-01-20 14:01:38,929] {scheduler_job.py:1613} INFO - Creating / updating <TaskInstance: process_replies.send_replies 2019-10-09 00:40:00+00:00 [scheduled]> in ORM
[2020-01-20 14:01:38,941] {scheduler_job.py:161} INFO - Processing /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py took 0.261 seconds
[2020-01-20 14:02:50,565] {scheduler_job.py:153} INFO - Started process (PID=5504) to work on /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 14:02:50,573] {scheduler_job.py:1539} INFO - Processing file /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py for tasks to queue
[2020-01-20 14:02:50,574] {logging_mixin.py:112} INFO - [2020-01-20 14:02:50,574] {dagbag.py:403} INFO - Filling up the DagBag from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 14:02:50,742] {scheduler_job.py:1551} INFO - DAG(s) dict_keys(['process_replies']) retrieved from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 14:02:50,773] {scheduler_job.py:1262} INFO - Processing process_replies
[2020-01-20 14:02:50,803] {scheduler_job.py:1272} INFO - Created <DagRun process_replies @ 2019-10-09T00:50:00+00:00: scheduled__2019-10-09T00:50:00+00:00, externally triggered: False>
[2020-01-20 14:02:50,806] {scheduler_job.py:740} INFO - Examining DAG run <DagRun process_replies @ 2019-10-09 00:40:00+00:00: scheduled__2019-10-09T00:40:00+00:00, externally triggered: False>
[2020-01-20 14:02:50,814] {logging_mixin.py:112} INFO - [2020-01-20 14:02:50,814] {dagrun.py:318} INFO - Marking run <DagRun process_replies @ 2019-10-09 00:40:00+00:00: scheduled__2019-10-09T00:40:00+00:00, externally triggered: False> successful
[2020-01-20 14:02:50,818] {scheduler_job.py:740} INFO - Examining DAG run <DagRun process_replies @ 2019-10-09 00:50:00+00:00: scheduled__2019-10-09T00:50:00+00:00, externally triggered: False>
[2020-01-20 14:02:50,831] {scheduler_job.py:440} INFO - Skipping SLA check for <DAG: process_replies> because no tasks in DAG have SLAs
[2020-01-20 14:02:50,836] {scheduler_job.py:1613} INFO - Creating / updating <TaskInstance: process_replies.send_replies 2019-10-09 00:50:00+00:00 [scheduled]> in ORM
[2020-01-20 14:02:50,844] {scheduler_job.py:161} INFO - Processing /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py took 0.279 seconds
[2020-01-20 14:10:31,268] {scheduler_job.py:153} INFO - Started process (PID=5648) to work on /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 14:10:31,274] {scheduler_job.py:1539} INFO - Processing file /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py for tasks to queue
[2020-01-20 14:10:31,275] {logging_mixin.py:112} INFO - [2020-01-20 14:10:31,275] {dagbag.py:403} INFO - Filling up the DagBag from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 14:10:31,329] {scheduler_job.py:1551} INFO - DAG(s) dict_keys(['process_replies']) retrieved from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 14:10:31,350] {scheduler_job.py:1262} INFO - Processing process_replies
[2020-01-20 14:10:31,373] {scheduler_job.py:1272} INFO - Created <DagRun process_replies @ 2020-01-20T00:00:00+00:00: scheduled__2020-01-20T00:00:00+00:00, externally triggered: False>
[2020-01-20 14:10:31,375] {scheduler_job.py:740} INFO - Examining DAG run <DagRun process_replies @ 2020-01-20 00:00:00+00:00: scheduled__2020-01-20T00:00:00+00:00, externally triggered: False>
[2020-01-20 14:10:31,383] {scheduler_job.py:440} INFO - Skipping SLA check for <DAG: process_replies> because no tasks in DAG have SLAs
[2020-01-20 14:10:31,386] {scheduler_job.py:1613} INFO - Creating / updating <TaskInstance: process_replies.send_replies 2020-01-20 00:00:00+00:00 [scheduled]> in ORM
[2020-01-20 14:10:31,393] {scheduler_job.py:161} INFO - Processing /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py took 0.125 seconds
[2020-01-20 14:11:43,201] {scheduler_job.py:153} INFO - Started process (PID=5686) to work on /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 14:11:43,209] {scheduler_job.py:1539} INFO - Processing file /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py for tasks to queue
[2020-01-20 14:11:43,210] {logging_mixin.py:112} INFO - [2020-01-20 14:11:43,210] {dagbag.py:403} INFO - Filling up the DagBag from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 14:11:43,261] {scheduler_job.py:1551} INFO - DAG(s) dict_keys(['process_replies']) retrieved from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 14:11:43,282] {scheduler_job.py:1262} INFO - Processing process_replies
[2020-01-20 14:11:43,303] {scheduler_job.py:1272} INFO - Created <DagRun process_replies @ 2020-01-20T00:10:00+00:00: scheduled__2020-01-20T00:10:00+00:00, externally triggered: False>
[2020-01-20 14:11:43,305] {scheduler_job.py:740} INFO - Examining DAG run <DagRun process_replies @ 2020-01-20 00:00:00+00:00: scheduled__2020-01-20T00:00:00+00:00, externally triggered: False>
[2020-01-20 14:11:43,311] {logging_mixin.py:112} INFO - [2020-01-20 14:11:43,310] {dagrun.py:318} INFO - Marking run <DagRun process_replies @ 2020-01-20 00:00:00+00:00: scheduled__2020-01-20T00:00:00+00:00, externally triggered: False> successful
[2020-01-20 14:11:43,314] {scheduler_job.py:740} INFO - Examining DAG run <DagRun process_replies @ 2020-01-20 00:10:00+00:00: scheduled__2020-01-20T00:10:00+00:00, externally triggered: False>
[2020-01-20 14:11:43,323] {scheduler_job.py:440} INFO - Skipping SLA check for <DAG: process_replies> because no tasks in DAG have SLAs
[2020-01-20 14:11:43,326] {scheduler_job.py:1613} INFO - Creating / updating <TaskInstance: process_replies.send_replies 2020-01-20 00:10:00+00:00 [scheduled]> in ORM
[2020-01-20 14:11:43,331] {scheduler_job.py:161} INFO - Processing /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py took 0.130 seconds
[2020-01-20 14:12:52,086] {scheduler_job.py:153} INFO - Started process (PID=5722) to work on /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 14:12:52,093] {scheduler_job.py:1539} INFO - Processing file /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py for tasks to queue
[2020-01-20 14:12:52,094] {logging_mixin.py:112} INFO - [2020-01-20 14:12:52,093] {dagbag.py:403} INFO - Filling up the DagBag from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 14:12:52,223] {scheduler_job.py:1551} INFO - DAG(s) dict_keys(['process_replies']) retrieved from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 14:12:52,242] {scheduler_job.py:1262} INFO - Processing process_replies
[2020-01-20 14:12:52,267] {scheduler_job.py:1272} INFO - Created <DagRun process_replies @ 2020-01-20T00:20:00+00:00: scheduled__2020-01-20T00:20:00+00:00, externally triggered: False>
[2020-01-20 14:12:52,270] {scheduler_job.py:740} INFO - Examining DAG run <DagRun process_replies @ 2020-01-20 00:10:00+00:00: scheduled__2020-01-20T00:10:00+00:00, externally triggered: False>
[2020-01-20 14:12:52,276] {logging_mixin.py:112} INFO - [2020-01-20 14:12:52,276] {dagrun.py:318} INFO - Marking run <DagRun process_replies @ 2020-01-20 00:10:00+00:00: scheduled__2020-01-20T00:10:00+00:00, externally triggered: False> successful
[2020-01-20 14:12:52,278] {scheduler_job.py:740} INFO - Examining DAG run <DagRun process_replies @ 2020-01-20 00:20:00+00:00: scheduled__2020-01-20T00:20:00+00:00, externally triggered: False>
[2020-01-20 14:12:52,286] {scheduler_job.py:440} INFO - Skipping SLA check for <DAG: process_replies> because no tasks in DAG have SLAs
[2020-01-20 14:12:52,290] {scheduler_job.py:1613} INFO - Creating / updating <TaskInstance: process_replies.send_replies 2020-01-20 00:20:00+00:00 [scheduled]> in ORM
[2020-01-20 14:12:52,298] {scheduler_job.py:161} INFO - Processing /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py took 0.212 seconds
[2020-01-20 14:14:00,752] {scheduler_job.py:153} INFO - Started process (PID=5756) to work on /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 14:14:00,760] {scheduler_job.py:1539} INFO - Processing file /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py for tasks to queue
[2020-01-20 14:14:00,761] {logging_mixin.py:112} INFO - [2020-01-20 14:14:00,761] {dagbag.py:403} INFO - Filling up the DagBag from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 14:14:00,891] {scheduler_job.py:1551} INFO - DAG(s) dict_keys(['process_replies']) retrieved from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 14:14:00,911] {scheduler_job.py:1262} INFO - Processing process_replies
[2020-01-20 14:14:00,931] {scheduler_job.py:1272} INFO - Created <DagRun process_replies @ 2020-01-20T00:30:00+00:00: scheduled__2020-01-20T00:30:00+00:00, externally triggered: False>
[2020-01-20 14:14:00,934] {scheduler_job.py:740} INFO - Examining DAG run <DagRun process_replies @ 2020-01-20 00:20:00+00:00: scheduled__2020-01-20T00:20:00+00:00, externally triggered: False>
[2020-01-20 14:14:00,940] {logging_mixin.py:112} INFO - [2020-01-20 14:14:00,940] {dagrun.py:318} INFO - Marking run <DagRun process_replies @ 2020-01-20 00:20:00+00:00: scheduled__2020-01-20T00:20:00+00:00, externally triggered: False> successful
[2020-01-20 14:14:00,942] {scheduler_job.py:740} INFO - Examining DAG run <DagRun process_replies @ 2020-01-20 00:30:00+00:00: scheduled__2020-01-20T00:30:00+00:00, externally triggered: False>
[2020-01-20 14:14:00,951] {scheduler_job.py:440} INFO - Skipping SLA check for <DAG: process_replies> because no tasks in DAG have SLAs
[2020-01-20 14:14:00,955] {scheduler_job.py:1613} INFO - Creating / updating <TaskInstance: process_replies.send_replies 2020-01-20 00:30:00+00:00 [scheduled]> in ORM
[2020-01-20 14:14:00,962] {scheduler_job.py:161} INFO - Processing /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py took 0.210 seconds
[2020-01-20 14:15:08,719] {scheduler_job.py:153} INFO - Started process (PID=5795) to work on /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 14:15:08,728] {scheduler_job.py:1539} INFO - Processing file /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py for tasks to queue
[2020-01-20 14:15:08,729] {logging_mixin.py:112} INFO - [2020-01-20 14:15:08,729] {dagbag.py:403} INFO - Filling up the DagBag from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 14:15:08,782] {scheduler_job.py:1551} INFO - DAG(s) dict_keys(['process_replies']) retrieved from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 14:15:08,801] {scheduler_job.py:1262} INFO - Processing process_replies
[2020-01-20 14:15:08,822] {scheduler_job.py:1272} INFO - Created <DagRun process_replies @ 2020-01-20T00:40:00+00:00: scheduled__2020-01-20T00:40:00+00:00, externally triggered: False>
[2020-01-20 14:15:08,824] {scheduler_job.py:740} INFO - Examining DAG run <DagRun process_replies @ 2020-01-20 00:30:00+00:00: scheduled__2020-01-20T00:30:00+00:00, externally triggered: False>
[2020-01-20 14:15:08,830] {logging_mixin.py:112} INFO - [2020-01-20 14:15:08,830] {dagrun.py:318} INFO - Marking run <DagRun process_replies @ 2020-01-20 00:30:00+00:00: scheduled__2020-01-20T00:30:00+00:00, externally triggered: False> successful
[2020-01-20 14:15:08,833] {scheduler_job.py:740} INFO - Examining DAG run <DagRun process_replies @ 2020-01-20 00:40:00+00:00: scheduled__2020-01-20T00:40:00+00:00, externally triggered: False>
[2020-01-20 14:15:08,842] {scheduler_job.py:440} INFO - Skipping SLA check for <DAG: process_replies> because no tasks in DAG have SLAs
[2020-01-20 14:15:08,845] {scheduler_job.py:1613} INFO - Creating / updating <TaskInstance: process_replies.send_replies 2020-01-20 00:40:00+00:00 [scheduled]> in ORM
[2020-01-20 14:15:08,853] {scheduler_job.py:161} INFO - Processing /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py took 0.133 seconds
[2020-01-20 14:16:15,737] {scheduler_job.py:153} INFO - Started process (PID=5829) to work on /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 14:16:15,745] {scheduler_job.py:1539} INFO - Processing file /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py for tasks to queue
[2020-01-20 14:16:15,746] {logging_mixin.py:112} INFO - [2020-01-20 14:16:15,746] {dagbag.py:403} INFO - Filling up the DagBag from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 14:16:15,800] {scheduler_job.py:1551} INFO - DAG(s) dict_keys(['process_replies']) retrieved from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 14:16:15,819] {scheduler_job.py:1262} INFO - Processing process_replies
[2020-01-20 14:16:15,844] {scheduler_job.py:1272} INFO - Created <DagRun process_replies @ 2020-01-20T00:50:00+00:00: scheduled__2020-01-20T00:50:00+00:00, externally triggered: False>
[2020-01-20 14:16:15,846] {scheduler_job.py:740} INFO - Examining DAG run <DagRun process_replies @ 2020-01-20 00:40:00+00:00: scheduled__2020-01-20T00:40:00+00:00, externally triggered: False>
[2020-01-20 14:16:15,852] {logging_mixin.py:112} INFO - [2020-01-20 14:16:15,852] {dagrun.py:318} INFO - Marking run <DagRun process_replies @ 2020-01-20 00:40:00+00:00: scheduled__2020-01-20T00:40:00+00:00, externally triggered: False> successful
[2020-01-20 14:16:15,854] {scheduler_job.py:740} INFO - Examining DAG run <DagRun process_replies @ 2020-01-20 00:50:00+00:00: scheduled__2020-01-20T00:50:00+00:00, externally triggered: False>
[2020-01-20 14:16:15,864] {scheduler_job.py:440} INFO - Skipping SLA check for <DAG: process_replies> because no tasks in DAG have SLAs
[2020-01-20 14:16:15,867] {scheduler_job.py:1613} INFO - Creating / updating <TaskInstance: process_replies.send_replies 2020-01-20 00:50:00+00:00 [scheduled]> in ORM
[2020-01-20 14:16:15,873] {scheduler_job.py:161} INFO - Processing /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py took 0.136 seconds
[2020-01-20 14:17:24,685] {scheduler_job.py:153} INFO - Started process (PID=5866) to work on /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 14:17:24,710] {scheduler_job.py:1539} INFO - Processing file /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py for tasks to queue
[2020-01-20 14:17:24,712] {logging_mixin.py:112} INFO - [2020-01-20 14:17:24,711] {dagbag.py:403} INFO - Filling up the DagBag from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 14:17:24,959] {scheduler_job.py:1551} INFO - DAG(s) dict_keys(['process_replies']) retrieved from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 14:17:24,986] {scheduler_job.py:1262} INFO - Processing process_replies
[2020-01-20 14:17:25,010] {scheduler_job.py:1272} INFO - Created <DagRun process_replies @ 2020-01-20T01:00:00+00:00: scheduled__2020-01-20T01:00:00+00:00, externally triggered: False>
[2020-01-20 14:17:25,012] {scheduler_job.py:740} INFO - Examining DAG run <DagRun process_replies @ 2020-01-20 00:50:00+00:00: scheduled__2020-01-20T00:50:00+00:00, externally triggered: False>
[2020-01-20 14:17:25,019] {logging_mixin.py:112} INFO - [2020-01-20 14:17:25,019] {dagrun.py:318} INFO - Marking run <DagRun process_replies @ 2020-01-20 00:50:00+00:00: scheduled__2020-01-20T00:50:00+00:00, externally triggered: False> successful
[2020-01-20 14:17:25,021] {scheduler_job.py:740} INFO - Examining DAG run <DagRun process_replies @ 2020-01-20 01:00:00+00:00: scheduled__2020-01-20T01:00:00+00:00, externally triggered: False>
[2020-01-20 14:17:25,030] {scheduler_job.py:440} INFO - Skipping SLA check for <DAG: process_replies> because no tasks in DAG have SLAs
[2020-01-20 14:17:25,033] {scheduler_job.py:1613} INFO - Creating / updating <TaskInstance: process_replies.send_replies 2020-01-20 01:00:00+00:00 [scheduled]> in ORM
[2020-01-20 14:17:25,040] {scheduler_job.py:161} INFO - Processing /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py took 0.355 seconds
[2020-01-20 14:18:33,199] {scheduler_job.py:153} INFO - Started process (PID=5900) to work on /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 14:18:33,205] {scheduler_job.py:1539} INFO - Processing file /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py for tasks to queue
[2020-01-20 14:18:33,206] {logging_mixin.py:112} INFO - [2020-01-20 14:18:33,206] {dagbag.py:403} INFO - Filling up the DagBag from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 14:18:33,258] {scheduler_job.py:1551} INFO - DAG(s) dict_keys(['process_replies']) retrieved from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 14:18:33,278] {scheduler_job.py:1262} INFO - Processing process_replies
[2020-01-20 14:18:33,300] {scheduler_job.py:1272} INFO - Created <DagRun process_replies @ 2020-01-20T01:10:00+00:00: scheduled__2020-01-20T01:10:00+00:00, externally triggered: False>
[2020-01-20 14:18:33,303] {scheduler_job.py:740} INFO - Examining DAG run <DagRun process_replies @ 2020-01-20 01:00:00+00:00: scheduled__2020-01-20T01:00:00+00:00, externally triggered: False>
[2020-01-20 14:18:33,309] {logging_mixin.py:112} INFO - [2020-01-20 14:18:33,308] {dagrun.py:318} INFO - Marking run <DagRun process_replies @ 2020-01-20 01:00:00+00:00: scheduled__2020-01-20T01:00:00+00:00, externally triggered: False> successful
[2020-01-20 14:18:33,312] {scheduler_job.py:740} INFO - Examining DAG run <DagRun process_replies @ 2020-01-20 01:10:00+00:00: scheduled__2020-01-20T01:10:00+00:00, externally triggered: False>
[2020-01-20 14:18:33,325] {scheduler_job.py:440} INFO - Skipping SLA check for <DAG: process_replies> because no tasks in DAG have SLAs
[2020-01-20 14:18:33,328] {scheduler_job.py:1613} INFO - Creating / updating <TaskInstance: process_replies.send_replies 2020-01-20 01:10:00+00:00 [scheduled]> in ORM
[2020-01-20 14:18:33,336] {scheduler_job.py:161} INFO - Processing /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py took 0.137 seconds
[2020-01-20 14:19:30,760] {scheduler_job.py:153} INFO - Started process (PID=5932) to work on /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 14:19:30,766] {scheduler_job.py:1539} INFO - Processing file /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py for tasks to queue
[2020-01-20 14:19:30,767] {logging_mixin.py:112} INFO - [2020-01-20 14:19:30,767] {dagbag.py:403} INFO - Filling up the DagBag from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 14:19:30,817] {scheduler_job.py:1551} INFO - DAG(s) dict_keys(['process_replies']) retrieved from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 14:19:30,840] {scheduler_job.py:1262} INFO - Processing process_replies
[2020-01-20 14:19:30,862] {scheduler_job.py:1272} INFO - Created <DagRun process_replies @ 2020-01-20T01:20:00+00:00: scheduled__2020-01-20T01:20:00+00:00, externally triggered: False>
[2020-01-20 14:19:30,865] {scheduler_job.py:740} INFO - Examining DAG run <DagRun process_replies @ 2020-01-20 01:10:00+00:00: scheduled__2020-01-20T01:10:00+00:00, externally triggered: False>
[2020-01-20 14:19:30,870] {logging_mixin.py:112} INFO - [2020-01-20 14:19:30,870] {dagrun.py:318} INFO - Marking run <DagRun process_replies @ 2020-01-20 01:10:00+00:00: scheduled__2020-01-20T01:10:00+00:00, externally triggered: False> successful
[2020-01-20 14:19:30,873] {scheduler_job.py:740} INFO - Examining DAG run <DagRun process_replies @ 2020-01-20 01:20:00+00:00: scheduled__2020-01-20T01:20:00+00:00, externally triggered: False>
[2020-01-20 14:19:30,883] {scheduler_job.py:440} INFO - Skipping SLA check for <DAG: process_replies> because no tasks in DAG have SLAs
[2020-01-20 14:19:30,887] {scheduler_job.py:1613} INFO - Creating / updating <TaskInstance: process_replies.send_replies 2020-01-20 01:20:00+00:00 [scheduled]> in ORM
[2020-01-20 14:19:30,894] {scheduler_job.py:161} INFO - Processing /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py took 0.134 seconds
[2020-01-20 14:20:27,707] {scheduler_job.py:153} INFO - Started process (PID=5964) to work on /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 14:20:27,715] {scheduler_job.py:1539} INFO - Processing file /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py for tasks to queue
[2020-01-20 14:20:27,716] {logging_mixin.py:112} INFO - [2020-01-20 14:20:27,715] {dagbag.py:403} INFO - Filling up the DagBag from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 14:20:27,766] {scheduler_job.py:1551} INFO - DAG(s) dict_keys(['process_replies']) retrieved from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 14:20:27,787] {scheduler_job.py:1262} INFO - Processing process_replies
[2020-01-20 14:20:27,810] {scheduler_job.py:1272} INFO - Created <DagRun process_replies @ 2020-01-20T01:30:00+00:00: scheduled__2020-01-20T01:30:00+00:00, externally triggered: False>
[2020-01-20 14:20:27,812] {scheduler_job.py:740} INFO - Examining DAG run <DagRun process_replies @ 2020-01-20 01:20:00+00:00: scheduled__2020-01-20T01:20:00+00:00, externally triggered: False>
[2020-01-20 14:20:27,819] {logging_mixin.py:112} INFO - [2020-01-20 14:20:27,818] {dagrun.py:318} INFO - Marking run <DagRun process_replies @ 2020-01-20 01:20:00+00:00: scheduled__2020-01-20T01:20:00+00:00, externally triggered: False> successful
[2020-01-20 14:20:27,821] {scheduler_job.py:740} INFO - Examining DAG run <DagRun process_replies @ 2020-01-20 01:30:00+00:00: scheduled__2020-01-20T01:30:00+00:00, externally triggered: False>
[2020-01-20 14:20:27,831] {scheduler_job.py:440} INFO - Skipping SLA check for <DAG: process_replies> because no tasks in DAG have SLAs
[2020-01-20 14:20:27,834] {scheduler_job.py:1613} INFO - Creating / updating <TaskInstance: process_replies.send_replies 2020-01-20 01:30:00+00:00 [scheduled]> in ORM
[2020-01-20 14:20:27,840] {scheduler_job.py:161} INFO - Processing /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py took 0.134 seconds
[2020-01-20 14:21:25,861] {scheduler_job.py:153} INFO - Started process (PID=5996) to work on /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 14:21:25,867] {scheduler_job.py:1539} INFO - Processing file /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py for tasks to queue
[2020-01-20 14:21:25,868] {logging_mixin.py:112} INFO - [2020-01-20 14:21:25,867] {dagbag.py:403} INFO - Filling up the DagBag from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 14:21:25,917] {scheduler_job.py:1551} INFO - DAG(s) dict_keys(['process_replies']) retrieved from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 14:21:25,942] {scheduler_job.py:1262} INFO - Processing process_replies
[2020-01-20 14:21:25,966] {scheduler_job.py:1272} INFO - Created <DagRun process_replies @ 2020-01-20T01:40:00+00:00: scheduled__2020-01-20T01:40:00+00:00, externally triggered: False>
[2020-01-20 14:21:25,969] {scheduler_job.py:740} INFO - Examining DAG run <DagRun process_replies @ 2020-01-20 01:30:00+00:00: scheduled__2020-01-20T01:30:00+00:00, externally triggered: False>
[2020-01-20 14:21:25,976] {logging_mixin.py:112} INFO - [2020-01-20 14:21:25,975] {dagrun.py:318} INFO - Marking run <DagRun process_replies @ 2020-01-20 01:30:00+00:00: scheduled__2020-01-20T01:30:00+00:00, externally triggered: False> successful
[2020-01-20 14:21:25,979] {scheduler_job.py:740} INFO - Examining DAG run <DagRun process_replies @ 2020-01-20 01:40:00+00:00: scheduled__2020-01-20T01:40:00+00:00, externally triggered: False>
[2020-01-20 14:21:25,991] {scheduler_job.py:440} INFO - Skipping SLA check for <DAG: process_replies> because no tasks in DAG have SLAs
[2020-01-20 14:21:25,995] {scheduler_job.py:1613} INFO - Creating / updating <TaskInstance: process_replies.send_replies 2020-01-20 01:40:00+00:00 [scheduled]> in ORM
[2020-01-20 14:21:26,002] {scheduler_job.py:161} INFO - Processing /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py took 0.142 seconds
[2020-01-20 14:22:22,494] {scheduler_job.py:153} INFO - Started process (PID=6035) to work on /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 14:22:22,503] {scheduler_job.py:1539} INFO - Processing file /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py for tasks to queue
[2020-01-20 14:22:22,504] {logging_mixin.py:112} INFO - [2020-01-20 14:22:22,504] {dagbag.py:403} INFO - Filling up the DagBag from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 14:22:22,555] {scheduler_job.py:1551} INFO - DAG(s) dict_keys(['process_replies']) retrieved from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 14:22:22,574] {scheduler_job.py:1262} INFO - Processing process_replies
[2020-01-20 14:22:22,599] {scheduler_job.py:1272} INFO - Created <DagRun process_replies @ 2020-01-20T01:50:00+00:00: scheduled__2020-01-20T01:50:00+00:00, externally triggered: False>
[2020-01-20 14:22:22,602] {scheduler_job.py:740} INFO - Examining DAG run <DagRun process_replies @ 2020-01-20 01:40:00+00:00: scheduled__2020-01-20T01:40:00+00:00, externally triggered: False>
[2020-01-20 14:22:22,612] {logging_mixin.py:112} INFO - [2020-01-20 14:22:22,611] {dagrun.py:318} INFO - Marking run <DagRun process_replies @ 2020-01-20 01:40:00+00:00: scheduled__2020-01-20T01:40:00+00:00, externally triggered: False> successful
[2020-01-20 14:22:22,614] {scheduler_job.py:740} INFO - Examining DAG run <DagRun process_replies @ 2020-01-20 01:50:00+00:00: scheduled__2020-01-20T01:50:00+00:00, externally triggered: False>
[2020-01-20 14:22:22,624] {scheduler_job.py:440} INFO - Skipping SLA check for <DAG: process_replies> because no tasks in DAG have SLAs
[2020-01-20 14:22:22,628] {scheduler_job.py:1613} INFO - Creating / updating <TaskInstance: process_replies.send_replies 2020-01-20 01:50:00+00:00 [scheduled]> in ORM
[2020-01-20 14:22:22,634] {scheduler_job.py:161} INFO - Processing /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py took 0.140 seconds
[2020-01-20 14:23:20,334] {scheduler_job.py:153} INFO - Started process (PID=6068) to work on /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 14:23:20,378] {scheduler_job.py:1539} INFO - Processing file /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py for tasks to queue
[2020-01-20 14:23:20,379] {logging_mixin.py:112} INFO - [2020-01-20 14:23:20,378] {dagbag.py:403} INFO - Filling up the DagBag from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 14:23:21,048] {scheduler_job.py:1551} INFO - DAG(s) dict_keys(['process_replies']) retrieved from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 14:23:21,080] {scheduler_job.py:1262} INFO - Processing process_replies
[2020-01-20 14:23:21,129] {scheduler_job.py:1272} INFO - Created <DagRun process_replies @ 2020-01-20T02:00:00+00:00: scheduled__2020-01-20T02:00:00+00:00, externally triggered: False>
[2020-01-20 14:23:21,136] {scheduler_job.py:740} INFO - Examining DAG run <DagRun process_replies @ 2020-01-20 01:50:00+00:00: scheduled__2020-01-20T01:50:00+00:00, externally triggered: False>
[2020-01-20 14:23:21,146] {logging_mixin.py:112} INFO - [2020-01-20 14:23:21,146] {dagrun.py:318} INFO - Marking run <DagRun process_replies @ 2020-01-20 01:50:00+00:00: scheduled__2020-01-20T01:50:00+00:00, externally triggered: False> successful
[2020-01-20 14:23:21,149] {scheduler_job.py:740} INFO - Examining DAG run <DagRun process_replies @ 2020-01-20 02:00:00+00:00: scheduled__2020-01-20T02:00:00+00:00, externally triggered: False>
[2020-01-20 14:23:21,160] {scheduler_job.py:440} INFO - Skipping SLA check for <DAG: process_replies> because no tasks in DAG have SLAs
[2020-01-20 14:23:21,163] {scheduler_job.py:1613} INFO - Creating / updating <TaskInstance: process_replies.send_replies 2020-01-20 02:00:00+00:00 [scheduled]> in ORM
[2020-01-20 14:23:21,174] {scheduler_job.py:161} INFO - Processing /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py took 0.840 seconds
[2020-01-20 14:24:20,032] {scheduler_job.py:153} INFO - Started process (PID=6120) to work on /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 14:24:20,049] {scheduler_job.py:1539} INFO - Processing file /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py for tasks to queue
[2020-01-20 14:24:20,050] {logging_mixin.py:112} INFO - [2020-01-20 14:24:20,050] {dagbag.py:403} INFO - Filling up the DagBag from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 14:24:20,227] {scheduler_job.py:1551} INFO - DAG(s) dict_keys(['process_replies']) retrieved from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 14:24:20,252] {scheduler_job.py:1262} INFO - Processing process_replies
[2020-01-20 14:24:20,274] {scheduler_job.py:1272} INFO - Created <DagRun process_replies @ 2020-01-20T02:10:00+00:00: scheduled__2020-01-20T02:10:00+00:00, externally triggered: False>
[2020-01-20 14:24:20,276] {scheduler_job.py:740} INFO - Examining DAG run <DagRun process_replies @ 2020-01-20 02:00:00+00:00: scheduled__2020-01-20T02:00:00+00:00, externally triggered: False>
[2020-01-20 14:24:20,282] {logging_mixin.py:112} INFO - [2020-01-20 14:24:20,282] {dagrun.py:318} INFO - Marking run <DagRun process_replies @ 2020-01-20 02:00:00+00:00: scheduled__2020-01-20T02:00:00+00:00, externally triggered: False> successful
[2020-01-20 14:24:20,285] {scheduler_job.py:740} INFO - Examining DAG run <DagRun process_replies @ 2020-01-20 02:10:00+00:00: scheduled__2020-01-20T02:10:00+00:00, externally triggered: False>
[2020-01-20 14:24:20,294] {scheduler_job.py:440} INFO - Skipping SLA check for <DAG: process_replies> because no tasks in DAG have SLAs
[2020-01-20 14:24:20,297] {scheduler_job.py:1613} INFO - Creating / updating <TaskInstance: process_replies.send_replies 2020-01-20 02:10:00+00:00 [scheduled]> in ORM
[2020-01-20 14:24:20,303] {scheduler_job.py:161} INFO - Processing /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py took 0.271 seconds
[2020-01-20 14:25:18,695] {scheduler_job.py:153} INFO - Started process (PID=6152) to work on /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 14:25:18,717] {scheduler_job.py:1539} INFO - Processing file /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py for tasks to queue
[2020-01-20 14:25:18,718] {logging_mixin.py:112} INFO - [2020-01-20 14:25:18,718] {dagbag.py:403} INFO - Filling up the DagBag from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 14:25:19,179] {scheduler_job.py:1551} INFO - DAG(s) dict_keys(['process_replies']) retrieved from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 14:25:19,235] {scheduler_job.py:1262} INFO - Processing process_replies
[2020-01-20 14:25:19,294] {scheduler_job.py:1272} INFO - Created <DagRun process_replies @ 2020-01-20T02:20:00+00:00: scheduled__2020-01-20T02:20:00+00:00, externally triggered: False>
[2020-01-20 14:25:19,296] {scheduler_job.py:740} INFO - Examining DAG run <DagRun process_replies @ 2020-01-20 02:10:00+00:00: scheduled__2020-01-20T02:10:00+00:00, externally triggered: False>
[2020-01-20 14:25:19,308] {logging_mixin.py:112} INFO - [2020-01-20 14:25:19,308] {dagrun.py:318} INFO - Marking run <DagRun process_replies @ 2020-01-20 02:10:00+00:00: scheduled__2020-01-20T02:10:00+00:00, externally triggered: False> successful
[2020-01-20 14:25:19,310] {scheduler_job.py:740} INFO - Examining DAG run <DagRun process_replies @ 2020-01-20 02:20:00+00:00: scheduled__2020-01-20T02:20:00+00:00, externally triggered: False>
[2020-01-20 14:25:19,331] {scheduler_job.py:440} INFO - Skipping SLA check for <DAG: process_replies> because no tasks in DAG have SLAs
[2020-01-20 14:25:19,334] {scheduler_job.py:1613} INFO - Creating / updating <TaskInstance: process_replies.send_replies 2020-01-20 02:20:00+00:00 [scheduled]> in ORM
[2020-01-20 14:25:19,376] {scheduler_job.py:161} INFO - Processing /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py took 0.681 seconds
[2020-01-20 14:26:17,635] {scheduler_job.py:153} INFO - Started process (PID=6184) to work on /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 14:26:17,645] {scheduler_job.py:1539} INFO - Processing file /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py for tasks to queue
[2020-01-20 14:26:17,646] {logging_mixin.py:112} INFO - [2020-01-20 14:26:17,645] {dagbag.py:403} INFO - Filling up the DagBag from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 14:26:17,716] {scheduler_job.py:1551} INFO - DAG(s) dict_keys(['process_replies']) retrieved from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 14:26:17,740] {scheduler_job.py:1262} INFO - Processing process_replies
[2020-01-20 14:26:17,770] {scheduler_job.py:1272} INFO - Created <DagRun process_replies @ 2020-01-20T02:30:00+00:00: scheduled__2020-01-20T02:30:00+00:00, externally triggered: False>
[2020-01-20 14:26:17,773] {scheduler_job.py:740} INFO - Examining DAG run <DagRun process_replies @ 2020-01-20 02:20:00+00:00: scheduled__2020-01-20T02:20:00+00:00, externally triggered: False>
[2020-01-20 14:26:17,781] {logging_mixin.py:112} INFO - [2020-01-20 14:26:17,781] {dagrun.py:318} INFO - Marking run <DagRun process_replies @ 2020-01-20 02:20:00+00:00: scheduled__2020-01-20T02:20:00+00:00, externally triggered: False> successful
[2020-01-20 14:26:17,784] {scheduler_job.py:740} INFO - Examining DAG run <DagRun process_replies @ 2020-01-20 02:30:00+00:00: scheduled__2020-01-20T02:30:00+00:00, externally triggered: False>
[2020-01-20 14:26:17,794] {scheduler_job.py:440} INFO - Skipping SLA check for <DAG: process_replies> because no tasks in DAG have SLAs
[2020-01-20 14:26:17,799] {scheduler_job.py:1613} INFO - Creating / updating <TaskInstance: process_replies.send_replies 2020-01-20 02:30:00+00:00 [scheduled]> in ORM
[2020-01-20 14:26:17,806] {scheduler_job.py:161} INFO - Processing /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py took 0.171 seconds
[2020-01-20 14:27:17,066] {scheduler_job.py:153} INFO - Started process (PID=6217) to work on /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 14:27:17,073] {scheduler_job.py:1539} INFO - Processing file /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py for tasks to queue
[2020-01-20 14:27:17,074] {logging_mixin.py:112} INFO - [2020-01-20 14:27:17,073] {dagbag.py:403} INFO - Filling up the DagBag from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 14:27:17,335] {scheduler_job.py:1551} INFO - DAG(s) dict_keys(['process_replies']) retrieved from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 14:27:17,373] {scheduler_job.py:1262} INFO - Processing process_replies
[2020-01-20 14:27:17,406] {scheduler_job.py:1272} INFO - Created <DagRun process_replies @ 2020-01-20T02:40:00+00:00: scheduled__2020-01-20T02:40:00+00:00, externally triggered: False>
[2020-01-20 14:27:17,409] {scheduler_job.py:740} INFO - Examining DAG run <DagRun process_replies @ 2020-01-20 02:30:00+00:00: scheduled__2020-01-20T02:30:00+00:00, externally triggered: False>
[2020-01-20 14:27:17,415] {logging_mixin.py:112} INFO - [2020-01-20 14:27:17,415] {dagrun.py:318} INFO - Marking run <DagRun process_replies @ 2020-01-20 02:30:00+00:00: scheduled__2020-01-20T02:30:00+00:00, externally triggered: False> successful
[2020-01-20 14:27:17,418] {scheduler_job.py:740} INFO - Examining DAG run <DagRun process_replies @ 2020-01-20 02:40:00+00:00: scheduled__2020-01-20T02:40:00+00:00, externally triggered: False>
[2020-01-20 14:27:17,428] {scheduler_job.py:440} INFO - Skipping SLA check for <DAG: process_replies> because no tasks in DAG have SLAs
[2020-01-20 14:27:17,433] {scheduler_job.py:1613} INFO - Creating / updating <TaskInstance: process_replies.send_replies 2020-01-20 02:40:00+00:00 [scheduled]> in ORM
[2020-01-20 14:27:17,458] {scheduler_job.py:161} INFO - Processing /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py took 0.392 seconds
[2020-01-20 14:28:15,134] {scheduler_job.py:153} INFO - Started process (PID=6252) to work on /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 14:28:15,142] {scheduler_job.py:1539} INFO - Processing file /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py for tasks to queue
[2020-01-20 14:28:15,143] {logging_mixin.py:112} INFO - [2020-01-20 14:28:15,143] {dagbag.py:403} INFO - Filling up the DagBag from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 14:28:15,196] {scheduler_job.py:1551} INFO - DAG(s) dict_keys(['process_replies']) retrieved from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 14:28:15,218] {scheduler_job.py:1262} INFO - Processing process_replies
[2020-01-20 14:28:15,241] {scheduler_job.py:1272} INFO - Created <DagRun process_replies @ 2020-01-20T02:50:00+00:00: scheduled__2020-01-20T02:50:00+00:00, externally triggered: False>
[2020-01-20 14:28:15,243] {scheduler_job.py:740} INFO - Examining DAG run <DagRun process_replies @ 2020-01-20 02:40:00+00:00: scheduled__2020-01-20T02:40:00+00:00, externally triggered: False>
[2020-01-20 14:28:15,251] {logging_mixin.py:112} INFO - [2020-01-20 14:28:15,250] {dagrun.py:318} INFO - Marking run <DagRun process_replies @ 2020-01-20 02:40:00+00:00: scheduled__2020-01-20T02:40:00+00:00, externally triggered: False> successful
[2020-01-20 14:28:15,254] {scheduler_job.py:740} INFO - Examining DAG run <DagRun process_replies @ 2020-01-20 02:50:00+00:00: scheduled__2020-01-20T02:50:00+00:00, externally triggered: False>
[2020-01-20 14:28:15,263] {scheduler_job.py:440} INFO - Skipping SLA check for <DAG: process_replies> because no tasks in DAG have SLAs
[2020-01-20 14:28:15,266] {scheduler_job.py:1613} INFO - Creating / updating <TaskInstance: process_replies.send_replies 2020-01-20 02:50:00+00:00 [scheduled]> in ORM
[2020-01-20 14:28:15,271] {scheduler_job.py:161} INFO - Processing /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py took 0.137 seconds
[2020-01-20 14:29:12,837] {scheduler_job.py:153} INFO - Started process (PID=6288) to work on /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 14:29:12,845] {scheduler_job.py:1539} INFO - Processing file /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py for tasks to queue
[2020-01-20 14:29:12,846] {logging_mixin.py:112} INFO - [2020-01-20 14:29:12,846] {dagbag.py:403} INFO - Filling up the DagBag from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 14:29:12,915] {scheduler_job.py:1551} INFO - DAG(s) dict_keys(['process_replies']) retrieved from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 14:29:12,935] {scheduler_job.py:1262} INFO - Processing process_replies
[2020-01-20 14:29:12,957] {scheduler_job.py:1272} INFO - Created <DagRun process_replies @ 2020-01-20T03:00:00+00:00: scheduled__2020-01-20T03:00:00+00:00, externally triggered: False>
[2020-01-20 14:29:12,959] {scheduler_job.py:740} INFO - Examining DAG run <DagRun process_replies @ 2020-01-20 02:50:00+00:00: scheduled__2020-01-20T02:50:00+00:00, externally triggered: False>
[2020-01-20 14:29:12,965] {logging_mixin.py:112} INFO - [2020-01-20 14:29:12,964] {dagrun.py:318} INFO - Marking run <DagRun process_replies @ 2020-01-20 02:50:00+00:00: scheduled__2020-01-20T02:50:00+00:00, externally triggered: False> successful
[2020-01-20 14:29:12,967] {scheduler_job.py:740} INFO - Examining DAG run <DagRun process_replies @ 2020-01-20 03:00:00+00:00: scheduled__2020-01-20T03:00:00+00:00, externally triggered: False>
[2020-01-20 14:29:12,978] {scheduler_job.py:440} INFO - Skipping SLA check for <DAG: process_replies> because no tasks in DAG have SLAs
[2020-01-20 14:29:12,982] {scheduler_job.py:1613} INFO - Creating / updating <TaskInstance: process_replies.send_replies 2020-01-20 03:00:00+00:00 [scheduled]> in ORM
[2020-01-20 14:29:12,990] {scheduler_job.py:161} INFO - Processing /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py took 0.153 seconds
[2020-01-20 14:30:11,292] {scheduler_job.py:153} INFO - Started process (PID=6319) to work on /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 14:30:11,298] {scheduler_job.py:1539} INFO - Processing file /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py for tasks to queue
[2020-01-20 14:30:11,299] {logging_mixin.py:112} INFO - [2020-01-20 14:30:11,299] {dagbag.py:403} INFO - Filling up the DagBag from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 14:30:11,363] {scheduler_job.py:1551} INFO - DAG(s) dict_keys(['process_replies']) retrieved from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 14:30:11,383] {scheduler_job.py:1262} INFO - Processing process_replies
[2020-01-20 14:30:11,405] {scheduler_job.py:1272} INFO - Created <DagRun process_replies @ 2020-01-20T03:10:00+00:00: scheduled__2020-01-20T03:10:00+00:00, externally triggered: False>
[2020-01-20 14:30:11,408] {scheduler_job.py:740} INFO - Examining DAG run <DagRun process_replies @ 2020-01-20 03:00:00+00:00: scheduled__2020-01-20T03:00:00+00:00, externally triggered: False>
[2020-01-20 14:30:11,415] {logging_mixin.py:112} INFO - [2020-01-20 14:30:11,414] {dagrun.py:318} INFO - Marking run <DagRun process_replies @ 2020-01-20 03:00:00+00:00: scheduled__2020-01-20T03:00:00+00:00, externally triggered: False> successful
[2020-01-20 14:30:11,417] {scheduler_job.py:740} INFO - Examining DAG run <DagRun process_replies @ 2020-01-20 03:10:00+00:00: scheduled__2020-01-20T03:10:00+00:00, externally triggered: False>
[2020-01-20 14:30:11,426] {scheduler_job.py:440} INFO - Skipping SLA check for <DAG: process_replies> because no tasks in DAG have SLAs
[2020-01-20 14:30:11,430] {scheduler_job.py:1613} INFO - Creating / updating <TaskInstance: process_replies.send_replies 2020-01-20 03:10:00+00:00 [scheduled]> in ORM
[2020-01-20 14:30:11,435] {scheduler_job.py:161} INFO - Processing /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py took 0.143 seconds
[2020-01-20 14:31:22,751] {scheduler_job.py:153} INFO - Started process (PID=6357) to work on /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 14:31:22,760] {scheduler_job.py:1539} INFO - Processing file /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py for tasks to queue
[2020-01-20 14:31:22,761] {logging_mixin.py:112} INFO - [2020-01-20 14:31:22,760] {dagbag.py:403} INFO - Filling up the DagBag from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 14:31:22,856] {scheduler_job.py:1551} INFO - DAG(s) dict_keys(['process_replies']) retrieved from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 14:31:22,887] {scheduler_job.py:1262} INFO - Processing process_replies
[2020-01-20 14:31:22,918] {scheduler_job.py:1272} INFO - Created <DagRun process_replies @ 2020-01-20T03:20:00+00:00: scheduled__2020-01-20T03:20:00+00:00, externally triggered: False>
[2020-01-20 14:31:22,921] {scheduler_job.py:740} INFO - Examining DAG run <DagRun process_replies @ 2020-01-20 03:10:00+00:00: scheduled__2020-01-20T03:10:00+00:00, externally triggered: False>
[2020-01-20 14:31:22,927] {logging_mixin.py:112} INFO - [2020-01-20 14:31:22,927] {dagrun.py:318} INFO - Marking run <DagRun process_replies @ 2020-01-20 03:10:00+00:00: scheduled__2020-01-20T03:10:00+00:00, externally triggered: False> successful
[2020-01-20 14:31:22,939] {scheduler_job.py:740} INFO - Examining DAG run <DagRun process_replies @ 2020-01-20 03:20:00+00:00: scheduled__2020-01-20T03:20:00+00:00, externally triggered: False>
[2020-01-20 14:31:22,955] {scheduler_job.py:440} INFO - Skipping SLA check for <DAG: process_replies> because no tasks in DAG have SLAs
[2020-01-20 14:31:22,958] {scheduler_job.py:1613} INFO - Creating / updating <TaskInstance: process_replies.send_replies 2020-01-20 03:20:00+00:00 [scheduled]> in ORM
[2020-01-20 14:31:22,967] {scheduler_job.py:161} INFO - Processing /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py took 0.217 seconds
[2020-01-20 14:32:19,268] {scheduler_job.py:153} INFO - Started process (PID=6389) to work on /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 14:32:19,277] {scheduler_job.py:1539} INFO - Processing file /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py for tasks to queue
[2020-01-20 14:32:19,278] {logging_mixin.py:112} INFO - [2020-01-20 14:32:19,278] {dagbag.py:403} INFO - Filling up the DagBag from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 14:32:19,355] {scheduler_job.py:1551} INFO - DAG(s) dict_keys(['process_replies']) retrieved from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 14:32:19,381] {scheduler_job.py:1262} INFO - Processing process_replies
[2020-01-20 14:32:19,412] {scheduler_job.py:1272} INFO - Created <DagRun process_replies @ 2020-01-20T03:30:00+00:00: scheduled__2020-01-20T03:30:00+00:00, externally triggered: False>
[2020-01-20 14:32:19,415] {scheduler_job.py:740} INFO - Examining DAG run <DagRun process_replies @ 2020-01-20 03:20:00+00:00: scheduled__2020-01-20T03:20:00+00:00, externally triggered: False>
[2020-01-20 14:32:19,424] {logging_mixin.py:112} INFO - [2020-01-20 14:32:19,423] {dagrun.py:318} INFO - Marking run <DagRun process_replies @ 2020-01-20 03:20:00+00:00: scheduled__2020-01-20T03:20:00+00:00, externally triggered: False> successful
[2020-01-20 14:32:19,428] {scheduler_job.py:740} INFO - Examining DAG run <DagRun process_replies @ 2020-01-20 03:30:00+00:00: scheduled__2020-01-20T03:30:00+00:00, externally triggered: False>
[2020-01-20 14:32:19,439] {scheduler_job.py:440} INFO - Skipping SLA check for <DAG: process_replies> because no tasks in DAG have SLAs
[2020-01-20 14:32:19,445] {scheduler_job.py:1613} INFO - Creating / updating <TaskInstance: process_replies.send_replies 2020-01-20 03:30:00+00:00 [scheduled]> in ORM
[2020-01-20 14:32:19,454] {scheduler_job.py:161} INFO - Processing /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py took 0.186 seconds
[2020-01-20 14:33:19,283] {scheduler_job.py:153} INFO - Started process (PID=6437) to work on /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 14:33:19,290] {scheduler_job.py:1539} INFO - Processing file /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py for tasks to queue
[2020-01-20 14:33:19,292] {logging_mixin.py:112} INFO - [2020-01-20 14:33:19,291] {dagbag.py:403} INFO - Filling up the DagBag from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 14:33:19,433] {scheduler_job.py:1551} INFO - DAG(s) dict_keys(['process_replies']) retrieved from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 14:33:19,488] {scheduler_job.py:1262} INFO - Processing process_replies
[2020-01-20 14:33:19,534] {scheduler_job.py:1272} INFO - Created <DagRun process_replies @ 2020-01-20T03:40:00+00:00: scheduled__2020-01-20T03:40:00+00:00, externally triggered: False>
[2020-01-20 14:33:19,538] {scheduler_job.py:740} INFO - Examining DAG run <DagRun process_replies @ 2020-01-20 03:30:00+00:00: scheduled__2020-01-20T03:30:00+00:00, externally triggered: False>
[2020-01-20 14:33:19,549] {logging_mixin.py:112} INFO - [2020-01-20 14:33:19,549] {dagrun.py:318} INFO - Marking run <DagRun process_replies @ 2020-01-20 03:30:00+00:00: scheduled__2020-01-20T03:30:00+00:00, externally triggered: False> successful
[2020-01-20 14:33:19,552] {scheduler_job.py:740} INFO - Examining DAG run <DagRun process_replies @ 2020-01-20 03:40:00+00:00: scheduled__2020-01-20T03:40:00+00:00, externally triggered: False>
[2020-01-20 14:33:19,563] {scheduler_job.py:440} INFO - Skipping SLA check for <DAG: process_replies> because no tasks in DAG have SLAs
[2020-01-20 14:33:19,566] {scheduler_job.py:1613} INFO - Creating / updating <TaskInstance: process_replies.send_replies 2020-01-20 03:40:00+00:00 [scheduled]> in ORM
[2020-01-20 14:33:19,572] {scheduler_job.py:161} INFO - Processing /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py took 0.289 seconds
[2020-01-20 14:34:17,446] {scheduler_job.py:153} INFO - Started process (PID=6477) to work on /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 14:34:17,453] {scheduler_job.py:1539} INFO - Processing file /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py for tasks to queue
[2020-01-20 14:34:17,454] {logging_mixin.py:112} INFO - [2020-01-20 14:34:17,454] {dagbag.py:403} INFO - Filling up the DagBag from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 14:34:17,505] {scheduler_job.py:1551} INFO - DAG(s) dict_keys(['process_replies']) retrieved from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 14:34:17,527] {scheduler_job.py:1262} INFO - Processing process_replies
[2020-01-20 14:34:17,551] {scheduler_job.py:1272} INFO - Created <DagRun process_replies @ 2020-01-20T03:50:00+00:00: scheduled__2020-01-20T03:50:00+00:00, externally triggered: False>
[2020-01-20 14:34:17,553] {scheduler_job.py:740} INFO - Examining DAG run <DagRun process_replies @ 2020-01-20 03:40:00+00:00: scheduled__2020-01-20T03:40:00+00:00, externally triggered: False>
[2020-01-20 14:34:17,558] {logging_mixin.py:112} INFO - [2020-01-20 14:34:17,558] {dagrun.py:318} INFO - Marking run <DagRun process_replies @ 2020-01-20 03:40:00+00:00: scheduled__2020-01-20T03:40:00+00:00, externally triggered: False> successful
[2020-01-20 14:34:17,561] {scheduler_job.py:740} INFO - Examining DAG run <DagRun process_replies @ 2020-01-20 03:50:00+00:00: scheduled__2020-01-20T03:50:00+00:00, externally triggered: False>
[2020-01-20 14:34:17,570] {scheduler_job.py:440} INFO - Skipping SLA check for <DAG: process_replies> because no tasks in DAG have SLAs
[2020-01-20 14:34:17,574] {scheduler_job.py:1613} INFO - Creating / updating <TaskInstance: process_replies.send_replies 2020-01-20 03:50:00+00:00 [scheduled]> in ORM
[2020-01-20 14:34:17,580] {scheduler_job.py:161} INFO - Processing /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py took 0.134 seconds
[2020-01-20 14:41:10,615] {scheduler_job.py:153} INFO - Started process (PID=6583) to work on /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 14:41:10,626] {scheduler_job.py:1539} INFO - Processing file /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py for tasks to queue
[2020-01-20 14:41:10,627] {logging_mixin.py:112} INFO - [2020-01-20 14:41:10,627] {dagbag.py:403} INFO - Filling up the DagBag from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 14:41:10,689] {scheduler_job.py:1551} INFO - DAG(s) dict_keys(['process_replies']) retrieved from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 14:41:10,708] {scheduler_job.py:161} INFO - Processing /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py took 0.093 seconds
[2020-01-20 14:41:56,726] {scheduler_job.py:153} INFO - Started process (PID=6609) to work on /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 14:41:56,734] {scheduler_job.py:1539} INFO - Processing file /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py for tasks to queue
[2020-01-20 14:41:56,735] {logging_mixin.py:112} INFO - [2020-01-20 14:41:56,735] {dagbag.py:403} INFO - Filling up the DagBag from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 14:41:56,788] {scheduler_job.py:1551} INFO - DAG(s) dict_keys(['process_replies']) retrieved from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 14:41:56,805] {scheduler_job.py:161} INFO - Processing /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py took 0.079 seconds
[2020-01-20 14:42:42,849] {scheduler_job.py:153} INFO - Started process (PID=6646) to work on /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 14:42:42,856] {scheduler_job.py:1539} INFO - Processing file /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py for tasks to queue
[2020-01-20 14:42:42,857] {logging_mixin.py:112} INFO - [2020-01-20 14:42:42,857] {dagbag.py:403} INFO - Filling up the DagBag from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 14:42:42,918] {scheduler_job.py:1551} INFO - DAG(s) dict_keys(['process_replies']) retrieved from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 14:42:42,936] {scheduler_job.py:161} INFO - Processing /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py took 0.087 seconds
[2020-01-20 14:43:29,009] {scheduler_job.py:153} INFO - Started process (PID=6682) to work on /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 14:43:29,016] {scheduler_job.py:1539} INFO - Processing file /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py for tasks to queue
[2020-01-20 14:43:29,017] {logging_mixin.py:112} INFO - [2020-01-20 14:43:29,016] {dagbag.py:403} INFO - Filling up the DagBag from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 14:43:29,115] {scheduler_job.py:1551} INFO - DAG(s) dict_keys(['process_replies']) retrieved from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 14:43:29,146] {scheduler_job.py:161} INFO - Processing /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py took 0.137 seconds
[2020-01-20 14:44:15,121] {scheduler_job.py:153} INFO - Started process (PID=6707) to work on /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 14:44:15,136] {scheduler_job.py:1539} INFO - Processing file /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py for tasks to queue
[2020-01-20 14:44:15,137] {logging_mixin.py:112} INFO - [2020-01-20 14:44:15,136] {dagbag.py:403} INFO - Filling up the DagBag from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 14:44:15,395] {scheduler_job.py:1551} INFO - DAG(s) dict_keys(['process_replies']) retrieved from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 14:44:15,452] {scheduler_job.py:161} INFO - Processing /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py took 0.330 seconds
[2020-01-20 14:45:01,363] {scheduler_job.py:153} INFO - Started process (PID=6737) to work on /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 14:45:01,395] {scheduler_job.py:1539} INFO - Processing file /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py for tasks to queue
[2020-01-20 14:45:01,396] {logging_mixin.py:112} INFO - [2020-01-20 14:45:01,396] {dagbag.py:403} INFO - Filling up the DagBag from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 14:45:01,693] {scheduler_job.py:1551} INFO - DAG(s) dict_keys(['process_replies']) retrieved from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 14:45:01,754] {scheduler_job.py:161} INFO - Processing /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py took 0.392 seconds
[2020-01-20 14:46:00,693] {scheduler_job.py:153} INFO - Started process (PID=6775) to work on /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 14:46:00,701] {scheduler_job.py:1539} INFO - Processing file /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py for tasks to queue
[2020-01-20 14:46:00,703] {logging_mixin.py:112} INFO - [2020-01-20 14:46:00,702] {dagbag.py:403} INFO - Filling up the DagBag from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 14:46:00,827] {scheduler_job.py:1551} INFO - DAG(s) dict_keys(['process_replies']) retrieved from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 14:46:00,851] {scheduler_job.py:161} INFO - Processing /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py took 0.158 seconds
[2020-01-20 14:46:46,831] {scheduler_job.py:153} INFO - Started process (PID=6799) to work on /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 14:46:46,840] {scheduler_job.py:1539} INFO - Processing file /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py for tasks to queue
[2020-01-20 14:46:46,842] {logging_mixin.py:112} INFO - [2020-01-20 14:46:46,841] {dagbag.py:403} INFO - Filling up the DagBag from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 14:46:46,897] {scheduler_job.py:1551} INFO - DAG(s) dict_keys(['process_replies']) retrieved from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 14:46:46,912] {scheduler_job.py:161} INFO - Processing /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py took 0.082 seconds
[2020-01-20 14:47:32,961] {scheduler_job.py:153} INFO - Started process (PID=6836) to work on /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 14:47:32,970] {scheduler_job.py:1539} INFO - Processing file /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py for tasks to queue
[2020-01-20 14:47:32,971] {logging_mixin.py:112} INFO - [2020-01-20 14:47:32,970] {dagbag.py:403} INFO - Filling up the DagBag from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 14:47:33,103] {scheduler_job.py:1551} INFO - DAG(s) dict_keys(['process_replies']) retrieved from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 14:47:33,125] {scheduler_job.py:161} INFO - Processing /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py took 0.164 seconds
[2020-01-20 14:48:19,073] {scheduler_job.py:153} INFO - Started process (PID=6862) to work on /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 14:48:19,080] {scheduler_job.py:1539} INFO - Processing file /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py for tasks to queue
[2020-01-20 14:48:19,081] {logging_mixin.py:112} INFO - [2020-01-20 14:48:19,081] {dagbag.py:403} INFO - Filling up the DagBag from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 14:48:19,139] {scheduler_job.py:1551} INFO - DAG(s) dict_keys(['process_replies']) retrieved from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 14:48:19,159] {scheduler_job.py:161} INFO - Processing /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py took 0.085 seconds
[2020-01-20 14:49:05,186] {scheduler_job.py:153} INFO - Started process (PID=6892) to work on /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 14:49:05,196] {scheduler_job.py:1539} INFO - Processing file /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py for tasks to queue
[2020-01-20 14:49:05,197] {logging_mixin.py:112} INFO - [2020-01-20 14:49:05,196] {dagbag.py:403} INFO - Filling up the DagBag from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 14:49:05,363] {scheduler_job.py:1551} INFO - DAG(s) dict_keys(['process_replies']) retrieved from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 14:49:05,382] {scheduler_job.py:161} INFO - Processing /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py took 0.196 seconds
[2020-01-20 14:49:51,310] {scheduler_job.py:153} INFO - Started process (PID=6919) to work on /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 14:49:51,316] {scheduler_job.py:1539} INFO - Processing file /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py for tasks to queue
[2020-01-20 14:49:51,317] {logging_mixin.py:112} INFO - [2020-01-20 14:49:51,317] {dagbag.py:403} INFO - Filling up the DagBag from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 14:49:51,369] {scheduler_job.py:1551} INFO - DAG(s) dict_keys(['process_replies']) retrieved from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 14:49:51,384] {scheduler_job.py:161} INFO - Processing /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py took 0.074 seconds
[2020-01-20 14:50:37,447] {scheduler_job.py:153} INFO - Started process (PID=6948) to work on /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 14:50:37,459] {scheduler_job.py:1539} INFO - Processing file /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py for tasks to queue
[2020-01-20 14:50:37,460] {logging_mixin.py:112} INFO - [2020-01-20 14:50:37,459] {dagbag.py:403} INFO - Filling up the DagBag from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 14:50:37,525] {scheduler_job.py:1551} INFO - DAG(s) dict_keys(['process_replies']) retrieved from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 14:50:37,546] {scheduler_job.py:161} INFO - Processing /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py took 0.098 seconds
[2020-01-20 14:51:23,567] {scheduler_job.py:153} INFO - Started process (PID=6978) to work on /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 14:51:23,574] {scheduler_job.py:1539} INFO - Processing file /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py for tasks to queue
[2020-01-20 14:51:23,575] {logging_mixin.py:112} INFO - [2020-01-20 14:51:23,574] {dagbag.py:403} INFO - Filling up the DagBag from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 14:51:23,631] {scheduler_job.py:1551} INFO - DAG(s) dict_keys(['process_replies']) retrieved from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 14:51:23,647] {scheduler_job.py:161} INFO - Processing /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py took 0.080 seconds
[2020-01-20 14:52:09,682] {scheduler_job.py:153} INFO - Started process (PID=7007) to work on /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 14:52:09,690] {scheduler_job.py:1539} INFO - Processing file /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py for tasks to queue
[2020-01-20 14:52:09,691] {logging_mixin.py:112} INFO - [2020-01-20 14:52:09,690] {dagbag.py:403} INFO - Filling up the DagBag from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 14:52:09,742] {scheduler_job.py:1551} INFO - DAG(s) dict_keys(['process_replies']) retrieved from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 14:52:09,757] {scheduler_job.py:161} INFO - Processing /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py took 0.076 seconds
[2020-01-20 14:52:55,798] {scheduler_job.py:153} INFO - Started process (PID=7039) to work on /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 14:52:55,805] {scheduler_job.py:1539} INFO - Processing file /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py for tasks to queue
[2020-01-20 14:52:55,806] {logging_mixin.py:112} INFO - [2020-01-20 14:52:55,806] {dagbag.py:403} INFO - Filling up the DagBag from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 14:52:56,016] {scheduler_job.py:1551} INFO - DAG(s) dict_keys(['process_replies']) retrieved from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 14:52:56,033] {scheduler_job.py:161} INFO - Processing /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py took 0.235 seconds
[2020-01-20 14:53:41,936] {scheduler_job.py:153} INFO - Started process (PID=7069) to work on /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 14:53:41,944] {scheduler_job.py:1539} INFO - Processing file /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py for tasks to queue
[2020-01-20 14:53:41,945] {logging_mixin.py:112} INFO - [2020-01-20 14:53:41,945] {dagbag.py:403} INFO - Filling up the DagBag from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 14:53:42,310] {scheduler_job.py:1551} INFO - DAG(s) dict_keys(['process_replies']) retrieved from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 14:53:42,349] {scheduler_job.py:161} INFO - Processing /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py took 0.413 seconds
[2020-01-20 14:54:28,083] {scheduler_job.py:153} INFO - Started process (PID=7112) to work on /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 14:54:28,091] {scheduler_job.py:1539} INFO - Processing file /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py for tasks to queue
[2020-01-20 14:54:28,095] {logging_mixin.py:112} INFO - [2020-01-20 14:54:28,094] {dagbag.py:403} INFO - Filling up the DagBag from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 14:54:28,263] {scheduler_job.py:1551} INFO - DAG(s) dict_keys(['process_replies']) retrieved from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 14:54:28,281] {scheduler_job.py:161} INFO - Processing /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py took 0.198 seconds
[2020-01-20 14:55:14,224] {scheduler_job.py:153} INFO - Started process (PID=7138) to work on /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 14:55:14,230] {scheduler_job.py:1539} INFO - Processing file /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py for tasks to queue
[2020-01-20 14:55:14,231] {logging_mixin.py:112} INFO - [2020-01-20 14:55:14,231] {dagbag.py:403} INFO - Filling up the DagBag from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 14:55:14,288] {scheduler_job.py:1551} INFO - DAG(s) dict_keys(['process_replies']) retrieved from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 14:55:14,305] {scheduler_job.py:161} INFO - Processing /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py took 0.081 seconds
[2020-01-20 14:56:00,337] {scheduler_job.py:153} INFO - Started process (PID=7162) to work on /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 14:56:00,344] {scheduler_job.py:1539} INFO - Processing file /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py for tasks to queue
[2020-01-20 14:56:00,344] {logging_mixin.py:112} INFO - [2020-01-20 14:56:00,344] {dagbag.py:403} INFO - Filling up the DagBag from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 14:56:00,518] {scheduler_job.py:1551} INFO - DAG(s) dict_keys(['process_replies']) retrieved from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 14:56:00,538] {scheduler_job.py:161} INFO - Processing /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py took 0.201 seconds
[2020-01-20 14:56:46,480] {scheduler_job.py:153} INFO - Started process (PID=7186) to work on /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 14:56:46,487] {scheduler_job.py:1539} INFO - Processing file /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py for tasks to queue
[2020-01-20 14:56:46,488] {logging_mixin.py:112} INFO - [2020-01-20 14:56:46,488] {dagbag.py:403} INFO - Filling up the DagBag from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 14:56:46,544] {scheduler_job.py:1551} INFO - DAG(s) dict_keys(['process_replies']) retrieved from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 14:56:46,562] {scheduler_job.py:161} INFO - Processing /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py took 0.081 seconds
[2020-01-20 14:57:32,615] {scheduler_job.py:153} INFO - Started process (PID=7224) to work on /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 14:57:32,624] {scheduler_job.py:1539} INFO - Processing file /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py for tasks to queue
[2020-01-20 14:57:32,625] {logging_mixin.py:112} INFO - [2020-01-20 14:57:32,625] {dagbag.py:403} INFO - Filling up the DagBag from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 14:57:32,776] {scheduler_job.py:1551} INFO - DAG(s) dict_keys(['process_replies']) retrieved from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 14:57:32,794] {scheduler_job.py:161} INFO - Processing /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py took 0.179 seconds
[2020-01-20 14:58:18,726] {scheduler_job.py:153} INFO - Started process (PID=7255) to work on /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 14:58:18,732] {scheduler_job.py:1539} INFO - Processing file /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py for tasks to queue
[2020-01-20 14:58:18,733] {logging_mixin.py:112} INFO - [2020-01-20 14:58:18,732] {dagbag.py:403} INFO - Filling up the DagBag from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 14:58:18,940] {scheduler_job.py:1551} INFO - DAG(s) dict_keys(['process_replies']) retrieved from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 14:58:18,957] {scheduler_job.py:161} INFO - Processing /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py took 0.231 seconds
[2020-01-20 14:59:17,682] {scheduler_job.py:153} INFO - Started process (PID=7291) to work on /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 14:59:17,690] {scheduler_job.py:1539} INFO - Processing file /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py for tasks to queue
[2020-01-20 14:59:17,691] {logging_mixin.py:112} INFO - [2020-01-20 14:59:17,691] {dagbag.py:403} INFO - Filling up the DagBag from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 14:59:17,753] {scheduler_job.py:1551} INFO - DAG(s) dict_keys(['process_replies']) retrieved from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 14:59:17,770] {scheduler_job.py:161} INFO - Processing /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py took 0.089 seconds
[2020-01-20 15:00:03,810] {scheduler_job.py:153} INFO - Started process (PID=7320) to work on /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 15:00:03,824] {scheduler_job.py:1539} INFO - Processing file /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py for tasks to queue
[2020-01-20 15:00:03,825] {logging_mixin.py:112} INFO - [2020-01-20 15:00:03,825] {dagbag.py:403} INFO - Filling up the DagBag from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 15:00:03,954] {scheduler_job.py:1551} INFO - DAG(s) dict_keys(['process_replies']) retrieved from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 15:00:03,969] {scheduler_job.py:161} INFO - Processing /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py took 0.159 seconds
[2020-01-20 15:01:09,875] {logging_mixin.py:112} INFO - [2020-01-20 15:01:09,874] {settings.py:213} DEBUG - Setting up DB connection pool (PID 7372)
[2020-01-20 15:01:09,879] {scheduler_job.py:153} INFO - Started process (PID=7372) to work on /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 15:01:09,884] {scheduler_job.py:1539} INFO - Processing file /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py for tasks to queue
[2020-01-20 15:01:09,886] {logging_mixin.py:112} INFO - [2020-01-20 15:01:09,885] {dagbag.py:403} INFO - Filling up the DagBag from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 15:01:09,888] {logging_mixin.py:112} INFO - [2020-01-20 15:01:09,888] {dagbag.py:232} DEBUG - Importing /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 15:01:10,125] {logging_mixin.py:112} INFO - [2020-01-20 15:01:10,124] {dagbag.py:370} DEBUG - Loaded DAG <DAG: process_replies>
[2020-01-20 15:01:10,125] {scheduler_job.py:1551} INFO - DAG(s) dict_keys(['process_replies']) retrieved from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 15:01:10,146] {scheduler_job.py:161} INFO - Processing /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py took 0.267 seconds
[2020-01-20 15:02:08,452] {logging_mixin.py:112} INFO - [2020-01-20 15:02:08,452] {settings.py:213} DEBUG - Setting up DB connection pool (PID 7404)
[2020-01-20 15:02:08,458] {scheduler_job.py:153} INFO - Started process (PID=7404) to work on /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 15:02:08,464] {scheduler_job.py:1539} INFO - Processing file /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py for tasks to queue
[2020-01-20 15:02:08,465] {logging_mixin.py:112} INFO - [2020-01-20 15:02:08,465] {dagbag.py:403} INFO - Filling up the DagBag from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 15:02:08,468] {logging_mixin.py:112} INFO - [2020-01-20 15:02:08,467] {dagbag.py:232} DEBUG - Importing /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 15:02:08,525] {logging_mixin.py:112} INFO - [2020-01-20 15:02:08,525] {dagbag.py:370} DEBUG - Loaded DAG <DAG: process_replies>
[2020-01-20 15:02:08,527] {scheduler_job.py:1551} INFO - DAG(s) dict_keys(['process_replies']) retrieved from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 15:02:08,548] {scheduler_job.py:161} INFO - Processing /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py took 0.090 seconds
[2020-01-20 15:02:54,604] {logging_mixin.py:112} INFO - [2020-01-20 15:02:54,604] {settings.py:213} DEBUG - Setting up DB connection pool (PID 7439)
[2020-01-20 15:02:54,610] {scheduler_job.py:153} INFO - Started process (PID=7439) to work on /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 15:02:54,616] {scheduler_job.py:1539} INFO - Processing file /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py for tasks to queue
[2020-01-20 15:02:54,617] {logging_mixin.py:112} INFO - [2020-01-20 15:02:54,617] {dagbag.py:403} INFO - Filling up the DagBag from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 15:02:54,619] {logging_mixin.py:112} INFO - [2020-01-20 15:02:54,618] {dagbag.py:232} DEBUG - Importing /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 15:02:54,670] {logging_mixin.py:112} INFO - [2020-01-20 15:02:54,670] {dagbag.py:370} DEBUG - Loaded DAG <DAG: process_replies>
[2020-01-20 15:02:54,671] {scheduler_job.py:1551} INFO - DAG(s) dict_keys(['process_replies']) retrieved from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 15:02:54,689] {scheduler_job.py:161} INFO - Processing /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py took 0.079 seconds
[2020-01-20 15:03:40,744] {logging_mixin.py:112} INFO - [2020-01-20 15:03:40,744] {settings.py:213} DEBUG - Setting up DB connection pool (PID 7482)
[2020-01-20 15:03:40,752] {scheduler_job.py:153} INFO - Started process (PID=7482) to work on /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 15:03:40,762] {scheduler_job.py:1539} INFO - Processing file /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py for tasks to queue
[2020-01-20 15:03:40,763] {logging_mixin.py:112} INFO - [2020-01-20 15:03:40,763] {dagbag.py:403} INFO - Filling up the DagBag from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 15:03:40,765] {logging_mixin.py:112} INFO - [2020-01-20 15:03:40,765] {dagbag.py:232} DEBUG - Importing /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 15:03:40,905] {logging_mixin.py:112} INFO - [2020-01-20 15:03:40,904] {dagbag.py:370} DEBUG - Loaded DAG <DAG: process_replies>
[2020-01-20 15:03:40,906] {scheduler_job.py:1551} INFO - DAG(s) dict_keys(['process_replies']) retrieved from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 15:03:40,924] {scheduler_job.py:161} INFO - Processing /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py took 0.172 seconds
[2020-01-20 15:18:11,981] {scheduler_job.py:153} INFO - Started process (PID=7586) to work on /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 15:18:11,988] {scheduler_job.py:1539} INFO - Processing file /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py for tasks to queue
[2020-01-20 15:18:11,989] {logging_mixin.py:112} INFO - [2020-01-20 15:18:11,988] {dagbag.py:403} INFO - Filling up the DagBag from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 15:18:12,057] {scheduler_job.py:1551} INFO - DAG(s) dict_keys(['process_replies']) retrieved from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 15:18:12,077] {scheduler_job.py:161} INFO - Processing /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py took 0.096 seconds
[2020-01-20 15:19:10,228] {scheduler_job.py:153} INFO - Started process (PID=7620) to work on /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 15:19:10,237] {scheduler_job.py:1539} INFO - Processing file /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py for tasks to queue
[2020-01-20 15:19:10,238] {logging_mixin.py:112} INFO - [2020-01-20 15:19:10,237] {dagbag.py:403} INFO - Filling up the DagBag from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 15:19:10,292] {scheduler_job.py:1551} INFO - DAG(s) dict_keys(['process_replies']) retrieved from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 15:19:10,308] {scheduler_job.py:161} INFO - Processing /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py took 0.080 seconds
[2020-01-20 15:19:56,365] {scheduler_job.py:153} INFO - Started process (PID=7648) to work on /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 15:19:56,372] {scheduler_job.py:1539} INFO - Processing file /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py for tasks to queue
[2020-01-20 15:19:56,373] {logging_mixin.py:112} INFO - [2020-01-20 15:19:56,372] {dagbag.py:403} INFO - Filling up the DagBag from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 15:19:56,559] {scheduler_job.py:1551} INFO - DAG(s) dict_keys(['process_replies']) retrieved from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 15:19:56,576] {scheduler_job.py:161} INFO - Processing /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py took 0.210 seconds
[2020-01-20 15:20:42,484] {scheduler_job.py:153} INFO - Started process (PID=7674) to work on /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 15:20:42,493] {scheduler_job.py:1539} INFO - Processing file /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py for tasks to queue
[2020-01-20 15:20:42,494] {logging_mixin.py:112} INFO - [2020-01-20 15:20:42,494] {dagbag.py:403} INFO - Filling up the DagBag from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 15:20:42,557] {scheduler_job.py:1551} INFO - DAG(s) dict_keys(['process_replies']) retrieved from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 15:20:42,574] {scheduler_job.py:161} INFO - Processing /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py took 0.090 seconds
[2020-01-20 15:21:28,612] {scheduler_job.py:153} INFO - Started process (PID=7703) to work on /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 15:21:28,621] {scheduler_job.py:1539} INFO - Processing file /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py for tasks to queue
[2020-01-20 15:21:28,622] {logging_mixin.py:112} INFO - [2020-01-20 15:21:28,622] {dagbag.py:403} INFO - Filling up the DagBag from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 15:21:28,842] {scheduler_job.py:1551} INFO - DAG(s) dict_keys(['process_replies']) retrieved from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 15:21:28,858] {scheduler_job.py:161} INFO - Processing /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py took 0.246 seconds
[2020-01-20 15:23:22,187] {scheduler_job.py:153} INFO - Started process (PID=7763) to work on /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 15:23:22,198] {scheduler_job.py:1539} INFO - Processing file /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py for tasks to queue
[2020-01-20 15:23:22,200] {logging_mixin.py:112} INFO - [2020-01-20 15:23:22,199] {dagbag.py:403} INFO - Filling up the DagBag from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 15:23:22,309] {scheduler_job.py:1551} INFO - DAG(s) dict_keys(['process_replies']) retrieved from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 15:23:22,337] {scheduler_job.py:161} INFO - Processing /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py took 0.150 seconds
[2020-01-20 15:24:21,443] {scheduler_job.py:153} INFO - Started process (PID=7803) to work on /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 15:24:21,451] {scheduler_job.py:1539} INFO - Processing file /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py for tasks to queue
[2020-01-20 15:24:21,453] {logging_mixin.py:112} INFO - [2020-01-20 15:24:21,452] {dagbag.py:403} INFO - Filling up the DagBag from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 15:24:21,678] {scheduler_job.py:1551} INFO - DAG(s) dict_keys(['process_replies']) retrieved from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 15:24:21,700] {scheduler_job.py:161} INFO - Processing /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py took 0.257 seconds
[2020-01-20 15:25:07,548] {scheduler_job.py:153} INFO - Started process (PID=7831) to work on /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 15:25:07,558] {scheduler_job.py:1539} INFO - Processing file /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py for tasks to queue
[2020-01-20 15:25:07,558] {logging_mixin.py:112} INFO - [2020-01-20 15:25:07,558] {dagbag.py:403} INFO - Filling up the DagBag from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 15:25:07,658] {scheduler_job.py:1551} INFO - DAG(s) dict_keys(['process_replies']) retrieved from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 15:25:07,677] {scheduler_job.py:161} INFO - Processing /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py took 0.129 seconds
[2020-01-20 15:25:53,665] {scheduler_job.py:153} INFO - Started process (PID=7857) to work on /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 15:25:53,673] {scheduler_job.py:1539} INFO - Processing file /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py for tasks to queue
[2020-01-20 15:25:53,674] {logging_mixin.py:112} INFO - [2020-01-20 15:25:53,674] {dagbag.py:403} INFO - Filling up the DagBag from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 15:25:53,729] {scheduler_job.py:1551} INFO - DAG(s) dict_keys(['process_replies']) retrieved from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 15:25:53,744] {scheduler_job.py:161} INFO - Processing /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py took 0.079 seconds
[2020-01-20 15:26:39,800] {scheduler_job.py:153} INFO - Started process (PID=7882) to work on /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 15:26:39,807] {scheduler_job.py:1539} INFO - Processing file /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py for tasks to queue
[2020-01-20 15:26:39,808] {logging_mixin.py:112} INFO - [2020-01-20 15:26:39,808] {dagbag.py:403} INFO - Filling up the DagBag from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 15:26:39,883] {scheduler_job.py:1551} INFO - DAG(s) dict_keys(['process_replies']) retrieved from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 15:26:39,904] {scheduler_job.py:161} INFO - Processing /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py took 0.104 seconds
[2020-01-20 15:27:25,925] {scheduler_job.py:153} INFO - Started process (PID=7909) to work on /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 15:27:25,932] {scheduler_job.py:1539} INFO - Processing file /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py for tasks to queue
[2020-01-20 15:27:25,933] {logging_mixin.py:112} INFO - [2020-01-20 15:27:25,933] {dagbag.py:403} INFO - Filling up the DagBag from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 15:27:26,146] {scheduler_job.py:1551} INFO - DAG(s) dict_keys(['process_replies']) retrieved from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 15:27:26,163] {scheduler_job.py:161} INFO - Processing /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py took 0.238 seconds
[2020-01-20 15:28:12,068] {scheduler_job.py:153} INFO - Started process (PID=7934) to work on /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 15:28:12,076] {scheduler_job.py:1539} INFO - Processing file /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py for tasks to queue
[2020-01-20 15:28:12,077] {logging_mixin.py:112} INFO - [2020-01-20 15:28:12,077] {dagbag.py:403} INFO - Filling up the DagBag from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 15:28:12,130] {scheduler_job.py:1551} INFO - DAG(s) dict_keys(['process_replies']) retrieved from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 15:28:12,145] {scheduler_job.py:161} INFO - Processing /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py took 0.077 seconds
[2020-01-20 15:28:58,178] {scheduler_job.py:153} INFO - Started process (PID=7960) to work on /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 15:28:58,186] {scheduler_job.py:1539} INFO - Processing file /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py for tasks to queue
[2020-01-20 15:28:58,187] {logging_mixin.py:112} INFO - [2020-01-20 15:28:58,187] {dagbag.py:403} INFO - Filling up the DagBag from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 15:28:58,240] {scheduler_job.py:1551} INFO - DAG(s) dict_keys(['process_replies']) retrieved from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 15:28:58,259] {scheduler_job.py:161} INFO - Processing /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py took 0.081 seconds
[2020-01-20 15:29:44,312] {scheduler_job.py:153} INFO - Started process (PID=7987) to work on /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 15:29:44,318] {scheduler_job.py:1539} INFO - Processing file /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py for tasks to queue
[2020-01-20 15:29:44,319] {logging_mixin.py:112} INFO - [2020-01-20 15:29:44,319] {dagbag.py:403} INFO - Filling up the DagBag from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 15:29:44,538] {scheduler_job.py:1551} INFO - DAG(s) dict_keys(['process_replies']) retrieved from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 15:29:44,557] {scheduler_job.py:161} INFO - Processing /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py took 0.245 seconds
[2020-01-20 15:30:43,075] {scheduler_job.py:153} INFO - Started process (PID=8028) to work on /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 15:30:43,083] {scheduler_job.py:1539} INFO - Processing file /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py for tasks to queue
[2020-01-20 15:30:43,084] {logging_mixin.py:112} INFO - [2020-01-20 15:30:43,083] {dagbag.py:403} INFO - Filling up the DagBag from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 15:30:43,135] {scheduler_job.py:1551} INFO - DAG(s) dict_keys(['process_replies']) retrieved from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 15:30:43,153] {scheduler_job.py:161} INFO - Processing /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py took 0.078 seconds
[2020-01-20 15:31:29,211] {scheduler_job.py:153} INFO - Started process (PID=8056) to work on /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 15:31:29,219] {scheduler_job.py:1539} INFO - Processing file /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py for tasks to queue
[2020-01-20 15:31:29,220] {logging_mixin.py:112} INFO - [2020-01-20 15:31:29,219] {dagbag.py:403} INFO - Filling up the DagBag from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 15:31:29,271] {scheduler_job.py:1551} INFO - DAG(s) dict_keys(['process_replies']) retrieved from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 15:31:29,288] {scheduler_job.py:161} INFO - Processing /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py took 0.076 seconds
[2020-01-20 15:32:15,333] {scheduler_job.py:153} INFO - Started process (PID=8082) to work on /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 15:32:15,342] {scheduler_job.py:1539} INFO - Processing file /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py for tasks to queue
[2020-01-20 15:32:15,343] {logging_mixin.py:112} INFO - [2020-01-20 15:32:15,342] {dagbag.py:403} INFO - Filling up the DagBag from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 15:32:15,410] {scheduler_job.py:1551} INFO - DAG(s) dict_keys(['process_replies']) retrieved from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 15:32:15,432] {scheduler_job.py:161} INFO - Processing /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py took 0.098 seconds
[2020-01-20 15:33:01,465] {scheduler_job.py:153} INFO - Started process (PID=8110) to work on /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 15:33:01,473] {scheduler_job.py:1539} INFO - Processing file /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py for tasks to queue
[2020-01-20 15:33:01,474] {logging_mixin.py:112} INFO - [2020-01-20 15:33:01,473] {dagbag.py:403} INFO - Filling up the DagBag from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 15:33:01,688] {scheduler_job.py:1551} INFO - DAG(s) dict_keys(['process_replies']) retrieved from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 15:33:01,716] {scheduler_job.py:161} INFO - Processing /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py took 0.251 seconds
[2020-01-20 15:33:47,586] {scheduler_job.py:153} INFO - Started process (PID=8138) to work on /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 15:33:47,593] {scheduler_job.py:1539} INFO - Processing file /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py for tasks to queue
[2020-01-20 15:33:47,594] {logging_mixin.py:112} INFO - [2020-01-20 15:33:47,594] {dagbag.py:403} INFO - Filling up the DagBag from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 15:33:47,704] {scheduler_job.py:1551} INFO - DAG(s) dict_keys(['process_replies']) retrieved from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 15:33:47,719] {scheduler_job.py:161} INFO - Processing /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py took 0.133 seconds
[2020-01-20 15:34:33,708] {scheduler_job.py:153} INFO - Started process (PID=8164) to work on /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 15:34:33,717] {scheduler_job.py:1539} INFO - Processing file /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py for tasks to queue
[2020-01-20 15:34:33,718] {logging_mixin.py:112} INFO - [2020-01-20 15:34:33,718] {dagbag.py:403} INFO - Filling up the DagBag from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 15:34:33,912] {scheduler_job.py:1551} INFO - DAG(s) dict_keys(['process_replies']) retrieved from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 15:34:33,937] {scheduler_job.py:161} INFO - Processing /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py took 0.229 seconds
[2020-01-20 15:35:19,833] {scheduler_job.py:153} INFO - Started process (PID=8193) to work on /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 15:35:19,844] {scheduler_job.py:1539} INFO - Processing file /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py for tasks to queue
[2020-01-20 15:35:19,845] {logging_mixin.py:112} INFO - [2020-01-20 15:35:19,844] {dagbag.py:403} INFO - Filling up the DagBag from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 15:35:19,915] {scheduler_job.py:1551} INFO - DAG(s) dict_keys(['process_replies']) retrieved from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 15:35:19,935] {scheduler_job.py:161} INFO - Processing /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py took 0.102 seconds
[2020-01-20 15:36:05,973] {scheduler_job.py:153} INFO - Started process (PID=8217) to work on /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 15:36:05,981] {scheduler_job.py:1539} INFO - Processing file /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py for tasks to queue
[2020-01-20 15:36:05,982] {logging_mixin.py:112} INFO - [2020-01-20 15:36:05,982] {dagbag.py:403} INFO - Filling up the DagBag from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 15:36:06,040] {scheduler_job.py:1551} INFO - DAG(s) dict_keys(['process_replies']) retrieved from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 15:36:06,057] {scheduler_job.py:161} INFO - Processing /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py took 0.084 seconds
[2020-01-20 15:36:52,105] {scheduler_job.py:153} INFO - Started process (PID=8245) to work on /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 15:36:52,114] {scheduler_job.py:1539} INFO - Processing file /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py for tasks to queue
[2020-01-20 15:36:52,115] {logging_mixin.py:112} INFO - [2020-01-20 15:36:52,115] {dagbag.py:403} INFO - Filling up the DagBag from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 15:36:52,168] {scheduler_job.py:1551} INFO - DAG(s) dict_keys(['process_replies']) retrieved from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 15:36:52,185] {scheduler_job.py:161} INFO - Processing /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py took 0.080 seconds
[2020-01-20 15:37:38,215] {scheduler_job.py:153} INFO - Started process (PID=8281) to work on /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 15:37:38,229] {scheduler_job.py:1539} INFO - Processing file /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py for tasks to queue
[2020-01-20 15:37:38,232] {logging_mixin.py:112} INFO - [2020-01-20 15:37:38,232] {dagbag.py:403} INFO - Filling up the DagBag from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 15:37:38,487] {scheduler_job.py:1551} INFO - DAG(s) dict_keys(['process_replies']) retrieved from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 15:37:38,550] {scheduler_job.py:161} INFO - Processing /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py took 0.335 seconds
[2020-01-20 15:38:24,345] {scheduler_job.py:153} INFO - Started process (PID=8312) to work on /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 15:38:24,351] {scheduler_job.py:1539} INFO - Processing file /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py for tasks to queue
[2020-01-20 15:38:24,352] {logging_mixin.py:112} INFO - [2020-01-20 15:38:24,352] {dagbag.py:403} INFO - Filling up the DagBag from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 15:38:24,553] {scheduler_job.py:1551} INFO - DAG(s) dict_keys(['process_replies']) retrieved from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 15:38:24,571] {scheduler_job.py:161} INFO - Processing /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py took 0.226 seconds
[2020-01-20 15:39:10,451] {scheduler_job.py:153} INFO - Started process (PID=8348) to work on /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 15:39:10,459] {scheduler_job.py:1539} INFO - Processing file /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py for tasks to queue
[2020-01-20 15:39:10,460] {logging_mixin.py:112} INFO - [2020-01-20 15:39:10,460] {dagbag.py:403} INFO - Filling up the DagBag from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 15:39:10,517] {scheduler_job.py:1551} INFO - DAG(s) dict_keys(['process_replies']) retrieved from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 15:39:10,533] {scheduler_job.py:161} INFO - Processing /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py took 0.083 seconds
[2020-01-20 15:44:09,830] {scheduler_job.py:153} INFO - Started process (PID=8425) to work on /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 15:44:09,840] {scheduler_job.py:1539} INFO - Processing file /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py for tasks to queue
[2020-01-20 15:44:09,841] {logging_mixin.py:112} INFO - [2020-01-20 15:44:09,841] {dagbag.py:403} INFO - Filling up the DagBag from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 15:44:09,942] {scheduler_job.py:1551} INFO - DAG(s) dict_keys(['process_replies']) retrieved from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 15:44:09,962] {scheduler_job.py:161} INFO - Processing /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py took 0.132 seconds
[2020-01-20 15:45:14,503] {scheduler_job.py:153} INFO - Started process (PID=8458) to work on /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 15:45:14,509] {scheduler_job.py:1539} INFO - Processing file /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py for tasks to queue
[2020-01-20 15:45:14,510] {logging_mixin.py:112} INFO - [2020-01-20 15:45:14,509] {dagbag.py:403} INFO - Filling up the DagBag from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 15:45:14,571] {scheduler_job.py:1551} INFO - DAG(s) dict_keys(['process_replies']) retrieved from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 15:45:14,588] {scheduler_job.py:161} INFO - Processing /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py took 0.085 seconds
[2020-01-20 15:46:00,639] {scheduler_job.py:153} INFO - Started process (PID=8483) to work on /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 15:46:00,646] {scheduler_job.py:1539} INFO - Processing file /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py for tasks to queue
[2020-01-20 15:46:00,647] {logging_mixin.py:112} INFO - [2020-01-20 15:46:00,647] {dagbag.py:403} INFO - Filling up the DagBag from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 15:46:00,840] {scheduler_job.py:1551} INFO - DAG(s) dict_keys(['process_replies']) retrieved from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 15:46:00,858] {scheduler_job.py:161} INFO - Processing /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py took 0.219 seconds
[2020-01-20 15:46:46,743] {scheduler_job.py:153} INFO - Started process (PID=8509) to work on /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 15:46:46,751] {scheduler_job.py:1539} INFO - Processing file /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py for tasks to queue
[2020-01-20 15:46:46,752] {logging_mixin.py:112} INFO - [2020-01-20 15:46:46,751] {dagbag.py:403} INFO - Filling up the DagBag from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 15:46:46,819] {scheduler_job.py:1551} INFO - DAG(s) dict_keys(['process_replies']) retrieved from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 15:46:46,837] {scheduler_job.py:161} INFO - Processing /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py took 0.094 seconds
[2020-01-20 15:47:32,883] {scheduler_job.py:153} INFO - Started process (PID=8546) to work on /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 15:47:32,893] {scheduler_job.py:1539} INFO - Processing file /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py for tasks to queue
[2020-01-20 15:47:32,894] {logging_mixin.py:112} INFO - [2020-01-20 15:47:32,894] {dagbag.py:403} INFO - Filling up the DagBag from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 15:47:32,967] {scheduler_job.py:1551} INFO - DAG(s) dict_keys(['process_replies']) retrieved from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 15:47:32,991] {scheduler_job.py:161} INFO - Processing /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py took 0.108 seconds
[2020-01-20 15:48:18,992] {scheduler_job.py:153} INFO - Started process (PID=8573) to work on /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 15:48:18,999] {scheduler_job.py:1539} INFO - Processing file /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py for tasks to queue
[2020-01-20 15:48:19,000] {logging_mixin.py:112} INFO - [2020-01-20 15:48:19,000] {dagbag.py:403} INFO - Filling up the DagBag from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 15:48:19,078] {scheduler_job.py:1551} INFO - DAG(s) dict_keys(['process_replies']) retrieved from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 15:48:19,096] {scheduler_job.py:161} INFO - Processing /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py took 0.103 seconds
[2020-01-20 15:49:05,145] {scheduler_job.py:153} INFO - Started process (PID=8600) to work on /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 15:49:05,153] {scheduler_job.py:1539} INFO - Processing file /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py for tasks to queue
[2020-01-20 15:49:05,153] {logging_mixin.py:112} INFO - [2020-01-20 15:49:05,153] {dagbag.py:403} INFO - Filling up the DagBag from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 15:49:05,213] {scheduler_job.py:1551} INFO - DAG(s) dict_keys(['process_replies']) retrieved from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 15:49:05,228] {scheduler_job.py:161} INFO - Processing /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py took 0.084 seconds
[2020-01-20 15:49:51,268] {scheduler_job.py:153} INFO - Started process (PID=8628) to work on /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 15:49:51,274] {scheduler_job.py:1539} INFO - Processing file /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py for tasks to queue
[2020-01-20 15:49:51,274] {logging_mixin.py:112} INFO - [2020-01-20 15:49:51,274] {dagbag.py:403} INFO - Filling up the DagBag from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 15:49:51,402] {scheduler_job.py:1551} INFO - DAG(s) dict_keys(['process_replies']) retrieved from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 15:49:51,435] {scheduler_job.py:161} INFO - Processing /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py took 0.167 seconds
[2020-01-20 15:50:37,385] {scheduler_job.py:153} INFO - Started process (PID=8666) to work on /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 15:50:37,393] {scheduler_job.py:1539} INFO - Processing file /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py for tasks to queue
[2020-01-20 15:50:37,394] {logging_mixin.py:112} INFO - [2020-01-20 15:50:37,394] {dagbag.py:403} INFO - Filling up the DagBag from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 15:50:37,452] {scheduler_job.py:1551} INFO - DAG(s) dict_keys(['process_replies']) retrieved from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 15:50:37,468] {scheduler_job.py:161} INFO - Processing /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py took 0.084 seconds
[2020-01-20 15:51:23,493] {scheduler_job.py:153} INFO - Started process (PID=8705) to work on /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 15:51:23,500] {scheduler_job.py:1539} INFO - Processing file /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py for tasks to queue
[2020-01-20 15:51:23,500] {logging_mixin.py:112} INFO - [2020-01-20 15:51:23,500] {dagbag.py:403} INFO - Filling up the DagBag from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 15:51:23,630] {scheduler_job.py:1551} INFO - DAG(s) dict_keys(['process_replies']) retrieved from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 15:51:23,646] {scheduler_job.py:161} INFO - Processing /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py took 0.153 seconds
[2020-01-20 15:52:09,611] {scheduler_job.py:153} INFO - Started process (PID=8742) to work on /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 15:52:09,627] {scheduler_job.py:1539} INFO - Processing file /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py for tasks to queue
[2020-01-20 15:52:09,630] {logging_mixin.py:112} INFO - [2020-01-20 15:52:09,629] {dagbag.py:403} INFO - Filling up the DagBag from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 15:52:10,209] {scheduler_job.py:1551} INFO - DAG(s) dict_keys(['process_replies']) retrieved from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 15:52:10,240] {scheduler_job.py:161} INFO - Processing /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py took 0.630 seconds
[2020-01-20 15:52:55,739] {scheduler_job.py:153} INFO - Started process (PID=8780) to work on /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 15:52:55,746] {scheduler_job.py:1539} INFO - Processing file /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py for tasks to queue
[2020-01-20 15:52:55,747] {logging_mixin.py:112} INFO - [2020-01-20 15:52:55,747] {dagbag.py:403} INFO - Filling up the DagBag from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 15:52:55,805] {scheduler_job.py:1551} INFO - DAG(s) dict_keys(['process_replies']) retrieved from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 15:52:55,822] {scheduler_job.py:161} INFO - Processing /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py took 0.082 seconds
[2020-01-20 15:53:41,870] {scheduler_job.py:153} INFO - Started process (PID=8810) to work on /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 15:53:41,876] {scheduler_job.py:1539} INFO - Processing file /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py for tasks to queue
[2020-01-20 15:53:41,877] {logging_mixin.py:112} INFO - [2020-01-20 15:53:41,877] {dagbag.py:403} INFO - Filling up the DagBag from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 15:53:41,934] {scheduler_job.py:1551} INFO - DAG(s) dict_keys(['process_replies']) retrieved from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 15:53:41,948] {scheduler_job.py:161} INFO - Processing /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py took 0.079 seconds
[2020-01-20 15:54:27,988] {scheduler_job.py:153} INFO - Started process (PID=8837) to work on /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 15:54:27,995] {scheduler_job.py:1539} INFO - Processing file /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py for tasks to queue
[2020-01-20 15:54:27,995] {logging_mixin.py:112} INFO - [2020-01-20 15:54:27,995] {dagbag.py:403} INFO - Filling up the DagBag from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 15:54:28,062] {scheduler_job.py:1551} INFO - DAG(s) dict_keys(['process_replies']) retrieved from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 15:54:28,083] {scheduler_job.py:161} INFO - Processing /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py took 0.095 seconds
[2020-01-20 15:55:14,108] {scheduler_job.py:153} INFO - Started process (PID=8861) to work on /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 15:55:14,116] {scheduler_job.py:1539} INFO - Processing file /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py for tasks to queue
[2020-01-20 15:55:14,117] {logging_mixin.py:112} INFO - [2020-01-20 15:55:14,117] {dagbag.py:403} INFO - Filling up the DagBag from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 15:55:14,209] {scheduler_job.py:1551} INFO - DAG(s) dict_keys(['process_replies']) retrieved from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 15:55:14,226] {scheduler_job.py:161} INFO - Processing /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py took 0.118 seconds
[2020-01-20 15:56:00,233] {scheduler_job.py:153} INFO - Started process (PID=8886) to work on /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 15:56:00,246] {scheduler_job.py:1539} INFO - Processing file /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py for tasks to queue
[2020-01-20 15:56:00,247] {logging_mixin.py:112} INFO - [2020-01-20 15:56:00,246] {dagbag.py:403} INFO - Filling up the DagBag from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 15:56:00,316] {scheduler_job.py:1551} INFO - DAG(s) dict_keys(['process_replies']) retrieved from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 15:56:00,331] {scheduler_job.py:161} INFO - Processing /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py took 0.098 seconds
[2020-01-20 15:56:46,371] {scheduler_job.py:153} INFO - Started process (PID=8912) to work on /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 15:56:46,379] {scheduler_job.py:1539} INFO - Processing file /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py for tasks to queue
[2020-01-20 15:56:46,380] {logging_mixin.py:112} INFO - [2020-01-20 15:56:46,380] {dagbag.py:403} INFO - Filling up the DagBag from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 15:56:46,482] {scheduler_job.py:1551} INFO - DAG(s) dict_keys(['process_replies']) retrieved from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 15:56:46,509] {scheduler_job.py:161} INFO - Processing /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py took 0.138 seconds
[2020-01-20 15:57:32,534] {scheduler_job.py:153} INFO - Started process (PID=8939) to work on /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 15:57:32,540] {scheduler_job.py:1539} INFO - Processing file /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py for tasks to queue
[2020-01-20 15:57:32,543] {logging_mixin.py:112} INFO - [2020-01-20 15:57:32,541] {dagbag.py:403} INFO - Filling up the DagBag from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 15:57:32,619] {scheduler_job.py:1551} INFO - DAG(s) dict_keys(['process_replies']) retrieved from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 15:57:32,643] {scheduler_job.py:161} INFO - Processing /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py took 0.109 seconds
[2020-01-20 15:58:18,650] {scheduler_job.py:153} INFO - Started process (PID=8967) to work on /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 15:58:18,660] {scheduler_job.py:1539} INFO - Processing file /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py for tasks to queue
[2020-01-20 15:58:18,661] {logging_mixin.py:112} INFO - [2020-01-20 15:58:18,661] {dagbag.py:403} INFO - Filling up the DagBag from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 15:58:18,725] {scheduler_job.py:1551} INFO - DAG(s) dict_keys(['process_replies']) retrieved from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 15:58:18,745] {scheduler_job.py:161} INFO - Processing /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py took 0.095 seconds
[2020-01-20 15:59:04,792] {scheduler_job.py:153} INFO - Started process (PID=8991) to work on /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 15:59:04,799] {scheduler_job.py:1539} INFO - Processing file /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py for tasks to queue
[2020-01-20 15:59:04,800] {logging_mixin.py:112} INFO - [2020-01-20 15:59:04,800] {dagbag.py:403} INFO - Filling up the DagBag from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 15:59:04,977] {scheduler_job.py:1551} INFO - DAG(s) dict_keys(['process_replies']) retrieved from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 15:59:04,999] {scheduler_job.py:161} INFO - Processing /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py took 0.207 seconds
[2020-01-20 15:59:50,891] {scheduler_job.py:153} INFO - Started process (PID=9025) to work on /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 15:59:50,897] {scheduler_job.py:1539} INFO - Processing file /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py for tasks to queue
[2020-01-20 15:59:50,898] {logging_mixin.py:112} INFO - [2020-01-20 15:59:50,897] {dagbag.py:403} INFO - Filling up the DagBag from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 15:59:50,962] {scheduler_job.py:1551} INFO - DAG(s) dict_keys(['process_replies']) retrieved from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 15:59:50,981] {scheduler_job.py:161} INFO - Processing /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py took 0.090 seconds
[2020-01-20 16:00:37,005] {scheduler_job.py:153} INFO - Started process (PID=9054) to work on /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 16:00:37,014] {scheduler_job.py:1539} INFO - Processing file /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py for tasks to queue
[2020-01-20 16:00:37,015] {logging_mixin.py:112} INFO - [2020-01-20 16:00:37,014] {dagbag.py:403} INFO - Filling up the DagBag from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 16:00:37,237] {scheduler_job.py:1551} INFO - DAG(s) dict_keys(['process_replies']) retrieved from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 16:00:37,255] {scheduler_job.py:161} INFO - Processing /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py took 0.250 seconds
[2020-01-20 16:01:23,153] {scheduler_job.py:153} INFO - Started process (PID=9088) to work on /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 16:01:23,159] {scheduler_job.py:1539} INFO - Processing file /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py for tasks to queue
[2020-01-20 16:01:23,160] {logging_mixin.py:112} INFO - [2020-01-20 16:01:23,160] {dagbag.py:403} INFO - Filling up the DagBag from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 16:01:23,219] {scheduler_job.py:1551} INFO - DAG(s) dict_keys(['process_replies']) retrieved from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 16:01:23,234] {scheduler_job.py:161} INFO - Processing /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py took 0.082 seconds
[2020-01-20 16:02:09,249] {scheduler_job.py:153} INFO - Started process (PID=9119) to work on /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 16:02:09,255] {scheduler_job.py:1539} INFO - Processing file /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py for tasks to queue
[2020-01-20 16:02:09,256] {logging_mixin.py:112} INFO - [2020-01-20 16:02:09,255] {dagbag.py:403} INFO - Filling up the DagBag from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 16:02:09,351] {scheduler_job.py:1551} INFO - DAG(s) dict_keys(['process_replies']) retrieved from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 16:02:09,366] {scheduler_job.py:161} INFO - Processing /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py took 0.117 seconds
[2020-01-20 16:02:55,386] {scheduler_job.py:153} INFO - Started process (PID=9164) to work on /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 16:02:55,394] {scheduler_job.py:1539} INFO - Processing file /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py for tasks to queue
[2020-01-20 16:02:55,395] {logging_mixin.py:112} INFO - [2020-01-20 16:02:55,395] {dagbag.py:403} INFO - Filling up the DagBag from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 16:02:55,466] {scheduler_job.py:1551} INFO - DAG(s) dict_keys(['process_replies']) retrieved from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 16:02:55,482] {scheduler_job.py:161} INFO - Processing /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py took 0.096 seconds
[2020-01-20 16:03:41,507] {scheduler_job.py:153} INFO - Started process (PID=9192) to work on /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 16:03:41,515] {scheduler_job.py:1539} INFO - Processing file /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py for tasks to queue
[2020-01-20 16:03:41,516] {logging_mixin.py:112} INFO - [2020-01-20 16:03:41,516] {dagbag.py:403} INFO - Filling up the DagBag from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 16:03:41,582] {scheduler_job.py:1551} INFO - DAG(s) dict_keys(['process_replies']) retrieved from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 16:03:41,599] {scheduler_job.py:161} INFO - Processing /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py took 0.093 seconds
[2020-01-20 16:04:40,385] {scheduler_job.py:153} INFO - Started process (PID=9236) to work on /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 16:04:40,394] {scheduler_job.py:1539} INFO - Processing file /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py for tasks to queue
[2020-01-20 16:04:40,395] {logging_mixin.py:112} INFO - [2020-01-20 16:04:40,395] {dagbag.py:403} INFO - Filling up the DagBag from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 16:04:40,488] {scheduler_job.py:1551} INFO - DAG(s) dict_keys(['process_replies']) retrieved from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 16:04:40,521] {scheduler_job.py:161} INFO - Processing /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py took 0.135 seconds
[2020-01-20 16:05:26,506] {scheduler_job.py:153} INFO - Started process (PID=9263) to work on /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 16:05:26,513] {scheduler_job.py:1539} INFO - Processing file /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py for tasks to queue
[2020-01-20 16:05:26,514] {logging_mixin.py:112} INFO - [2020-01-20 16:05:26,513] {dagbag.py:403} INFO - Filling up the DagBag from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 16:05:26,728] {scheduler_job.py:1551} INFO - DAG(s) dict_keys(['process_replies']) retrieved from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 16:05:26,746] {scheduler_job.py:161} INFO - Processing /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py took 0.240 seconds
[2020-01-20 16:06:12,655] {scheduler_job.py:153} INFO - Started process (PID=9288) to work on /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 16:06:12,665] {scheduler_job.py:1539} INFO - Processing file /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py for tasks to queue
[2020-01-20 16:06:12,666] {logging_mixin.py:112} INFO - [2020-01-20 16:06:12,665] {dagbag.py:403} INFO - Filling up the DagBag from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 16:06:13,182] {scheduler_job.py:1551} INFO - DAG(s) dict_keys(['process_replies']) retrieved from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 16:06:13,201] {scheduler_job.py:161} INFO - Processing /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py took 0.547 seconds
[2020-01-20 16:06:58,794] {scheduler_job.py:153} INFO - Started process (PID=9314) to work on /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 16:06:58,804] {scheduler_job.py:1539} INFO - Processing file /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py for tasks to queue
[2020-01-20 16:06:58,804] {logging_mixin.py:112} INFO - [2020-01-20 16:06:58,804] {dagbag.py:403} INFO - Filling up the DagBag from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 16:06:58,885] {scheduler_job.py:1551} INFO - DAG(s) dict_keys(['process_replies']) retrieved from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 16:06:58,902] {scheduler_job.py:161} INFO - Processing /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py took 0.109 seconds
[2020-01-20 16:07:44,921] {scheduler_job.py:153} INFO - Started process (PID=9351) to work on /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 16:07:44,928] {scheduler_job.py:1539} INFO - Processing file /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py for tasks to queue
[2020-01-20 16:07:44,929] {logging_mixin.py:112} INFO - [2020-01-20 16:07:44,929] {dagbag.py:403} INFO - Filling up the DagBag from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 16:07:45,273] {scheduler_job.py:1551} INFO - DAG(s) dict_keys(['process_replies']) retrieved from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 16:07:45,296] {scheduler_job.py:161} INFO - Processing /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py took 0.375 seconds
[2020-01-20 16:08:31,058] {scheduler_job.py:153} INFO - Started process (PID=9382) to work on /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 16:08:31,064] {scheduler_job.py:1539} INFO - Processing file /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py for tasks to queue
[2020-01-20 16:08:31,065] {logging_mixin.py:112} INFO - [2020-01-20 16:08:31,065] {dagbag.py:403} INFO - Filling up the DagBag from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 16:08:31,129] {scheduler_job.py:1551} INFO - DAG(s) dict_keys(['process_replies']) retrieved from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 16:08:31,146] {scheduler_job.py:161} INFO - Processing /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py took 0.089 seconds
[2020-01-20 16:09:17,213] {scheduler_job.py:153} INFO - Started process (PID=9408) to work on /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 16:09:17,219] {scheduler_job.py:1539} INFO - Processing file /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py for tasks to queue
[2020-01-20 16:09:17,220] {logging_mixin.py:112} INFO - [2020-01-20 16:09:17,219] {dagbag.py:403} INFO - Filling up the DagBag from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 16:09:17,271] {scheduler_job.py:1551} INFO - DAG(s) dict_keys(['process_replies']) retrieved from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 16:09:17,288] {scheduler_job.py:161} INFO - Processing /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py took 0.075 seconds
[2020-01-20 16:10:03,325] {scheduler_job.py:153} INFO - Started process (PID=9439) to work on /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 16:10:03,333] {scheduler_job.py:1539} INFO - Processing file /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py for tasks to queue
[2020-01-20 16:10:03,334] {logging_mixin.py:112} INFO - [2020-01-20 16:10:03,334] {dagbag.py:403} INFO - Filling up the DagBag from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 16:10:03,391] {scheduler_job.py:1551} INFO - DAG(s) dict_keys(['process_replies']) retrieved from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 16:10:03,409] {scheduler_job.py:161} INFO - Processing /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py took 0.084 seconds
[2020-01-20 16:10:49,435] {scheduler_job.py:153} INFO - Started process (PID=10113) to work on /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 16:10:49,441] {scheduler_job.py:1539} INFO - Processing file /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py for tasks to queue
[2020-01-20 16:10:49,441] {logging_mixin.py:112} INFO - [2020-01-20 16:10:49,441] {dagbag.py:403} INFO - Filling up the DagBag from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 16:10:49,701] {scheduler_job.py:1551} INFO - DAG(s) dict_keys(['process_replies']) retrieved from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 16:10:49,718] {scheduler_job.py:161} INFO - Processing /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py took 0.284 seconds
[2020-01-20 16:13:35,576] {scheduler_job.py:153} INFO - Started process (PID=10525) to work on /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 16:13:35,587] {scheduler_job.py:1539} INFO - Processing file /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py for tasks to queue
[2020-01-20 16:13:35,592] {logging_mixin.py:112} INFO - [2020-01-20 16:13:35,591] {dagbag.py:403} INFO - Filling up the DagBag from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 16:13:35,757] {scheduler_job.py:1551} INFO - DAG(s) dict_keys(['process_replies']) retrieved from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 16:13:35,788] {scheduler_job.py:1262} INFO - Processing process_replies
[2020-01-20 16:13:35,835] {scheduler_job.py:1272} INFO - Created <DagRun process_replies @ 2020-01-20T10:30:00+00:00: scheduled__2020-01-20T10:30:00+00:00, externally triggered: False>
[2020-01-20 16:13:35,840] {scheduler_job.py:740} INFO - Examining DAG run <DagRun process_replies @ 2020-01-20 10:30:00+00:00: scheduled__2020-01-20T10:30:00+00:00, externally triggered: False>
[2020-01-20 16:13:35,853] {scheduler_job.py:440} INFO - Skipping SLA check for <DAG: process_replies> because no tasks in DAG have SLAs
[2020-01-20 16:13:35,856] {scheduler_job.py:1613} INFO - Creating / updating <TaskInstance: process_replies.send_replies 2020-01-20 10:30:00+00:00 [scheduled]> in ORM
[2020-01-20 16:13:35,862] {scheduler_job.py:161} INFO - Processing /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py took 0.287 seconds
[2020-01-20 16:14:34,569] {scheduler_job.py:153} INFO - Started process (PID=10558) to work on /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 16:14:34,583] {scheduler_job.py:1539} INFO - Processing file /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py for tasks to queue
[2020-01-20 16:14:34,584] {logging_mixin.py:112} INFO - [2020-01-20 16:14:34,583] {dagbag.py:403} INFO - Filling up the DagBag from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 16:14:34,719] {scheduler_job.py:1551} INFO - DAG(s) dict_keys(['process_replies']) retrieved from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 16:14:34,768] {scheduler_job.py:1262} INFO - Processing process_replies
[2020-01-20 16:14:34,800] {scheduler_job.py:740} INFO - Examining DAG run <DagRun process_replies @ 2020-01-20 10:30:00+00:00: scheduled__2020-01-20T10:30:00+00:00, externally triggered: False>
[2020-01-20 16:14:34,812] {logging_mixin.py:112} INFO - [2020-01-20 16:14:34,811] {dagrun.py:318} INFO - Marking run <DagRun process_replies @ 2020-01-20 10:30:00+00:00: scheduled__2020-01-20T10:30:00+00:00, externally triggered: False> successful
[2020-01-20 16:14:34,816] {scheduler_job.py:440} INFO - Skipping SLA check for <DAG: process_replies> because no tasks in DAG have SLAs
[2020-01-20 16:14:34,819] {scheduler_job.py:161} INFO - Processing /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py took 0.249 seconds
[2020-01-20 16:15:20,697] {scheduler_job.py:153} INFO - Started process (PID=10588) to work on /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 16:15:20,708] {scheduler_job.py:1539} INFO - Processing file /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py for tasks to queue
[2020-01-20 16:15:20,709] {logging_mixin.py:112} INFO - [2020-01-20 16:15:20,709] {dagbag.py:403} INFO - Filling up the DagBag from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 16:15:20,840] {scheduler_job.py:1551} INFO - DAG(s) dict_keys(['process_replies']) retrieved from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 16:15:20,867] {scheduler_job.py:1262} INFO - Processing process_replies
[2020-01-20 16:15:20,882] {scheduler_job.py:440} INFO - Skipping SLA check for <DAG: process_replies> because no tasks in DAG have SLAs
[2020-01-20 16:15:20,885] {scheduler_job.py:161} INFO - Processing /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py took 0.188 seconds
[2020-01-20 16:16:06,812] {scheduler_job.py:153} INFO - Started process (PID=10623) to work on /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 16:16:06,822] {scheduler_job.py:1539} INFO - Processing file /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py for tasks to queue
[2020-01-20 16:16:06,823] {logging_mixin.py:112} INFO - [2020-01-20 16:16:06,822] {dagbag.py:403} INFO - Filling up the DagBag from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 16:16:06,884] {scheduler_job.py:1551} INFO - DAG(s) dict_keys(['process_replies']) retrieved from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 16:16:06,905] {scheduler_job.py:1262} INFO - Processing process_replies
[2020-01-20 16:16:06,918] {scheduler_job.py:440} INFO - Skipping SLA check for <DAG: process_replies> because no tasks in DAG have SLAs
[2020-01-20 16:16:06,920] {scheduler_job.py:161} INFO - Processing /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py took 0.109 seconds
[2020-01-20 16:16:52,931] {scheduler_job.py:153} INFO - Started process (PID=10650) to work on /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 16:16:52,940] {scheduler_job.py:1539} INFO - Processing file /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py for tasks to queue
[2020-01-20 16:16:52,941] {logging_mixin.py:112} INFO - [2020-01-20 16:16:52,941] {dagbag.py:403} INFO - Filling up the DagBag from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 16:16:53,017] {scheduler_job.py:1551} INFO - DAG(s) dict_keys(['process_replies']) retrieved from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 16:16:53,041] {scheduler_job.py:1262} INFO - Processing process_replies
[2020-01-20 16:16:53,056] {scheduler_job.py:440} INFO - Skipping SLA check for <DAG: process_replies> because no tasks in DAG have SLAs
[2020-01-20 16:16:53,059] {scheduler_job.py:161} INFO - Processing /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py took 0.127 seconds
[2020-01-20 16:17:39,068] {scheduler_job.py:153} INFO - Started process (PID=10684) to work on /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 16:17:39,075] {scheduler_job.py:1539} INFO - Processing file /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py for tasks to queue
[2020-01-20 16:17:39,076] {logging_mixin.py:112} INFO - [2020-01-20 16:17:39,076] {dagbag.py:403} INFO - Filling up the DagBag from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 16:17:39,210] {scheduler_job.py:1551} INFO - DAG(s) dict_keys(['process_replies']) retrieved from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 16:17:39,230] {scheduler_job.py:1262} INFO - Processing process_replies
[2020-01-20 16:17:39,242] {scheduler_job.py:440} INFO - Skipping SLA check for <DAG: process_replies> because no tasks in DAG have SLAs
[2020-01-20 16:17:39,244] {scheduler_job.py:161} INFO - Processing /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py took 0.177 seconds
[2020-01-20 16:18:25,197] {scheduler_job.py:153} INFO - Started process (PID=10712) to work on /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 16:18:25,202] {scheduler_job.py:1539} INFO - Processing file /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py for tasks to queue
[2020-01-20 16:18:25,203] {logging_mixin.py:112} INFO - [2020-01-20 16:18:25,203] {dagbag.py:403} INFO - Filling up the DagBag from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 16:18:25,258] {scheduler_job.py:1551} INFO - DAG(s) dict_keys(['process_replies']) retrieved from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 16:18:25,277] {scheduler_job.py:1262} INFO - Processing process_replies
[2020-01-20 16:18:25,290] {scheduler_job.py:440} INFO - Skipping SLA check for <DAG: process_replies> because no tasks in DAG have SLAs
[2020-01-20 16:18:25,292] {scheduler_job.py:161} INFO - Processing /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py took 0.095 seconds
[2020-01-20 16:19:11,311] {scheduler_job.py:153} INFO - Started process (PID=10737) to work on /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 16:19:11,321] {scheduler_job.py:1539} INFO - Processing file /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py for tasks to queue
[2020-01-20 16:19:11,322] {logging_mixin.py:112} INFO - [2020-01-20 16:19:11,322] {dagbag.py:403} INFO - Filling up the DagBag from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 16:19:11,455] {scheduler_job.py:1551} INFO - DAG(s) dict_keys(['process_replies']) retrieved from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 16:19:11,480] {scheduler_job.py:1262} INFO - Processing process_replies
[2020-01-20 16:19:11,492] {scheduler_job.py:440} INFO - Skipping SLA check for <DAG: process_replies> because no tasks in DAG have SLAs
[2020-01-20 16:19:11,494] {scheduler_job.py:161} INFO - Processing /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py took 0.183 seconds
[2020-01-20 16:19:57,422] {scheduler_job.py:153} INFO - Started process (PID=10762) to work on /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 16:19:57,429] {scheduler_job.py:1539} INFO - Processing file /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py for tasks to queue
[2020-01-20 16:19:57,430] {logging_mixin.py:112} INFO - [2020-01-20 16:19:57,430] {dagbag.py:403} INFO - Filling up the DagBag from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 16:19:57,482] {scheduler_job.py:1551} INFO - DAG(s) dict_keys(['process_replies']) retrieved from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 16:19:57,503] {scheduler_job.py:1262} INFO - Processing process_replies
[2020-01-20 16:19:57,516] {scheduler_job.py:440} INFO - Skipping SLA check for <DAG: process_replies> because no tasks in DAG have SLAs
[2020-01-20 16:19:57,518] {scheduler_job.py:161} INFO - Processing /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py took 0.096 seconds
[2020-01-20 16:20:43,538] {scheduler_job.py:153} INFO - Started process (PID=10792) to work on /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 16:20:43,546] {scheduler_job.py:1539} INFO - Processing file /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py for tasks to queue
[2020-01-20 16:20:43,547] {logging_mixin.py:112} INFO - [2020-01-20 16:20:43,547] {dagbag.py:403} INFO - Filling up the DagBag from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 16:20:43,739] {scheduler_job.py:1551} INFO - DAG(s) dict_keys(['process_replies']) retrieved from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 16:20:43,760] {scheduler_job.py:1262} INFO - Processing process_replies
[2020-01-20 16:20:43,789] {scheduler_job.py:1272} INFO - Created <DagRun process_replies @ 2020-01-20T10:40:00+00:00: scheduled__2020-01-20T10:40:00+00:00, externally triggered: False>
[2020-01-20 16:20:43,791] {scheduler_job.py:740} INFO - Examining DAG run <DagRun process_replies @ 2020-01-20 10:40:00+00:00: scheduled__2020-01-20T10:40:00+00:00, externally triggered: False>
[2020-01-20 16:20:43,801] {scheduler_job.py:440} INFO - Skipping SLA check for <DAG: process_replies> because no tasks in DAG have SLAs
[2020-01-20 16:20:43,804] {scheduler_job.py:1613} INFO - Creating / updating <TaskInstance: process_replies.send_replies 2020-01-20 10:40:00+00:00 [scheduled]> in ORM
[2020-01-20 16:20:43,811] {scheduler_job.py:161} INFO - Processing /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py took 0.273 seconds
[2020-01-20 16:21:42,324] {scheduler_job.py:153} INFO - Started process (PID=10826) to work on /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 16:21:42,333] {scheduler_job.py:1539} INFO - Processing file /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py for tasks to queue
[2020-01-20 16:21:42,335] {logging_mixin.py:112} INFO - [2020-01-20 16:21:42,334] {dagbag.py:403} INFO - Filling up the DagBag from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 16:21:42,410] {scheduler_job.py:1551} INFO - DAG(s) dict_keys(['process_replies']) retrieved from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 16:21:42,435] {scheduler_job.py:1262} INFO - Processing process_replies
[2020-01-20 16:21:42,447] {scheduler_job.py:740} INFO - Examining DAG run <DagRun process_replies @ 2020-01-20 10:40:00+00:00: scheduled__2020-01-20T10:40:00+00:00, externally triggered: False>
[2020-01-20 16:21:42,455] {logging_mixin.py:112} INFO - [2020-01-20 16:21:42,454] {dagrun.py:318} INFO - Marking run <DagRun process_replies @ 2020-01-20 10:40:00+00:00: scheduled__2020-01-20T10:40:00+00:00, externally triggered: False> successful
[2020-01-20 16:21:42,461] {scheduler_job.py:440} INFO - Skipping SLA check for <DAG: process_replies> because no tasks in DAG have SLAs
[2020-01-20 16:21:42,464] {scheduler_job.py:161} INFO - Processing /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py took 0.140 seconds
[2020-01-20 16:22:28,435] {scheduler_job.py:153} INFO - Started process (PID=10853) to work on /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 16:22:28,442] {scheduler_job.py:1539} INFO - Processing file /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py for tasks to queue
[2020-01-20 16:22:28,443] {logging_mixin.py:112} INFO - [2020-01-20 16:22:28,443] {dagbag.py:403} INFO - Filling up the DagBag from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 16:22:28,659] {scheduler_job.py:1551} INFO - DAG(s) dict_keys(['process_replies']) retrieved from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 16:22:28,682] {scheduler_job.py:1262} INFO - Processing process_replies
[2020-01-20 16:22:28,703] {scheduler_job.py:440} INFO - Skipping SLA check for <DAG: process_replies> because no tasks in DAG have SLAs
[2020-01-20 16:22:28,706] {scheduler_job.py:161} INFO - Processing /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py took 0.272 seconds
[2020-01-20 16:23:14,564] {scheduler_job.py:153} INFO - Started process (PID=10883) to work on /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 16:23:14,570] {scheduler_job.py:1539} INFO - Processing file /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py for tasks to queue
[2020-01-20 16:23:14,572] {logging_mixin.py:112} INFO - [2020-01-20 16:23:14,571] {dagbag.py:403} INFO - Filling up the DagBag from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 16:23:14,635] {scheduler_job.py:1551} INFO - DAG(s) dict_keys(['process_replies']) retrieved from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 16:23:14,659] {scheduler_job.py:1262} INFO - Processing process_replies
[2020-01-20 16:23:14,673] {scheduler_job.py:440} INFO - Skipping SLA check for <DAG: process_replies> because no tasks in DAG have SLAs
[2020-01-20 16:23:14,676] {scheduler_job.py:161} INFO - Processing /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py took 0.112 seconds
[2020-01-20 16:24:00,696] {scheduler_job.py:153} INFO - Started process (PID=10909) to work on /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 16:24:00,704] {scheduler_job.py:1539} INFO - Processing file /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py for tasks to queue
[2020-01-20 16:24:00,707] {logging_mixin.py:112} INFO - [2020-01-20 16:24:00,705] {dagbag.py:403} INFO - Filling up the DagBag from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 16:24:00,912] {scheduler_job.py:1551} INFO - DAG(s) dict_keys(['process_replies']) retrieved from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 16:24:00,933] {scheduler_job.py:1262} INFO - Processing process_replies
[2020-01-20 16:24:00,946] {scheduler_job.py:440} INFO - Skipping SLA check for <DAG: process_replies> because no tasks in DAG have SLAs
[2020-01-20 16:24:00,949] {scheduler_job.py:161} INFO - Processing /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py took 0.253 seconds
[2020-01-20 16:26:43,897] {scheduler_job.py:153} INFO - Started process (PID=10979) to work on /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 16:26:43,903] {scheduler_job.py:1539} INFO - Processing file /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py for tasks to queue
[2020-01-20 16:26:43,903] {logging_mixin.py:112} INFO - [2020-01-20 16:26:43,903] {dagbag.py:403} INFO - Filling up the DagBag from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 16:26:44,030] {scheduler_job.py:1551} INFO - DAG(s) dict_keys(['process_replies']) retrieved from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 16:26:44,049] {scheduler_job.py:161} INFO - Processing /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py took 0.152 seconds
[2020-01-20 16:27:42,030] {scheduler_job.py:153} INFO - Started process (PID=11017) to work on /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 16:27:42,037] {scheduler_job.py:1539} INFO - Processing file /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py for tasks to queue
[2020-01-20 16:27:42,040] {logging_mixin.py:112} INFO - [2020-01-20 16:27:42,040] {dagbag.py:403} INFO - Filling up the DagBag from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 16:27:42,120] {scheduler_job.py:1551} INFO - DAG(s) dict_keys(['process_replies']) retrieved from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 16:27:42,144] {scheduler_job.py:161} INFO - Processing /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py took 0.115 seconds
[2020-01-20 16:28:28,172] {scheduler_job.py:153} INFO - Started process (PID=11051) to work on /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 16:28:28,183] {scheduler_job.py:1539} INFO - Processing file /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py for tasks to queue
[2020-01-20 16:28:28,184] {logging_mixin.py:112} INFO - [2020-01-20 16:28:28,184] {dagbag.py:403} INFO - Filling up the DagBag from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 16:28:28,281] {scheduler_job.py:1551} INFO - DAG(s) dict_keys(['process_replies']) retrieved from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 16:28:28,306] {scheduler_job.py:161} INFO - Processing /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py took 0.134 seconds
[2020-01-20 16:29:14,295] {scheduler_job.py:153} INFO - Started process (PID=11096) to work on /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 16:29:14,301] {scheduler_job.py:1539} INFO - Processing file /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py for tasks to queue
[2020-01-20 16:29:14,302] {logging_mixin.py:112} INFO - [2020-01-20 16:29:14,302] {dagbag.py:403} INFO - Filling up the DagBag from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 16:29:14,367] {scheduler_job.py:1551} INFO - DAG(s) dict_keys(['process_replies']) retrieved from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 16:29:14,383] {scheduler_job.py:161} INFO - Processing /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py took 0.088 seconds
[2020-01-20 16:30:00,433] {scheduler_job.py:153} INFO - Started process (PID=11126) to work on /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 16:30:00,440] {scheduler_job.py:1539} INFO - Processing file /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py for tasks to queue
[2020-01-20 16:30:00,441] {logging_mixin.py:112} INFO - [2020-01-20 16:30:00,441] {dagbag.py:403} INFO - Filling up the DagBag from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 16:30:00,579] {scheduler_job.py:1551} INFO - DAG(s) dict_keys(['process_replies']) retrieved from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 16:30:00,595] {scheduler_job.py:161} INFO - Processing /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py took 0.163 seconds
[2020-01-20 16:31:26,119] {scheduler_job.py:153} INFO - Started process (PID=11167) to work on /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 16:31:26,128] {scheduler_job.py:1539} INFO - Processing file /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py for tasks to queue
[2020-01-20 16:31:26,129] {logging_mixin.py:112} INFO - [2020-01-20 16:31:26,129] {dagbag.py:403} INFO - Filling up the DagBag from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 16:31:26,186] {scheduler_job.py:1551} INFO - DAG(s) dict_keys(['process_replies']) retrieved from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 16:31:26,204] {scheduler_job.py:161} INFO - Processing /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py took 0.085 seconds
[2020-01-20 16:32:24,641] {scheduler_job.py:153} INFO - Started process (PID=11203) to work on /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 16:32:24,650] {scheduler_job.py:1539} INFO - Processing file /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py for tasks to queue
[2020-01-20 16:32:24,651] {logging_mixin.py:112} INFO - [2020-01-20 16:32:24,651] {dagbag.py:403} INFO - Filling up the DagBag from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 16:32:24,725] {scheduler_job.py:1551} INFO - DAG(s) dict_keys(['process_replies']) retrieved from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 16:32:24,744] {scheduler_job.py:161} INFO - Processing /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py took 0.103 seconds
[2020-01-20 16:34:06,992] {scheduler_job.py:153} INFO - Started process (PID=11268) to work on /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 16:34:07,001] {scheduler_job.py:1539} INFO - Processing file /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py for tasks to queue
[2020-01-20 16:34:07,003] {logging_mixin.py:112} INFO - [2020-01-20 16:34:07,002] {dagbag.py:403} INFO - Filling up the DagBag from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 16:34:07,058] {scheduler_job.py:1551} INFO - DAG(s) dict_keys(['process_replies']) retrieved from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 16:34:07,075] {scheduler_job.py:161} INFO - Processing /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py took 0.083 seconds
[2020-01-20 16:34:53,113] {scheduler_job.py:153} INFO - Started process (PID=11292) to work on /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 16:34:53,120] {scheduler_job.py:1539} INFO - Processing file /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py for tasks to queue
[2020-01-20 16:34:53,121] {logging_mixin.py:112} INFO - [2020-01-20 16:34:53,120] {dagbag.py:403} INFO - Filling up the DagBag from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 16:34:53,179] {scheduler_job.py:1551} INFO - DAG(s) dict_keys(['process_replies']) retrieved from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 16:34:53,200] {scheduler_job.py:161} INFO - Processing /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py took 0.086 seconds
[2020-01-20 16:35:39,253] {scheduler_job.py:153} INFO - Started process (PID=11319) to work on /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 16:35:39,258] {scheduler_job.py:1539} INFO - Processing file /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py for tasks to queue
[2020-01-20 16:35:39,259] {logging_mixin.py:112} INFO - [2020-01-20 16:35:39,259] {dagbag.py:403} INFO - Filling up the DagBag from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 16:35:39,311] {scheduler_job.py:1551} INFO - DAG(s) dict_keys(['process_replies']) retrieved from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 16:35:39,328] {scheduler_job.py:161} INFO - Processing /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py took 0.075 seconds
[2020-01-20 16:36:25,385] {scheduler_job.py:153} INFO - Started process (PID=11345) to work on /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 16:36:25,415] {scheduler_job.py:1539} INFO - Processing file /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py for tasks to queue
[2020-01-20 16:36:25,418] {logging_mixin.py:112} INFO - [2020-01-20 16:36:25,417] {dagbag.py:403} INFO - Filling up the DagBag from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 16:36:25,582] {scheduler_job.py:1551} INFO - DAG(s) dict_keys(['process_replies']) retrieved from /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py
[2020-01-20 16:36:25,600] {scheduler_job.py:161} INFO - Processing /Users/aneeshmakala/Documents/ComputerScience/datascience/hapPy/airflow/dags/process_replies.py took 0.216 seconds
