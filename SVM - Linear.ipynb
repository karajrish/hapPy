{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "import helper\n",
    "import text_embeddings\n",
    "import performance\n",
    "import models\n",
    "import predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = helper.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Split data into train/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = helper.split_data(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Text embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_features, x_test_features, vectorizer = text_embeddings.encode_bag_of_words(x_train, x_test, 'text')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Grid Search using "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-  https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDClassifier.html#sklearn.linear_model.SGDClassifier\n",
    "-  https://scikit-learn.org/stable/modules/kernel_approximation.html  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_x_train = x_train_features['text']['data']\n",
    "final_y_train = y_train\n",
    "\n",
    "final_x_test = x_test_features['text']['data']\n",
    "final_y_test = y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_params = dict(eta0=0.0001,loss='hinge', random_state=15, penalty='l2', tol=1e-3, verbose=0)\n",
    "model_class = SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "import matplotlib.pyplot as plt\n",
    "# from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from scipy.stats import randint as sp_randint\n",
    "\n",
    "\n",
    "alpha_range = [ 0.0001,0.001,0.01,0.1,1,2,3,4,5,6,7,8,9,10,50,100]\n",
    "\n",
    "model = model_class(**model_params)\n",
    "\n",
    "search_params = {'alpha' : alpha_range}\n",
    "search = GridSearchCV(model,\n",
    "                      search_params,\n",
    "                      cv=5,\n",
    "                      scoring=\"f1\",\n",
    "                     return_train_score=True)\n",
    "\n",
    "\n",
    "search.fit(final_x_train, final_y_train)\n",
    "results = pd.DataFrame.from_dict(search.cv_results_)\n",
    "results = results.sort_values(['param_alpha'])\n",
    "results['mean_train_score-mean_test_score'] = results['mean_train_score'] - results['mean_test_score']\n",
    "results[['param_alpha','mean_train_score','mean_test_score', 'mean_train_score-mean_test_score']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train\n",
    "plt.plot(results['param_alpha'], results['mean_train_score'], label=\"Train AUC\")\n",
    "plt.scatter(results['param_alpha'], results['mean_train_score'], label=\"Train AUC points\")\n",
    "\n",
    "# Validation\n",
    "plt.plot(results['param_alpha'], results['mean_test_score'], label=\"Validation AUC\")\n",
    "plt.scatter(results['param_alpha'], results['mean_test_score'], label=\"Validation AUC points\")\n",
    "\n",
    "plt.xlabel(\"Alpha: hyperparameter\")\n",
    "plt.ylabel(\"AUC\")\n",
    "plt.title(\"AUC vs alpha curves\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.01\n",
    "final_model = model_class(alpha=alpha, **model_params)\n",
    "final_model.fit(final_x_train, final_y_train)\n",
    "\n",
    "final_y_train_pred = final_model.predict(final_x_train)\n",
    "final_y_test_pred = final_model.predict(final_x_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Train\n",
    "train_cm = confusion_matrix(final_y_train, final_y_train_pred)\n",
    "train_cm = pd.DataFrame(train_cm, columns=['actual_0', 'actual_1'],\n",
    "                            index=['predicted_0','predicted_1'])\n",
    "print(\"Confusion matrix for Train set\")\n",
    "print(train_cm)\n",
    "print()\n",
    "\n",
    "# Test\n",
    "test_cm = confusion_matrix(final_y_test, final_y_test_pred)\n",
    "test_cm = pd.DataFrame(test_cm, columns=['actual_0', 'actual_1'],\n",
    "                            index=['predicted_0','predicted_1'])\n",
    "print(\"Confusion matrix for Test set\")\n",
    "print(test_cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Performance Measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:probability estimates are not available for loss='hinge'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.8959937018894332,\n",
       " 'f1': 0.928849260965831,\n",
       " 'confusion_matrix':              actual_0  actual_1\n",
       " predicted_0      2482       634\n",
       " predicted_1       555      7761}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "performance_measures = performance.get_performance_measures(final_model, final_x_test, final_y_test)\n",
    "performance_measures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"happy January\"\n",
    "predict.is_text_depressed(final_model, text, \n",
    "                         model_id=\"NB\",\n",
    "                         vectorizer=vectorizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Future Work\n",
    "- Explore string kernel https://github.com/timshenkao/StringKernelSVM\n",
    "- word2vec using SVM (https://shop.tarjomeplus.com/UploadFileEn/TPLUS_EN_3959.pdf)\n",
    "- https://www.analyticsvidhya.com/blog/2018/04/a-comprehensive-guide-to-understand-and-implement-text-classification-in-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
